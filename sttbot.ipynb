{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdihoore/STTforPersian/blob/main/sttbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx0Ee8w5Gk4Z"
      },
      "outputs": [],
      "source": [
        "!pip install telethon google-generativeai python-dotenv nest_asyncio Pillow pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import re\n",
        "import math\n",
        "import zipfile\n",
        "import shutil # For robust directory cleanup\n",
        "from io import BytesIO\n",
        "\n",
        "from telethon import TelegramClient, events, Button\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold, GenerationConfig\n",
        "from google.api_core import exceptions as google_exceptions # For specific error handling\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# --- Configuration ---\n",
        "# Apply nest_asyncio early\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    API_ID = int(userdata.get('TELEGRAM_API_ID'))\n",
        "    API_HASH = userdata.get('TELEGRAM_API_HASH')\n",
        "    BOT_TOKEN = userdata.get('TELEGRAM_BOT_TTS')\n",
        "\n",
        "    # Load multiple Google API Keys\n",
        "    # Name your secrets like GOOGLE_API_KEY_1, GOOGLE_API_KEY_2, etc. in Colab\n",
        "    GOOGLE_API_KEYS_LIST = []\n",
        "    for i in range(1, 6): # Try to load up to 5 keys, adjust as needed\n",
        "        key = userdata.get(f'GOOGLE_API_KEY_{i}')\n",
        "        if key:\n",
        "            GOOGLE_API_KEYS_LIST.append(key)\n",
        "\n",
        "    if not all([API_ID, API_HASH, BOT_TOKEN]):\n",
        "        raise ValueError(\"Telegram API_ID, API_HASH, or BOT_TOKEN is missing.\")\n",
        "    if not GOOGLE_API_KEYS_LIST:\n",
        "        raise ValueError(\"At least one GOOGLE_API_KEY_n must be configured in Colab secrets.\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.critical(f\"Error loading secrets: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Model and API Configuration ---\n",
        "MODEL_PREFERENCES = {\n",
        "    \"transcription\": [\"gemini-1.5-flash-latest\", \"gemini-1.5-flash-latest\"], # Pro for potentially better accuracy\n",
        "    \"summarization_detailed\": [\"gemini-2.5-flash-preview-04-17-thinking\", \"gemini-2.5-flash-preview-04-17\"], # Pro essential for detailed summaries\n",
        "    \"translation_segmentation\": [\"gemini-1.5-flash-latest\"],\n",
        "    \"bot_response\": [\"gemini-1.5-flash-latest\"],\n",
        "}\n",
        "\n",
        "GENERATION_CONFIGS = {\n",
        "    \"default\": GenerationConfig(temperature=0.5),\n",
        "    \"summarization_detailed\": GenerationConfig(temperature=0.4, top_p=0.95), # Lower temp for factual detail\n",
        "    \"translation_segmentation\": GenerationConfig(temperature=0.2), # More deterministic\n",
        "    \"bot_response\": GenerationConfig(temperature=0.7),\n",
        "}\n",
        "\n",
        "SAFETY_SETTINGS = [\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_HARASSMENT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_HATE_SPEECH, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "]\n",
        "\n",
        "# --- Global State for API Key Management ---\n",
        "_current_key_index = 0\n",
        "_active_google_api_key = None\n",
        "\n",
        "def configure_gemini_client(api_key_to_set):\n",
        "    global _active_google_api_key\n",
        "    if api_key_to_set != _active_google_api_key:\n",
        "        logger.info(f\"Configuring Google AI SDK with API key ending with ...{api_key_to_set[-4:]}\")\n",
        "        try:\n",
        "            genai.configure(api_key=api_key_to_set)\n",
        "            _active_google_api_key = api_key_to_set\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to configure Google AI SDK with key ...{api_key_to_set[-4:]}: {e}\")\n",
        "            _active_google_api_key = None\n",
        "            return False\n",
        "    return True # Already configured with this key\n",
        "\n",
        "# Initialize with the first key\n",
        "if not configure_gemini_client(GOOGLE_API_KEYS_LIST[0]):\n",
        "    logger.critical(\"Failed to configure Gemini with the initial API key. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Telethon Client Initialization\n",
        "session_name = f\"bot_session_{BOT_TOKEN.split(':')[0]}\"\n",
        "client = TelegramClient(session_name, API_ID, API_HASH)\n",
        "TEMP_DIR = Path(\"./temp_files_linguascribe_bot\")\n",
        "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TEMP_EXTRACTION_DIR = TEMP_DIR / \"extracted_files\"\n",
        "TEMP_EXTRACTION_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# --- Audio/Video Processing Constants ---\n",
        "MAX_DURATION_MINUTES = 25  # Max duration for single audio processing before splitting (Gemini Flash can handle up to 1h, Pro even more, but smaller chunks are safer for retries)\n",
        "MAX_DURATION_MS = MAX_DURATION_MINUTES * 60 * 1000\n",
        "VIDEO_MIME_TYPES = ['video/mp4', 'video/mpeg', 'video/quicktime', 'video/x-msvideo', 'video/x-flv', 'video/webm', 'video/x-matroska', 'video/avi']\n",
        "AUDIO_OUTPUT_FORMAT = \"ogg\" # opus in ogg\n",
        "AUDIO_OUTPUT_CODEC = \"libopus\"\n",
        "AUDIO_OUTPUT_BITRATE = \"48k\" # Reduced bitrate for smaller size\n",
        "AUDIO_SAMPLE_RATE = 16000 # Good for speech\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "async def cleanup_files_and_dirs(*paths):\n",
        "    for path_obj in paths:\n",
        "        path = Path(path_obj)\n",
        "        if not path.exists():\n",
        "            continue\n",
        "        try:\n",
        "            if path.is_file():\n",
        "                path.unlink()\n",
        "                logger.info(f\"Deleted temporary file: {path}\")\n",
        "            elif path.is_dir():\n",
        "                shutil.rmtree(path)\n",
        "                logger.info(f\"Deleted temporary directory: {path}\")\n",
        "        except OSError as e:\n",
        "            logger.error(f\"Error deleting {path}: {e}\")\n",
        "\n",
        "def generate_srt_with_timecodes(segmented_text):\n",
        "    lines = [line for line in segmented_text.split(\"\\n\") if line.strip()]\n",
        "    if not lines:\n",
        "        return \"1\\n00:00:00,000 --> 00:00:05,000\\n(Ù…Ø­ØªÙˆØ§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯)\\n\"\n",
        "    srt_content = []\n",
        "    current_time_total_seconds = 0\n",
        "    segment_duration_seconds = 5 # Average duration per subtitle line\n",
        "    for i, line in enumerate(lines):\n",
        "        start_seconds = current_time_total_seconds\n",
        "        end_seconds = current_time_total_seconds + segment_duration_seconds\n",
        "        def format_time(s):\n",
        "            return f\"{int(s // 3600):02}:{int(s % 3600 // 60):02}:{int(s % 60):02},{int((s % 1) * 1000):03}\"\n",
        "        srt_content.append(str(i + 1))\n",
        "        srt_content.append(f\"{format_time(start_seconds)} --> {format_time(end_seconds)}\")\n",
        "        srt_content.append(line)\n",
        "        srt_content.append(\"\")\n",
        "        current_time_total_seconds = end_seconds + 0.5 # Add a small gap\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "async def get_audio_duration(file_path):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        duration_ms = len(audio)\n",
        "        logger.info(f\"Audio duration for {file_path}: {duration_ms/1000:.2f}s ({duration_ms/60000:.2f}min)\")\n",
        "        return duration_ms\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting audio duration for {file_path}: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def split_audio_file(file_path, base_name, max_duration_ms=MAX_DURATION_MS):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        total_duration_ms = len(audio)\n",
        "\n",
        "        if total_duration_ms <= max_duration_ms:\n",
        "            logger.info(f\"Audio {base_name} is short enough, no split needed.\")\n",
        "            return [str(file_path)]\n",
        "\n",
        "        num_chunks = math.ceil(total_duration_ms / max_duration_ms)\n",
        "        logger.info(f\"Splitting audio {base_name} into {num_chunks} chunks.\")\n",
        "        chunk_paths = []\n",
        "        for i in range(num_chunks):\n",
        "            start_ms = i * max_duration_ms\n",
        "            end_ms = min((i + 1) * max_duration_ms, total_duration_ms)\n",
        "            chunk = audio[start_ms:end_ms]\n",
        "            # Ensure correct extension based on AUDIO_OUTPUT_FORMAT\n",
        "            chunk_filename = f\"{base_name}_part{i+1}.{AUDIO_OUTPUT_FORMAT}\"\n",
        "            chunk_path = TEMP_DIR / chunk_filename\n",
        "            logger.info(f\"Exporting chunk {i+1}/{num_chunks} to {chunk_path}\")\n",
        "            chunk.export(str(chunk_path), format=AUDIO_OUTPUT_FORMAT, codec=AUDIO_OUTPUT_CODEC if AUDIO_OUTPUT_FORMAT == \"ogg\" else None, bitrate=AUDIO_OUTPUT_BITRATE)\n",
        "            chunk_paths.append(str(chunk_path))\n",
        "        return chunk_paths\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error splitting audio file {base_name}: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "# --- Core Gemini API Request Function with Retry ---\n",
        "async def gemini_request_with_retry(\n",
        "    task_name: str,\n",
        "    model_preference_key: str,\n",
        "    prompt_parts: list,\n",
        "    generation_config_key: str,\n",
        "    file_path_to_upload: str = None\n",
        "):\n",
        "    global _current_key_index\n",
        "    uploaded_file_ref = None\n",
        "    max_key_cycles = len(GOOGLE_API_KEYS_LIST)\n",
        "\n",
        "    for key_cycle in range(max_key_cycles):\n",
        "        current_api_key = GOOGLE_API_KEYS_LIST[_current_key_index]\n",
        "        logger.info(f\"[Task: {task_name}] Attempting with API key ending ...{current_api_key[-4:]} (Cycle {key_cycle+1}/{max_key_cycles})\")\n",
        "\n",
        "        if not configure_gemini_client(current_api_key):\n",
        "            _current_key_index = (_current_key_index + 1) % len(GOOGLE_API_KEYS_LIST)\n",
        "            continue # Try next key if this one fails to configure\n",
        "\n",
        "        models_to_try = MODEL_PREFERENCES.get(model_preference_key, [MODEL_PREFERENCES[\"bot_response\"][0]])\n",
        "        gen_config = GENERATION_CONFIGS.get(generation_config_key, GENERATION_CONFIGS[\"default\"])\n",
        "\n",
        "        # File Upload (if needed, once per key attempt)\n",
        "        if file_path_to_upload and not uploaded_file_ref: # Only upload once per successful key config\n",
        "            try:\n",
        "                logger.info(f\"[Task: {task_name}] Uploading file: {file_path_to_upload} with key ...{current_api_key[-4:]}\")\n",
        "                # genai.upload_file is synchronous\n",
        "                uploaded_file_ref = await asyncio.to_thread(\n",
        "                    genai.upload_file, path=file_path_to_upload,\n",
        "                    # mime_type can be specified if Path(file_path_to_upload).suffix is not reliable\n",
        "                )\n",
        "                logger.info(f\"[Task: {task_name}] File uploaded successfully: {uploaded_file_ref.name}\")\n",
        "                # Prepend file to prompt_parts if upload successful\n",
        "                current_prompt_parts = [uploaded_file_ref] + prompt_parts\n",
        "            except Exception as e:\n",
        "                logger.error(f\"[Task: {task_name}] File upload failed with key ...{current_api_key[-4:]}: {e}\")\n",
        "                # If upload fails, this key might be problematic for uploads or file is bad.\n",
        "                # Cycle to next key by incrementing index and continuing outer loop.\n",
        "                _current_key_index = (_current_key_index + 1) % len(GOOGLE_API_KEYS_LIST)\n",
        "                uploaded_file_ref = None # Reset for next key\n",
        "                continue\n",
        "        elif file_path_to_upload and uploaded_file_ref: # File already uploaded with this key\n",
        "             current_prompt_parts = [uploaded_file_ref] + prompt_parts\n",
        "        else: # No file to upload\n",
        "            current_prompt_parts = prompt_parts\n",
        "\n",
        "\n",
        "        for model_name in models_to_try:\n",
        "            logger.info(f\"[Task: {task_name}] Trying model: {model_name} with key ...{current_api_key[-4:]}\")\n",
        "            try:\n",
        "                model = genai.GenerativeModel(\n",
        "                    model_name=model_name,\n",
        "                    generation_config=gen_config,\n",
        "                    safety_settings=SAFETY_SETTINGS\n",
        "                )\n",
        "                # model.generate_content is synchronous\n",
        "                response = await asyncio.to_thread(\n",
        "                    model.generate_content, contents=current_prompt_parts\n",
        "                )\n",
        "                # Check for empty or problematic response\n",
        "                if not response.candidates or not response.text:\n",
        "                    if response.prompt_feedback and response.prompt_feedback.block_reason:\n",
        "                        logger.warning(f\"[Task: {task_name}] Request blocked for model {model_name}. Reason: {response.prompt_feedback.block_reason_message or response.prompt_feedback.block_reason}\")\n",
        "                        # This is often not retriable with same input. Break from model loop.\n",
        "                        break\n",
        "                    else:\n",
        "                        logger.warning(f\"[Task: {task_name}] Empty response from model {model_name}. Candidates: {response.candidates}\")\n",
        "                        # Treat as a failure for this model, try next model or key\n",
        "                        continue # Try next model\n",
        "\n",
        "                logger.info(f\"[Task: {task_name}] Successful response from model {model_name} with key ...{current_api_key[-4:]}\")\n",
        "                return response.text.strip(), uploaded_file_ref # Return text and file_ref\n",
        "\n",
        "            except (google_exceptions.ResourceExhausted,\n",
        "                    google_exceptions.InternalServerError,\n",
        "                    google_exceptions.DeadlineExceeded,\n",
        "                    google_exceptions.ServiceUnavailable,\n",
        "                    google_exceptions.Aborted) as e:\n",
        "                logger.warning(f\"[Task: {task_name}] Retryable API error with model {model_name} / key ...{current_api_key[-4:]}: {type(e).__name__} - {e}. Retrying with next model/key.\")\n",
        "                await asyncio.sleep(1) # Simple backoff\n",
        "                continue # Try next model or, if end of models, will go to next key\n",
        "            except (google_exceptions.InvalidArgument, google_exceptions.PermissionDenied) as e:\n",
        "                logger.error(f\"[Task: {task_name}] Non-retryable (for this model/key) API error with model {model_name} / key ...{current_api_key[-4:]}: {type(e).__name__} - {e}. Skipping model/key.\")\n",
        "                break # Break from model loop, try next key\n",
        "            except genai.types.BlockedPromptException as e:\n",
        "                logger.error(f\"[Task: {task_name}] BlockedPromptException with model {model_name}: {e}. This input is problematic.\")\n",
        "                raise # Re-raise, as this is usually an input issue not fixable by retry\n",
        "            except Exception as e:\n",
        "                logger.error(f\"[Task: {task_name}] Unexpected error with model {model_name} / key ...{current_api_key[-4:]}: {type(e).__name__} - {e}\", exc_info=True)\n",
        "                # For unexpected errors, break from model loop and try next key\n",
        "                break\n",
        "\n",
        "        # If all models for the current key failed or were skipped\n",
        "        _current_key_index = (_current_key_index + 1) % len(GOOGLE_API_KEYS_LIST)\n",
        "        uploaded_file_ref = None # Reset uploaded file ref if we are changing key\n",
        "\n",
        "    # If all keys and models failed\n",
        "    logger.error(f\"[Task: {task_name}] All API keys and models failed after {max_key_cycles} cycles.\")\n",
        "    raise Exception(f\"Failed to get response for {task_name} after multiple retries with all available keys/models.\")\n",
        "\n",
        "\n",
        "# --- Specific Google AI API Call Functions (using the retry wrapper) ---\n",
        "\n",
        "async def transcribe_audio_google(file_path):\n",
        "    logger.info(f\"Transcribing audio file: {file_path}\")\n",
        "    prompt = \"Please transcribe the audio provided accurately. Return ONLY the plain text transcription.\"\n",
        "    transcription, uploaded_file_ref = await gemini_request_with_retry(\n",
        "        task_name=\"AudioTranscription\",\n",
        "        model_preference_key=\"transcription\",\n",
        "        prompt_parts=[prompt],\n",
        "        generation_config_key=\"default\",\n",
        "        file_path_to_upload=file_path\n",
        "    )\n",
        "    if not transcription:\n",
        "        raise ValueError(\"Transcription failed: No text returned after retries.\")\n",
        "    return transcription, uploaded_file_ref\n",
        "\n",
        "DETAILED_SUMMARY_PROMPT_FOR_COLLEGE_PREP_FA = \"\"\"\n",
        "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø®Ø¨Ø±Ù‡ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ ÙˆØ¸ÛŒÙÙ‡ ØªÙ‡ÛŒÙ‡ Ù…Ø·Ø§Ù„Ø¨ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ø¢Ø²Ù…ÙˆÙ†â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ (Ú©Ù†Ú©ÙˆØ±) Ø±Ø§ Ø¨Ø± Ø¹Ù‡Ø¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯.\n",
        "ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ (Ú©Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ù† Ø¯Ø± Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¢Ù…Ø¯Ù‡) Ùˆ Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ Ø¢Ù† Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.\n",
        "Ù„Ø·ÙØ§Ù‹ Ø§ÛŒÙ† Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ ÛŒÚ© Ø®Ù„Ø§ØµÙ‡ Ø¨Ø³ÛŒØ§Ø± Ø¬Ø§Ù…Ø¹ØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª ÙØ±Ø§ÙˆØ§Ù† Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ùˆ Ø¯Ø±Ú© Ú©Ø§Ù…Ù„ Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¢Ø²Ù…ÙˆÙ† Ù…Ù‡Ù… Ø¯Ø§Ø±Ø¯ØŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§Ø´Ø¯.\n",
        "\n",
        "Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡ Ùˆ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø§Ù…Ø¹ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ø¢Ø²Ù…ÙˆÙ†:\n",
        "\n",
        "1.  **Ù…Ù‚Ø¯Ù…Ù‡ Ùˆ Ù‡Ø¯Ù Ú©Ù„ÛŒ (Û±-Û² Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù):**\n",
        "    *   Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ Ùˆ Ù‡Ø¯Ù Ú©Ù„ÛŒ Ø§Ø² Ø§Ø±Ø§Ø¦Ù‡ Ø§ÛŒÙ† Ù…Ø­ØªÙˆØ§ Ú†ÛŒØ³ØªØŸ\n",
        "    *   Ø²Ù…ÛŒÙ†Ù‡ Ùˆ Ø¨Ø³ØªØ± Ø§ØµÙ„ÛŒ Ø¨Ø­Ø« Ú†ÛŒØ³ØªØŸ\n",
        "\n",
        "2.  **Ù…ÙØ§Ù‡ÛŒÙ… Ùˆ ØªØ¹Ø§Ø±ÛŒÙ Ú©Ù„ÛŒØ¯ÛŒ (Ù„ÛŒØ³Øª Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡):**\n",
        "    *   ØªÙ…Ø§Ù…ÛŒ Ø§ØµØ·Ù„Ø§Ø­Ø§ØªØŒ Ù…ÙØ§Ù‡ÛŒÙ… Ùˆ ÙˆØ§Ú˜Ú¯Ø§Ù† ØªØ®ØµØµÛŒ Ù…Ù‡Ù… Ù…Ø·Ø±Ø­ Ø´Ø¯Ù‡ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯.\n",
        "    *   Ù‡Ø± Ú©Ø¯Ø§Ù… Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± ÙˆØ§Ø¶Ø­ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¯Ø± Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¨Ø­Ø« ØªØ¹Ø±ÛŒÙ Ú©Ù†ÛŒØ¯.\n",
        "\n",
        "3.  **Ù†Ú©Ø§Øª Ø§ØµÙ„ÛŒ Ùˆ Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ (Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ØªÛŒ ÛŒØ§ Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Markdown):**\n",
        "    *   ØªÙ…Ø§Ù…ÛŒ Ù†Ú©Ø§ØªØŒ Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù…Ø·Ø±Ø­ Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ ØªÙØµÛŒÙ„ Ø¨ÛŒØ§Ù† Ú©Ù†ÛŒØ¯.\n",
        "    *   Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ú©ØªÙ‡ ÛŒØ§ Ø§Ø³ØªØ¯Ù„Ø§Ù„ØŒ Ø´ÙˆØ§Ù‡Ø¯ØŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ØŒ Ø¢Ù…Ø§Ø±ØŒ Ø§Ø±Ù‚Ø§Ù…ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ Ùˆ Ø§Ø³Ø§Ù…ÛŒ Ù…Ù‡Ù… Ø°Ú©Ø± Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ Ø¨ÛŒØ§ÙˆØ±ÛŒØ¯.\n",
        "    *   Ø§Ú¯Ø± Ø²Ù†Ø¬ÛŒØ±Ù‡ Ù…Ù†Ø·Ù‚ÛŒ ÛŒØ§ Ù…Ø±Ø§Ø­Ù„ Ø®Ø§ØµÛŒ Ø¯Ø± Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ú¯Ø§Ù… Ø¨Ù‡ Ú¯Ø§Ù… ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯.\n",
        "\n",
        "4.  **Ø¬Ø²Ø¦ÛŒØ§Øª ØªÚ©Ù…ÛŒÙ„ÛŒ Ùˆ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… (Ø­Ø¯Ø§Ù‚Ù„ Ûµ-Û· Ù…ÙˆØ±Ø¯ ÛŒØ§ Ø¨ÛŒØ´ØªØ± Ø¯Ø± ØµÙˆØ±Øª Ù„Ø²ÙˆÙ…):**\n",
        "    *   Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒØŒ Ù…ÙˆØ§Ø±Ø¯ Ø®Ø§ØµØŒ Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ù…ÙˆØ±Ø¯ÛŒ ÛŒØ§ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ´Ù† Ø´Ø¯Ù† Ù…ÙØ§Ù‡ÛŒÙ… Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ø±Ø§ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ø´Ø±Ø­ Ø¯Ù‡ÛŒØ¯.\n",
        "    *   Ù†Ù‚Ù„ Ù‚ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ùˆ ØªØ§Ø«ÛŒØ±Ú¯Ø°Ø§Ø± Ø±Ø§ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯) Ø¨Ø§ Ø°Ú©Ø± Ø¯Ù‚ÛŒÙ‚ Ø¢ÙˆØ±Ø¯Ù‡ Ùˆ Ø§Ù‡Ù…ÛŒØª Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯.\n",
        "\n",
        "5.  **ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ù…Ø­ØªÙˆØ§ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù† Ùˆ Ù…Ø±ØªØ¨Ø· Ø¨ÙˆØ¯Ù†):**\n",
        "    *   Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÛŒÙ† Ù…ÙØ§Ù‡ÛŒÙ… Ù…Ø®ØªÙ„Ù Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ\n",
        "    *   Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ùˆ Ø¶Ø¹Ù Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ (Ø¯Ø± ØµÙˆØ±Øª ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø®ÙˆØ¯ Ù…Ø­ØªÙˆØ§) Ú†ÛŒØ³ØªØŸ\n",
        "    *   Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§ØªØŒ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ ÛŒØ§ Ù†ØªØ§ÛŒØ¬ Ø¹Ù…Ù„ÛŒ Ú©Ù‡ Ø§Ø² Ø¨Ø­Ø« Ø­Ø§ØµÙ„ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ú©Ø¯Ø§Ù…Ù†Ø¯ØŸ\n",
        "    *   Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ØŒ ÙØ±Ø¶ÛŒÙ‡ Ø²Ù…ÛŒÙ†Ù‡â€ŒØ§ÛŒ ÛŒØ§ Ù¾ÛŒØ§Ù…Ø¯Ù‡Ø§ÛŒ Ù¾Ù†Ù‡Ø§Ù† Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯.\n",
        "\n",
        "6.  **Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§ØµÙ„ÛŒ Ùˆ Ù¾ÛŒØ§Ù… Ù†Ù‡Ø§ÛŒÛŒ (Û±-Û² Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù):**\n",
        "    *   Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø­Ø« Ùˆ Ù…Ù‡Ù…ØªØ±ÛŒÙ† Ù†ØªØ§ÛŒØ¬ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ú¯Ø±ÙØª Ú†ÛŒØ³ØªØŸ\n",
        "    *   Ù¾ÛŒØ§Ù… Ø§ØµÙ„ÛŒ ÛŒØ§ Ø¯Ø±Ø³ÛŒ Ú©Ù‡ Ù…Ø®Ø§Ø·Ø¨ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø§ÛŒÙ† Ù…Ø­ØªÙˆØ§ Ø¨Ú¯ÛŒØ±Ø¯ Ú†ÛŒØ³ØªØŸ\n",
        "\n",
        "7.  **Ø³Ø§Ø®ØªØ§Ø± Ùˆ Ø²Ø¨Ø§Ù†:**\n",
        "    *   Ø®Ù„Ø§ØµÙ‡ Ø¨Ø§ÛŒØ¯ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±Ø³Ù…ÛŒØŒ Ø¹Ù„Ù…ÛŒ Ùˆ Ø±ÙˆØ§Ù† Ø¨Ø§Ø´Ø¯.\n",
        "    *   Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ (Ù…Ø§Ù†Ù†Ø¯ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ØŒ ØªÛŒØªØ±Ù‡Ø§ÛŒ ÙØ±Ø¹ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Markdown Ù…Ø§Ù†Ù†Ø¯ #, ##, ###, *, -) Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†Ø¯Ù‡ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ØªØ§ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØª Ù…Ø±ÙˆØ± Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§Ø¨Ø¯.\n",
        "    *   Ø¯Ø± Ø§Ø±Ø§Ø¦Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ú©ÙˆØªØ§Ù‡ÛŒ Ù†Ú©Ù†ÛŒØ¯Ø› Ù‡Ø¯ÙØŒ Ù¾ÙˆØ´Ø´ Ú©Ø§Ù…Ù„ Ùˆ Ø¹Ù…ÛŒÙ‚ Ù…Ø·Ø§Ù„Ø¨ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ø¢Ø²Ù…ÙˆÙ† Ø§Ø³Øª.\n",
        "    *   ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒØŒ Ø¨Ø¯ÙˆÙ† Ø¹Ø¨Ø§Ø±Øª Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ ÛŒØ§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´ÙˆØ¯.\n",
        "\"\"\"\n",
        "\n",
        "async def summarize_audio_google(audio_file_ref_for_context, transcription_context):\n",
        "    logger.info(\"Generating detailed summary for college prep...\")\n",
        "    # audio_file_ref_for_context is used by the model to get richer context than just text\n",
        "    summary_prompt_formatted = DETAILED_SUMMARY_PROMPT_FOR_COLLEGE_PREP_FA.format(transcription_context=transcription_context)\n",
        "\n",
        "    # Note: We are passing audio_file_ref_for_context. The retry wrapper expects a file *path*.\n",
        "    # For summarization, we pass the *transcription* as primary text content,\n",
        "    # and the audio_file_ref is a reference to an *already uploaded* file.\n",
        "    # The current `gemini_request_with_retry` uploads a file if path is given.\n",
        "    # We need to adjust how `summarize_audio_google` calls it if it relies on an existing ref.\n",
        "\n",
        "    # Option 1: If audio_file_ref is essential and already exists, prompt needs to be [text_prompt, audio_file_ref]\n",
        "    # The retry wrapper needs to support passing pre-uploaded file objects.\n",
        "    # For now, let's assume the model can work very well with detailed text prompt and transcription.\n",
        "    # If the audio file itself *must* be re-sent for summarization, we'd need the path.\n",
        "    # Let's assume the transcription is rich enough for the text-based summarization models (Pro)\n",
        "    # and if we need multimodal summary, we'd pass the audio file path again.\n",
        "\n",
        "    # Current summarization prompt is text-based but uses transcription for context.\n",
        "    # If we want the model to *listen* again, we pass the audio_file_ref.\n",
        "    # The prompt implies both audio and text are provided.\n",
        "\n",
        "    # Simplification: For now, the `summarize_audio_google` will use the transcription text.\n",
        "    # If the `audio_file_ref` is to be used, `gemini_request_with_retry` needs modification\n",
        "    # to accept `genai.File` objects directly in `prompt_parts` without re-uploading.\n",
        "    # Let's assume for detailed summary, a powerful model can work from transcription.\n",
        "    # If we must use the audio file reference:\n",
        "    # prompt_parts = [summary_prompt_formatted, audio_file_ref_for_context]\n",
        "    # And `gemini_request_with_retry` would need to handle this case.\n",
        "\n",
        "    # For now, using text-only summarization with transcription as primary input:\n",
        "      summary_text, _ = await gemini_request_with_retry(\n",
        "        task_name=\"DetailedSummarization\",\n",
        "        model_preference_key=\"summarization_detailed\",\n",
        "        prompt_parts=[summary_prompt_formatted],\n",
        "        generation_config_key=\"summarization_detailed\",\n",
        "        file_path_to_upload=None # Or pass audio_file_ref_for_context if retry wrapper is adapted\n",
        "    )\n",
        "\n",
        "\n",
        "    # To use the audio_file_ref with the current retry wrapper, we'd effectively need to \"re-upload\" it logically\n",
        "    # or the wrapper needs to accept genai.File objects.\n",
        "    # Let's adapt the prompt_parts for summarize_audio_google specifically.\n",
        "    # The `gemini_request_with_retry` will have to be smart.\n",
        "    # If `file_path_to_upload` is a `genai.File` object, use it directly.\n",
        "\n",
        "    # --- REVISED APPROACH for summarize_audio_google to use existing file ref ---\n",
        "    # This requires `gemini_request_with_retry` to handle `file_path_to_upload` being a `genai.File` object.\n",
        "    # Let's assume `gemini_request_with_retry` is NOT changed for now, and we pass audio file path if needed.\n",
        "    # The original logic was: model.generate_content([summary_prompt, audio_file_ref])\n",
        "    # The simplest for now is to use the transcription for the detailed summary,\n",
        "    # relying on a strong Pro model.\n",
        "\n",
        "    if not summary:\n",
        "        raise ValueError(\"Summarization failed: No text returned after retries.\")\n",
        "    return \"\\u200F\" + summary_text\n",
        "\n",
        "\n",
        "async def translate_to_persian_google(text):\n",
        "    if not text or not text.strip(): return \"\"\n",
        "    logger.info(\"Translating text to Persian...\")\n",
        "    prompt = f'Translate the following text to Persian:\\n\\n\"{text}\"\\n\\nReturn ONLY the Persian translation, with no introductory phrases.'\n",
        "    translation, _ = await gemini_request_with_retry(\n",
        "        task_name=\"TranslationToPersian\",\n",
        "        model_preference_key=\"translation_segmentation\",\n",
        "        prompt_parts=[prompt],\n",
        "        generation_config_key=\"translation_segmentation\"\n",
        "    )\n",
        "    if not translation:\n",
        "        raise ValueError(\"Translation failed: No text returned.\")\n",
        "    return translation\n",
        "\n",
        "async def segment_persian_text_google(persian_text):\n",
        "    logger.info(\"Segmenting Persian text for SRT...\")\n",
        "    segmentation_prompt = f\"\"\"Take the following Persian text and break it into suitable subtitle segments. Each segment should be on a new line. Aim for natural breaks and readable lengths for subtitles (typically 1-2 short sentences or phrases).\n",
        "Return ONLY the segmented text, with each segment on a new line. Do not add numbering.\n",
        "Persian text:\n",
        "---\n",
        "{persian_text}\n",
        "---\"\"\"\n",
        "    segmented_text, _ = await gemini_request_with_retry(\n",
        "        task_name=\"TextSegmentation\",\n",
        "        model_preference_key=\"translation_segmentation\",\n",
        "        prompt_parts=[segmentation_prompt],\n",
        "        generation_config_key=\"translation_segmentation\"\n",
        "    )\n",
        "    if not segmented_text:\n",
        "        logger.warning(\"LLM Segmentation response was empty. Using regex fallback.\")\n",
        "        segments = re.split(r'[à¥¤\\.ØŸ!\\n]+', persian_text)\n",
        "        segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "        if not segmented_text: raise ValueError(\"Segmentation failed: No text from LLM or fallback.\")\n",
        "    return segmented_text\n",
        "\n",
        "async def generate_persian_srt_google(transcription):\n",
        "    logger.info(\"Generating Persian SRT...\")\n",
        "    try:\n",
        "        # For SRT, a direct, less \"creative\" translation might be better than a highly contextual one.\n",
        "        # However, for now, using the same translation function.\n",
        "        persian_translation = await translate_to_persian_google(transcription)\n",
        "        if not persian_translation: raise ValueError(\"Translation step failed for SRT.\")\n",
        "\n",
        "        segmented_persian_text = await segment_persian_text_google(persian_translation)\n",
        "        if not segmented_persian_text: raise ValueError(\"Segmentation step failed for SRT.\")\n",
        "\n",
        "        srt_content = generate_srt_with_timecodes(segmented_persian_text)\n",
        "        logger.info(\"SRT generation successful.\")\n",
        "        return srt_content\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating SRT: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def get_bot_response_google(message_text):\n",
        "    logger.info(f\"Getting bot response for: {message_text[:50]}...\")\n",
        "    prompt = f\"\"\"You are LinguaScribe_Bot, a helpful Telegram assistant. The user's language is Persian.\n",
        "User says: \"{message_text}\"\n",
        "Provide a concise and helpful response in Persian.\n",
        "If they ask about your capabilities, mention:\n",
        "- Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† (Audio transcription)\n",
        "- Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø§Ù…Ø¹ Ùˆ ØªØ®ØµØµÛŒ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ (Detailed audio summarization for study/prep)\n",
        "- ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ (Persian SRT subtitle generation)\n",
        "- Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ZIP Ø­Ø§ÙˆÛŒ ØµÙˆØª ÛŒØ§ Ù…ØªÙ† (Processing ZIP files with audio/text)\n",
        "- ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ ØµÙˆØª Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ (Video to audio conversion for processing)\n",
        "\n",
        "Keep responses brief. If the input is non-sensical or just a greeting, respond politely and briefly in Persian.\n",
        "Return ONLY the bot's reply in Persian.\n",
        "\"\"\"\n",
        "    reply, _ = await gemini_request_with_retry(\n",
        "        task_name=\"BotResponse\",\n",
        "        model_preference_key=\"bot_response\",\n",
        "        prompt_parts=[prompt],\n",
        "        generation_config_key=\"bot_response\"\n",
        "    )\n",
        "    if not reply:\n",
        "        return \"Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‚Ø§Ø¯Ø± Ø¨Ù‡ Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ù†ÛŒØ³ØªÙ….\"\n",
        "    return reply\n",
        "\n",
        "# --- Core Media Processing Logic ---\n",
        "\n",
        "async def process_single_audio_file_operations(\n",
        "    audio_file_path: str,\n",
        "    original_name_base: str,\n",
        "    chat_id: int,\n",
        "    processing_msg_event,\n",
        "    is_part_of_long_audio=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Processes a single audio file (or a chunk of a longer one).\n",
        "    Returns transcription, path to transcription file, path to SRT file, and the Google uploaded file reference.\n",
        "    \"\"\"\n",
        "    files_to_cleanup_later = []\n",
        "    google_audio_file_ref = None\n",
        "    transcription = \"\"\n",
        "    transcription_path_str = None\n",
        "    srt_path_str = None\n",
        "\n",
        "    try:\n",
        "        # 1. Transcription\n",
        "        await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†...\")\n",
        "        transcription, google_audio_file_ref = await transcribe_audio_google(audio_file_path)\n",
        "        files_to_cleanup_later.append(audio_file_path) # Original/converted audio chunk\n",
        "\n",
        "        transcription_filename = f\"{original_name_base}_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcription)\n",
        "        transcription_path_str = str(transcription_path)\n",
        "        files_to_cleanup_later.append(transcription_path_str)\n",
        "\n",
        "        await client.send_file(chat_id, transcription_path_str, caption=\"ğŸ¤ Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:\")\n",
        "        await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\nâœ… Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        # 2. SRT Generation (only if not part of a larger audio being processed, or do it per chunk too?)\n",
        "        # For long audio, SRT is generated for the full combined text later.\n",
        "        if not is_part_of_long_audio:\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT)...\")\n",
        "            srt_content = await generate_persian_srt_google(transcription)\n",
        "            srt_filename = f\"{original_name_base}_subtitles.srt\"\n",
        "            srt_path = TEMP_DIR / srt_filename\n",
        "            with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(srt_content)\n",
        "            srt_path_str = str(srt_path)\n",
        "            files_to_cleanup_later.append(srt_path_str)\n",
        "            await client.send_file(chat_id, srt_path_str, caption=\"ğŸ¬ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT):\")\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\nâœ… ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT) Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        # Summary is done after all chunks are processed for long audio.\n",
        "        # For single short audio, summary is done here.\n",
        "        if not is_part_of_long_audio:\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙ‡ÛŒÙ‡ Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹...\")\n",
        "            # For summary, we need the audio_file_ref if the model uses multimodal input.\n",
        "            # The `summarize_audio_google` currently uses text-based approach with transcription.\n",
        "            # If it were to use the audio file, we'd pass `google_audio_file_ref`.\n",
        "            summary = await summarize_audio_google(google_audio_file_ref, transcription)\n",
        "            summary_filename = f\"{original_name_base}_summary.md\" # Save as markdown\n",
        "            summary_path = TEMP_DIR / summary_filename\n",
        "            with open(summary_path, \"w\", encoding=\"utf-8\") as f: f.write(summary)\n",
        "            files_to_cleanup_later.append(str(summary_path))\n",
        "\n",
        "            await client.send_file(chat_id, str(summary_path), caption=\"ğŸ“ *Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ù…Ø­ØªÙˆØ§:*\", parse_mode='md')\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\nâœ… Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "            await client.edit_message(processing_msg_event, \"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\")\n",
        "\n",
        "        return transcription, transcription_path_str, srt_path_str, google_audio_file_ref, files_to_cleanup_later\n",
        "\n",
        "    except genai.types.BlockedPromptException as bpe:\n",
        "        logger.error(f\"Processing stopped due to blocked prompt: {bpe}\", exc_info=True)\n",
        "        await client.edit_message(processing_msg_event, f\"âŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙˆÙ‚Ù Ø´Ø¯. Ù…Ø­ØªÙˆØ§ÛŒ Ø§Ø±Ø³Ø§Ù„ÛŒ Ø¨Ø§ Ø³ÛŒØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ…Ù†ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø± Ù†ÛŒØ³Øª.\")\n",
        "        # Do not delete uploaded_file_ref here, it's managed by Google\n",
        "        return None, None, None, google_audio_file_ref, files_to_cleanup_later # google_audio_file_ref might be None if upload failed\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_single_audio_file_operations for {original_name_base}: {e}\")\n",
        "        await client.edit_message(processing_msg_event, f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ({original_name_base}): {str(e)[:100]}\")\n",
        "        return None, None, None, google_audio_file_ref, files_to_cleanup_later\n",
        "\n",
        "\n",
        "async def process_audio_file(event, audio_file_path: str, original_name_base: str, chat_id: int, processing_msg_event):\n",
        "    \"\"\"Handles splitting if necessary, then processes audio, generates summary and SRT for the whole.\"\"\"\n",
        "    all_local_files_to_cleanup = [audio_file_path] # Start with the input audio path\n",
        "    # google_uploaded_file_refs are not cleaned by us, Google manages them.\n",
        "\n",
        "    try:\n",
        "        audio_duration_ms = await get_audio_duration(audio_file_path)\n",
        "        needs_splitting = audio_duration_ms > MAX_DURATION_MS\n",
        "\n",
        "        chunk_paths = []\n",
        "        if needs_splitting:\n",
        "            await client.edit_message(\n",
        "                processing_msg_event,\n",
        "                f\"âš ï¸ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø´Ù…Ø§ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø³Øª ({audio_duration_ms/60000:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡). Ø¯Ø± Ø­Ø§Ù„ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª ~{MAX_DURATION_MINUTES} Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´...\"\n",
        "            )\n",
        "            chunk_paths = await split_audio_file(audio_file_path, original_name_base, MAX_DURATION_MS)\n",
        "            all_local_files_to_cleanup.extend(chunk_paths)\n",
        "            if audio_file_path in chunk_paths: # If not split, original path is the only \"chunk\"\n",
        "                 pass # original audio_file_path is already in all_local_files_to_cleanup\n",
        "            elif audio_file_path not in chunk_paths and chunk_paths: # Original was split\n",
        "                # The original large file (audio_file_path) is implicitly cleaned if split_audio_file creates new files from it.\n",
        "                # If split_audio_file returns the original path (no split), it's handled.\n",
        "                pass\n",
        "\n",
        "\n",
        "        else:\n",
        "            logger.info(f\"Audio duration ({audio_duration_ms/60000:.2f} min) is under threshold, processing as single unit.\")\n",
        "            chunk_paths = [audio_file_path] # Process the original file as a single chunk\n",
        "\n",
        "        full_transcription_parts = []\n",
        "        # We need one audio_file_ref for the final summary if it's multimodal.\n",
        "        # Let's use the ref from the first chunk.\n",
        "        first_chunk_google_ref = None\n",
        "\n",
        "        for i, chunk_path in enumerate(chunk_paths):\n",
        "            chunk_name_base = f\"{original_name_base}_part{i+1}\" if needs_splitting else original_name_base\n",
        "            await client.edit_message(\n",
        "                processing_msg_event,\n",
        "                processing_msg_event.text + f\"\\n\\nProcessing chunk {i+1}/{len(chunk_paths)}: {Path(chunk_path).name}\"\n",
        "            )\n",
        "\n",
        "            transcription, _, _, google_ref, chunk_cleanup_files = await process_single_audio_file_operations(\n",
        "                audio_file_path=chunk_path,\n",
        "                original_name_base=chunk_name_base,\n",
        "                chat_id=chat_id,\n",
        "                processing_msg_event=processing_msg_event,\n",
        "                is_part_of_long_audio=needs_splitting # True if there are multiple chunks\n",
        "            )\n",
        "            all_local_files_to_cleanup.extend(chunk_cleanup_files)\n",
        "\n",
        "            if transcription:\n",
        "                full_transcription_parts.append(transcription)\n",
        "                if i == 0 and google_ref: # Save ref from first chunk\n",
        "                    first_chunk_google_ref = google_ref\n",
        "            else:\n",
        "                # If a chunk fails, we might stop or continue. For now, continue.\n",
        "                logger.warning(f\"Chunk {i+1} ({Path(chunk_path).name}) failed transcription. Skipping for combined output.\")\n",
        "                await client.edit_message(processing_msg_event, processing_msg_event.text + f\"\\nâš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‚Ø·Ø¹Ù‡ {i+1} Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "\n",
        "\n",
        "        if not full_transcription_parts:\n",
        "            await client.edit_message(processing_msg_event, \"âŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡ÛŒÚ† Ø¨Ø®Ø´ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÛŒØ² Ù†Ø¨ÙˆØ¯.\")\n",
        "            return # Early exit\n",
        "\n",
        "        full_transcription = \"\\n\\n\".join(full_transcription_parts)\n",
        "        full_transcription_filename = f\"{original_name_base}_FULL_transcription.txt\"\n",
        "        full_transcription_path = TEMP_DIR / full_transcription_filename\n",
        "        with open(full_transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(full_transcription)\n",
        "        all_local_files_to_cleanup.append(str(full_transcription_path))\n",
        "\n",
        "        if needs_splitting: # If it was split, send the full transcription\n",
        "            await client.send_file(chat_id, str(full_transcription_path), caption=\"ğŸ¤ Ù…ØªÙ† Ú©Ø§Ù…Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ (Ø§Ø² ØªÙ…Ø§Ù…ÛŒ Ù‚Ø·Ø¹Ø§Øª):\")\n",
        "\n",
        "        # Generate combined SRT and Summary if multiple chunks were processed OR if it was single file not processed by `is_part_of_long_audio=False` path\n",
        "        if needs_splitting: # For long audio, generate combined SRT and summary now\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT) Ú©Ø§Ù…Ù„...\")\n",
        "            combined_srt_content = await generate_persian_srt_google(full_transcription)\n",
        "            combined_srt_filename = f\"{original_name_base}_FULL_subtitles.srt\"\n",
        "            combined_srt_path = TEMP_DIR / combined_srt_filename\n",
        "            with open(combined_srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(combined_srt_content)\n",
        "            all_local_files_to_cleanup.append(str(combined_srt_path))\n",
        "            await client.send_file(chat_id, str(combined_srt_path), caption=\"ğŸ¬ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ú©Ø§Ù…Ù„ (SRT):\")\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\nâœ… ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ú©Ø§Ù…Ù„ (SRT) Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙ‡ÛŒÙ‡ Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ú©Ø§Ù…Ù„...\")\n",
        "            # Use transcription of all parts. If multimodal summary is desired, use first_chunk_google_ref\n",
        "            combined_summary = await summarize_audio_google(first_chunk_google_ref, full_transcription) # Pass ref if summarize_audio_google is adapted\n",
        "\n",
        "            summary_filename = f\"{original_name_base}_FULL_summary.md\"\n",
        "            summary_path = TEMP_DIR / summary_filename\n",
        "            with open(summary_path, \"w\", encoding=\"utf-8\") as f: f.write(combined_summary)\n",
        "            all_local_files_to_cleanup.append(str(summary_path))\n",
        "\n",
        "            await client.send_file(chat_id, str(summary_path), caption=\"ğŸ“ *Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„:*\", parse_mode='md')\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\nâœ… Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ú©Ø§Ù…Ù„ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        final_message = \"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„\"\n",
        "        if needs_splitting: final_message += f\" ØµÙˆØªÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ ({audio_duration_ms/60000:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡)\"\n",
        "        final_message += \" Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\"\n",
        "        await client.edit_message(processing_msg_event, final_message)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Critical error in process_audio_file for {original_name_base}: {e}\")\n",
        "        await client.edit_message(processing_msg_event, f\"âŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ: {str(e)[:100]}\")\n",
        "    finally:\n",
        "        # Cleanup all local temporary files accumulated\n",
        "        unique_cleanup_paths = list(set(all_local_files_to_cleanup)) # Remove duplicates\n",
        "        await cleanup_files_and_dirs(*unique_cleanup_paths)\n",
        "\n",
        "\n",
        "# --- Main Bot Event Handlers ---\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/start'))\n",
        "async def start(event):\n",
        "    sender = await event.get_sender()\n",
        "    logger.info(f\"/start from User {sender.id} in Chat {event.chat_id}\")\n",
        "    await event.reply(\n",
        "        \"ğŸ‘‹ Ø³Ù„Ø§Ù…! Ø¨Ù‡ Ø±Ø¨Ø§Øª *LinguaScribe* Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯.\\n\\n\"\n",
        "        \"Ø§ÛŒÙ† Ø±Ø¨Ø§Øª Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒØŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ ÛŒØ§ ZIP Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†Ø¯:\\n\"\n",
        "        \"ğŸ¤ **Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¯Ù‚ÛŒÙ‚**\\n\"\n",
        "        \"ğŸ“ **Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø§Ù…Ø¹ Ùˆ ØªØ®ØµØµÛŒ** (Ù…Ù†Ø§Ø³Ø¨ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ø¢Ø²Ù…ÙˆÙ†)\\n\"\n",
        "        \"ğŸ¬ **ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT ÙØ§Ø±Ø³ÛŒ**\\n\"\n",
        "        \"ğŸ“¹ **ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ ØµÙˆØª** Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„\\n\"\n",
        "        \"ğŸ—œï¸ **Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ZIP** Ø­Ø§ÙˆÛŒ ØµÙˆØª ÛŒØ§ Ù…ØªÙ†\\n\\n\"\n",
        "        \"ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ (voice, audio), ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ, ÛŒØ§ ÙØ§ÛŒÙ„ ZIP Ø¨Ø±Ø§ÛŒ Ù…Ù† Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/help'))\n",
        "async def help_command(event):\n",
        "    await event.reply(\n",
        "        \"ğŸ” **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ LinguaScribe Bot**\\n\\n\"\n",
        "        \"1ï¸âƒ£ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒØŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒØŒ ÛŒØ§ ZIP Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "        \"2ï¸âƒ£ Ø±Ø¨Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¢Ù† Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\\n\"\n",
        "        \"   - ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ ØµÙˆØª ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\\n\"\n",
        "        \"   - ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ZIP Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡ (ØµÙˆØª/Ù…ØªÙ†) Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\\n\"\n",
        "        \"   - Ø¨Ø±Ø§ÛŒ ØµÙˆØª: Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒØŒ Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ØŒ Ùˆ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\\n\"\n",
        "        \"   - Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† (Ø§Ø² ZIP): Ù…Ø­ØªÙˆØ§ ØªØ±Ú©ÛŒØ¨ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\\n\\n\"\n",
        "        \"ğŸ“‹ **Ù†Ú©Ø§Øª**:\\n\"\n",
        "        f\"â€¢ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ ØªØ§ {MAX_DURATION_MINUTES} Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ©Ø¬Ø§ØŒ Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ± Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø®Ø´â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\\n\"\n",
        "        \"â€¢ Ø²Ø¨Ø§Ù† Ø§ØµÙ„ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª.\\n\\n\"\n",
        "        \"ğŸ“Œ **Ø¯Ø³ØªÙˆØ±Ø§Øª:** /start, /help\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.text and not e.text.startswith('/')))\n",
        "async def handle_text_message(event):\n",
        "    chat_id = event.chat_id\n",
        "    message_text = event.text\n",
        "    logger.info(f\"Text message in chat {chat_id}: {message_text[:50]}...\")\n",
        "    processing_msg = await event.reply(\"â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ø´Ù…Ø§...\")\n",
        "    try:\n",
        "        bot_response = await get_bot_response_google(message_text)\n",
        "        await client.edit_message(processing_msg, bot_response)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling text message: {e}\", exc_info=True)\n",
        "        await client.edit_message(processing_msg, \"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ø´Ù…Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯.\")\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.audio or e.voice or e.document))\n",
        "async def handle_media_message(event):\n",
        "    chat_id = event.chat_id\n",
        "    sender = await event.get_sender()\n",
        "    message_id = event.message.id\n",
        "    logger.info(f\"Media from User {sender.id} (msg_id:{message_id}) in Chat {chat_id}\")\n",
        "\n",
        "    media_item = None\n",
        "    file_name_attr = None\n",
        "    mime_type_attr = None\n",
        "    media_type_for_log = \"unknown\"\n",
        "\n",
        "    if event.audio:\n",
        "        media_item = event.audio\n",
        "        media_type_for_log = \"audio\"\n",
        "        mime_type_attr = getattr(media_item, 'mime_type', 'audio/ogg') # Default if not present\n",
        "        file_name_attr = getattr(media_item, 'attributes', [{}])[0].file_name if media_item.attributes and hasattr(media_item.attributes[0], 'file_name') else f\"audio_{message_id}.{mime_type_attr.split('/')[-1]}\"\n",
        "    elif event.voice:\n",
        "        media_item = event.voice\n",
        "        media_type_for_log = \"voice\"\n",
        "        mime_type_attr = getattr(media_item, 'mime_type', 'audio/ogg')\n",
        "        file_name_attr = f\"voice_{message_id}.ogg\"\n",
        "    elif event.document:\n",
        "        media_item = event.document\n",
        "        mime_type_attr = getattr(media_item, 'mime_type', '')\n",
        "        file_name_attr = getattr(media_item, 'attributes', [{}])[0].file_name if media_item.attributes and hasattr(media_item.attributes[0], 'file_name') else f\"document_{message_id}\"\n",
        "\n",
        "        if mime_type_attr.startswith('audio/'):\n",
        "            media_type_for_log = \"document_audio\"\n",
        "        elif mime_type_attr.startswith('video/'):\n",
        "            media_type_for_log = \"document_video\"\n",
        "        elif mime_type_attr in ['application/zip', 'application/x-zip-compressed'] or file_name_attr.lower().endswith('.zip'):\n",
        "            media_type_for_log = \"document_zip\"\n",
        "        else:\n",
        "            await event.reply(\"âš ï¸ Ø§ÛŒÙ† Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ ØªÙˆØ³Ø· Ø±Ø¨Ø§Øª Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒØŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ ÛŒØ§ ZIP Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "            return\n",
        "    else: # Should not happen given the func filter, but as a safeguard\n",
        "        return\n",
        "\n",
        "    processing_msg = await event.reply(\"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„...\")\n",
        "\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    original_name_base = Path(file_name_attr).stem\n",
        "    # Use a generic download name, actual format determined later\n",
        "    download_path_initial = TEMP_DIR / f\"{original_name_base}_{timestamp}{Path(file_name_attr).suffix or '.dat'}\"\n",
        "\n",
        "    local_files_to_cleanup_main_handler = [str(download_path_initial)]\n",
        "\n",
        "    try:\n",
        "        await client.download_media(message=event.message, file=str(download_path_initial))\n",
        "        logger.info(f\"File {file_name_attr} ({media_type_for_log}) downloaded to {download_path_initial}\")\n",
        "        await client.edit_message(processing_msg, \"âœ… ÙØ§ÛŒÙ„ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ÙˆÙ„ÛŒÙ‡...\")\n",
        "\n",
        "        # --- ZIP File Handling ---\n",
        "        if media_type_for_log == \"document_zip\":\n",
        "            await client.edit_message(processing_msg, processing_msg.text + \"\\nğŸ—œï¸ ÙØ§ÛŒÙ„ ZIP Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ØŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬...\")\n",
        "            extraction_path = TEMP_EXTRACTION_DIR / f\"{original_name_base}_{timestamp}_extracted\"\n",
        "            extraction_path.mkdir(parents=True, exist_ok=True)\n",
        "            local_files_to_cleanup_main_handler.append(str(extraction_path)) # ensure extracted dir is cleaned\n",
        "\n",
        "            extracted_files_info = []\n",
        "            try:\n",
        "                with zipfile.ZipFile(download_path_initial, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(extraction_path)\n",
        "                logger.info(f\"ZIP extracted to {extraction_path}\")\n",
        "\n",
        "                # Process extracted files\n",
        "                combined_text_content = []\n",
        "                audio_files_in_zip = []\n",
        "\n",
        "                for item in extraction_path.rglob('*'): # Recurse through subdirectories\n",
        "                    if item.is_file():\n",
        "                        item_name_base = item.stem\n",
        "                        item_suffix_lower = item.suffix.lower()\n",
        "\n",
        "                        # Check for audio types\n",
        "                        if item_suffix_lower in ['.mp3', '.wav', '.ogg', '.m4a', '.opus', '.flac', '.aac']:\n",
        "                            audio_files_in_zip.append(item)\n",
        "                        # Check for text types\n",
        "                        elif item_suffix_lower in ['.txt', '.md', '.rtf']: # Add more text types if needed\n",
        "                            try:\n",
        "                                combined_text_content.append(item.read_text(encoding='utf-8'))\n",
        "                                logger.info(f\"Read text from {item.name}\")\n",
        "                            except Exception as e:\n",
        "                                logger.warning(f\"Could not read text file {item.name}: {e}\")\n",
        "\n",
        "                if audio_files_in_zip:\n",
        "                    await client.edit_message(processing_msg, processing_msg.text + f\"\\nğŸ”Š {len(audio_files_in_zip)} ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¯Ø± ZIP ÛŒØ§ÙØª Ø´Ø¯. Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¢Ù†â€ŒÙ‡Ø§...\")\n",
        "                    for i, audio_item_path in enumerate(audio_files_in_zip):\n",
        "                        zip_audio_name_base = f\"{original_name_base}_zip_audio{i+1}_{audio_item_path.stem}\"\n",
        "                        # Create a new processing message for each audio file to avoid super long message\n",
        "                        audio_proc_msg = await event.reply(f\"â³ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ {i+1}/{len(audio_files_in_zip)} Ø§Ø² ZIP: {audio_item_path.name}\")\n",
        "                        await process_audio_file(event, str(audio_item_path), zip_audio_name_base, chat_id, audio_proc_msg)\n",
        "                        # Don't add audio_item_path to local_files_to_cleanup_main_handler, process_audio_file handles its copies/chunks.\n",
        "                        # The extraction_path itself will be cleaned, removing all original extracted files.\n",
        "\n",
        "                if combined_text_content:\n",
        "                    full_extracted_text = \"\\n\\n---\\n\\n\".join(combined_text_content)\n",
        "                    text_output_filename = f\"{original_name_base}_extracted_texts.txt\"\n",
        "                    text_output_path = TEMP_DIR / text_output_filename\n",
        "                    with open(text_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(full_extracted_text)\n",
        "                    local_files_to_cleanup_main_handler.append(str(text_output_path))\n",
        "                    await client.send_file(chat_id, str(text_output_path), caption=\"ğŸ“œ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ ZIP:\")\n",
        "                    await client.edit_message(processing_msg, processing_msg.text + \"\\nğŸ“œ Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÛŒ Ø§Ø² ZIP Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "                if not audio_files_in_zip and not combined_text_content:\n",
        "                     await client.edit_message(processing_msg, processing_msg.text + \"\\nâš ï¸ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÛŒØ§ Ù…ØªÙ†ÛŒ Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ø¯Ø± ZIP ÛŒØ§ÙØª Ù†Ø´Ø¯.\")\n",
        "                else:\n",
        "                     await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ÛŒ ZIP ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯.\")\n",
        "\n",
        "            except zipfile.BadZipFile:\n",
        "                logger.error(f\"Bad ZIP file: {download_path_initial}\")\n",
        "                await client.edit_message(processing_msg, \"âŒ ÙØ§ÛŒÙ„ ZIP Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing ZIP file: {e}\", exc_info=True)\n",
        "                await client.edit_message(processing_msg, f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ZIP: {e}\")\n",
        "            return # End of ZIP processing\n",
        "\n",
        "        # --- Video to Audio Conversion ---\n",
        "        actual_audio_file_to_process = download_path_initial\n",
        "        if media_type_for_log.startswith(\"document_video\") or mime_type_attr.startswith(\"video/\"):\n",
        "            await client.edit_message(processing_msg, processing_msg.text + \"\\nğŸ“¹ ÙØ§ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ØŒ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ØµÙˆØª ÙØ´Ø±Ø¯Ù‡...\")\n",
        "            converted_audio_path = TEMP_DIR / f\"{original_name_base}_{timestamp}_converted.{AUDIO_OUTPUT_FORMAT}\"\n",
        "            try:\n",
        "                video_segment = AudioSegment.from_file(str(download_path_initial))\n",
        "                audio_only = video_segment.set_channels(1).set_frame_rate(AUDIO_SAMPLE_RATE)\n",
        "                audio_only.export(\n",
        "                    str(converted_audio_path),\n",
        "                    format=AUDIO_OUTPUT_FORMAT,\n",
        "                    codec=AUDIO_OUTPUT_CODEC if AUDIO_OUTPUT_FORMAT == \"ogg\" else None,\n",
        "                    bitrate=AUDIO_OUTPUT_BITRATE\n",
        "                )\n",
        "                actual_audio_file_to_process = converted_audio_path\n",
        "                local_files_to_cleanup_main_handler.append(str(converted_audio_path)) # Add converted file for cleanup\n",
        "                logger.info(f\"Video converted to audio: {converted_audio_path}\")\n",
        "                await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ ØµÙˆØª ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯.\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error converting video to audio: {e}\", exc_info=True)\n",
        "                await client.edit_message(processing_msg, f\"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ ØµÙˆØª: {e}. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ (Ø§Ú¯Ø± ØµÙˆØª Ø¨Ø§Ø´Ø¯)...\")\n",
        "                # Fallback to actual_audio_file_to_process = download_path_initial if conversion fails\n",
        "                # but it might not be an audio file. For now, we assume it fails cleanly if not convertible.\n",
        "                if not mime_type_attr.startswith('audio/'): # If original was not audio, then fail\n",
        "                     await client.edit_message(processing_msg, processing_msg.text + \"\\nâŒ ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ ÙˆÛŒØ¯ÛŒÙˆ Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØµÙˆØª Ù†ÛŒØ³Øª.\")\n",
        "                     return\n",
        "\n",
        "        # --- Audio Processing (Original Audio, Document Audio, or Converted Video) ---\n",
        "        if media_type_for_log.startswith(\"audio\") or media_type_for_log.startswith(\"voice\") or \\\n",
        "           media_type_for_log.startswith(\"document_audio\") or actual_audio_file_to_process != download_path_initial: # i.e. video was converted\n",
        "\n",
        "            # Ensure the file is in a format pydub can handle well for duration check and potential re-encoding/splitting\n",
        "            # Re-encoding to a standard format (like ogg opus) can help.\n",
        "            standardized_audio_path = TEMP_DIR / f\"{Path(actual_audio_file_to_process).stem}_standardized.{AUDIO_OUTPUT_FORMAT}\"\n",
        "            try:\n",
        "                audio_seg = AudioSegment.from_file(str(actual_audio_file_to_process))\n",
        "                # Standardize: mono, 16kHz, ogg opus\n",
        "                audio_seg = audio_seg.set_channels(1).set_frame_rate(AUDIO_SAMPLE_RATE)\n",
        "                audio_seg.export(\n",
        "                    str(standardized_audio_path),\n",
        "                    format=AUDIO_OUTPUT_FORMAT,\n",
        "                    codec=AUDIO_OUTPUT_CODEC if AUDIO_OUTPUT_FORMAT == \"ogg\" else None,\n",
        "                    bitrate=AUDIO_OUTPUT_BITRATE\n",
        "                )\n",
        "                logger.info(f\"Audio standardized to: {standardized_audio_path}\")\n",
        "                if str(actual_audio_file_to_process) != str(download_path_initial): # if it was converted video\n",
        "                    local_files_to_cleanup_main_handler.append(str(actual_audio_file_to_process)) # The intermediate converted video audio\n",
        "                actual_audio_file_to_process = standardized_audio_path\n",
        "                local_files_to_cleanup_main_handler.append(str(standardized_audio_path))\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Could not standardize audio {actual_audio_file_to_process}: {e}. Proceeding with original/converted.\")\n",
        "                # actual_audio_file_to_process remains as it was\n",
        "\n",
        "            await process_audio_file(event, str(actual_audio_file_to_process), original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # If it was just a document that wasn't audio, video, or zip, it would have been filtered earlier.\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Unhandled error in handle_media_message for {file_name_attr}: {e}\")\n",
        "        try:\n",
        "            await client.edit_message(processing_msg, \"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ ÛŒÚ© Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "        except: # If editing message fails (e.g., message deleted)\n",
        "            pass\n",
        "    finally:\n",
        "        # General cleanup for files created directly in this handler (like initial download)\n",
        "        # Files created by sub-processors (process_audio_file) are cleaned by them.\n",
        "        unique_cleanup_paths_main = list(set(local_files_to_cleanup_main_handler))\n",
        "        await cleanup_files_and_dirs(*unique_cleanup_paths_main)\n",
        "        # Clean the entire extraction base dir if it was used\n",
        "        if TEMP_EXTRACTION_DIR.exists():\n",
        "            await cleanup_files_and_dirs(TEMP_EXTRACTION_DIR)\n",
        "            TEMP_EXTRACTION_DIR.mkdir(parents=True, exist_ok=True) # Recreate for next use\n",
        "\n",
        "\n",
        "# --- Main Entry Point ---\n",
        "async def main():\n",
        "    logger.info(\"Starting LinguaScribe Bot...\")\n",
        "\n",
        "    # Clear temp directory at startup (robustly)\n",
        "    if TEMP_DIR.exists():\n",
        "        try:\n",
        "            shutil.rmtree(TEMP_DIR)\n",
        "            logger.info(f\"Cleaned up old temp directory: {TEMP_DIR}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error cleaning up temp directory {TEMP_DIR} at startup: {e}\")\n",
        "    TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    TEMP_EXTRACTION_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "    await client.start(bot_token=BOT_TOKEN)\n",
        "    me = await client.get_me()\n",
        "    logger.info(f\"Bot @{me.username} started successfully!\")\n",
        "    logger.info(f\"Using {len(GOOGLE_API_KEYS_LIST)} Google API Key(s).\")\n",
        "    logger.info(f\"Initial Google API Key: ...{_active_google_api_key[-4:] if _active_google_api_key else 'N/A'}\")\n",
        "\n",
        "    try:\n",
        "        await client.run_until_disconnected()\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"Bot stopped by user (Ctrl+C)\")\n",
        "    finally:\n",
        "        await client.disconnect()\n",
        "        logger.info(\"Bot disconnected.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ],
      "metadata": {
        "id": "Bnmj3r78OGC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The old code for one job only:\n",
        "## it do transcribe and get text srt and summary"
      ],
      "metadata": {
        "id": "I8_WmnPRSWoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS1cE8WIGs_O",
        "outputId": "0bc9e696-78cd-46ff-b0de-dff48d1c7188"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Error during translation: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 306, in translate_to_persian_google\n",
            "    translation = response.text.strip()\n",
            "                  ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 463, in text\n",
            "    parts = self.parts\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 446, in parts\n",
            "    raise ValueError(msg)\n",
            "ValueError: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "ERROR:__main__:Error generating SRT: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 347, in generate_persian_srt_google\n",
            "    persian_translation = await translate_to_persian_google(transcription)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 306, in translate_to_persian_google\n",
            "    translation = response.text.strip()\n",
            "                  ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 463, in text\n",
            "    parts = self.parts\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 446, in parts\n",
            "    raise ValueError(msg)\n",
            "ValueError: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "ERROR:__main__:Error in process_long_audio: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 438, in process_long_audio\n",
            "    srt_content = await generate_persian_srt_google(full_transcription)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 347, in generate_persian_srt_google\n",
            "    persian_translation = await translate_to_persian_google(transcription)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 306, in translate_to_persian_google\n",
            "    translation = response.text.strip()\n",
            "                  ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 463, in text\n",
            "    parts = self.parts\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 446, in parts\n",
            "    raise ValueError(msg)\n",
            "ValueError: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import re\n",
        "import math\n",
        "from telethon import TelegramClient, events, Button\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from pydub import AudioSegment  # New import for audio processing\n",
        "\n",
        "# --- Configuration ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    API_ID = int(userdata.get('TELEGRAM_API_ID'))\n",
        "    API_HASH = userdata.get('TELEGRAM_API_HASH')\n",
        "    BOT_TOKEN = userdata.get('TELEGRAM_BOT_TTS')\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY1')  # Main key\n",
        "    GOOGLE_SUMMARY_API_KEY = userdata.get('GOOGLE_SUMMARY_API_KEY')  # Specific key for summaries\n",
        "\n",
        "    if not all([API_ID, API_HASH, BOT_TOKEN, GOOGLE_API_KEY, GOOGLE_SUMMARY_API_KEY]):\n",
        "        raise ValueError(\"One or more secrets are missing.\")\n",
        "    if GOOGLE_API_KEY == GOOGLE_SUMMARY_API_KEY:\n",
        "        print(\"Main Google API Key and Summary API Key are the same. No key switching needed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading secrets: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Apply nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Initial Google AI SDK Configuration (with the MAIN key) ---\n",
        "try:\n",
        "    logger.info(f\"Configuring Google AI SDK with MAIN API key ending with ...{GOOGLE_API_KEY[-4:]}\")\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error configuring Google AI SDK with main key: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_CONFIG = {\n",
        "    \"text_model_name\": \"gemini-2.5-flash-preview-04-17-thinking\",\n",
        "    \"multimodal_model_name\": \"gemini-1.5-flash-latest\",\n",
        "    \"generation_config\": {\"temperature\": 0.5},\n",
        "    \"summarization_generation_config\": {\"temperature\": 0.6},\n",
        "    SAFETY_SETTINGS = [\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_HARASSMENT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_HATE_SPEECH, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "]\n",
        "}\n",
        "\n",
        "# Telethon Client Initialization\n",
        "session_name = f\"bot_session_{BOT_TOKEN.split(':')[0]}\"  # Ensure unique session name\n",
        "client = TelegramClient(session_name, API_ID, API_HASH)\n",
        "TEMP_DIR = Path(\"./temp_audio_telethon_bot\")\n",
        "TEMP_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Audio Processing Constants ---\n",
        "MAX_DURATION_MINUTES = 30  # Maximum duration in minutes before splitting\n",
        "MAX_DURATION_MS = MAX_DURATION_MINUTES * 60 * 1000  # Convert to milliseconds\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def get_gemini_model_instance(model_name_key, custom_generation_config_key=None):\n",
        "    \"\"\"\n",
        "    Creates and returns a Gemini model instance.\n",
        "    ASSUMES genai IS ALREADY CONFIGURED with the correct API key FOR THIS CALL.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model_name_actual = MODEL_CONFIG[model_name_key]\n",
        "        generation_config_actual = MODEL_CONFIG[custom_generation_config_key] if custom_generation_config_key else MODEL_CONFIG[\"generation_config\"]\n",
        "\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=model_name_actual,\n",
        "            generation_config=generation_config_actual,\n",
        "            safety_settings=MODEL_CONFIG[\"safety_settings\"]\n",
        "        )\n",
        "        logger.info(f\"Created model instance for {model_name_actual} (current global API key is in use)\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating Gemini model {model_name_actual}: {e}\")\n",
        "        raise\n",
        "\n",
        "async def cleanup_files(*files):\n",
        "    for file_path in files:\n",
        "        if file_path and Path(file_path).exists():\n",
        "            try:\n",
        "                Path(file_path).unlink()\n",
        "                logger.info(f\"Deleted temporary file: {file_path}\")\n",
        "            except OSError as e:\n",
        "                logger.error(f\"Error deleting file {file_path}: {e}\")\n",
        "\n",
        "def generate_srt_with_timecodes(segmented_text):\n",
        "    lines = [line for line in segmented_text.split(\"\\n\") if line.strip()]\n",
        "    if not lines:\n",
        "        return \"1\\n00:00:00,000 --> 00:00:05,000\\n(Ù…Ø­ØªÙˆØ§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯)\\n\"\n",
        "    srt_content = []\n",
        "    current_time_total_seconds = 0\n",
        "    segment_duration_seconds = 5\n",
        "    for i, line in enumerate(lines):\n",
        "        start_seconds = current_time_total_seconds\n",
        "        end_seconds = current_time_total_seconds + segment_duration_seconds\n",
        "        def format_time(s):\n",
        "            return f\"{int(s // 3600):02}:{int(s % 3600 // 60):02}:{int(s % 60):02},{int((s % 1) * 1000):03}\"\n",
        "        srt_content.append(str(i + 1))\n",
        "        srt_content.append(f\"{format_time(start_seconds)} --> {format_time(end_seconds)}\")\n",
        "        srt_content.append(line)\n",
        "        srt_content.append(\"\")\n",
        "        current_time_total_seconds = end_seconds\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "# --- New Audio Splitting Functions ---\n",
        "\n",
        "async def get_audio_duration(file_path):\n",
        "    \"\"\"Get the duration of an audio file in milliseconds.\"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        duration_ms = len(audio)\n",
        "        logger.info(f\"Audio duration: {duration_ms/1000:.2f} seconds ({duration_ms/60000:.2f} minutes)\")\n",
        "        return duration_ms\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting audio duration: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def split_audio_file(file_path, base_name, max_duration_ms=MAX_DURATION_MS):\n",
        "    \"\"\"\n",
        "    Split an audio file into chunks of max_duration_ms.\n",
        "    Returns a list of paths to the split audio files.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        total_duration_ms = len(audio)\n",
        "\n",
        "        if total_duration_ms <= max_duration_ms:\n",
        "            logger.info(f\"Audio is shorter than {MAX_DURATION_MINUTES} minutes, no need to split\")\n",
        "            return [file_path]\n",
        "\n",
        "        # Calculate number of chunks needed\n",
        "        num_chunks = math.ceil(total_duration_ms / max_duration_ms)\n",
        "        logger.info(f\"Splitting audio into {num_chunks} chunks of {MAX_DURATION_MINUTES} minutes each\")\n",
        "\n",
        "        chunk_paths = []\n",
        "        for i in range(num_chunks):\n",
        "            start_ms = i * max_duration_ms\n",
        "            end_ms = min((i + 1) * max_duration_ms, total_duration_ms)\n",
        "\n",
        "            chunk = audio[start_ms:end_ms]\n",
        "            chunk_filename = f\"{base_name}_part{i+1}.ogg\"\n",
        "            chunk_path = TEMP_DIR / chunk_filename\n",
        "\n",
        "            logger.info(f\"Exporting chunk {i+1}/{num_chunks} to {chunk_path}\")\n",
        "            chunk.export(str(chunk_path), format=\"ogg\")\n",
        "            chunk_paths.append(str(chunk_path))\n",
        "\n",
        "        logger.info(f\"Successfully split audio into {len(chunk_paths)} chunks\")\n",
        "        return chunk_paths\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error splitting audio file: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "# --- Google AI API Call Functions ---\n",
        "\n",
        "async def transcribe_audio_google(file_path):\n",
        "    logger.info(f\"Transcribing audio file: {file_path}\")\n",
        "    google_audio_file_obj = None\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"multimodal_model_name\")  # Assumes main key is active\n",
        "        logger.info(\"Uploading audio file for transcription...\")\n",
        "        # upload_file is synchronous, so run in a thread\n",
        "        google_audio_file_obj = await asyncio.to_thread(genai.upload_file, path=file_path)\n",
        "        logger.info(f\"Audio file uploaded: {google_audio_file_obj.name}\")\n",
        "\n",
        "        prompt = \"Please transcribe the audio provided accurately. Return ONLY the plain text transcription.\"\n",
        "\n",
        "        # Run the synchronous generate_content in a thread\n",
        "        response = await asyncio.to_thread(\n",
        "            model.generate_content,\n",
        "            [prompt, google_audio_file_obj]  # Pass contents directly\n",
        "        )\n",
        "\n",
        "        transcription = response.text.strip()\n",
        "\n",
        "        if not transcription:\n",
        "             logger.warning(\"Transcription response was empty.\")\n",
        "             raise ValueError(\"Transcription failed: No text returned.\")\n",
        "        logger.info(\"Transcription successful.\")\n",
        "        return transcription, google_audio_file_obj\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during transcription: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def summarize_audio_google(audio_file_ref, transcription_context):\n",
        "    logger.info(\"Summarizing audio content...\")\n",
        "    # --- API Key Switching Logic ---\n",
        "    current_global_key_is_main = True  # Assume it's the main key initially\n",
        "\n",
        "    if GOOGLE_API_KEY != GOOGLE_SUMMARY_API_KEY and GOOGLE_SUMMARY_API_KEY:\n",
        "        try:\n",
        "            logger.info(f\"Temporarily configuring genai for GOOGLE_SUMMARY_API_KEY (ends ...{GOOGLE_SUMMARY_API_KEY[-4:]}) for summarization\")\n",
        "            genai.configure(api_key=GOOGLE_SUMMARY_API_KEY)\n",
        "            current_global_key_is_main = False  # Now it's the summary key\n",
        "\n",
        "            model = get_gemini_model_instance(\"multimodal_model_name\", \"summarization_generation_config\")\n",
        "\n",
        "            summary_prompt = \"\"\"\n",
        "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ùˆ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯.\n",
        "ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ Ø¢Ù† Ù†ÛŒØ² Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡ Ùˆ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ø²ÛŒØ± Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª.\n",
        "Ù„Ø·ÙØ§Ù‹ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ ÛŒÚ© Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:\n",
        "\n",
        "Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ:\n",
        "1.  **Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ (Û²-Û³ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù):** Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ Ùˆ Ù‡Ø¯ÙØŒ Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ø­Ø«ØŒ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§ØµÙ„ÛŒ.\n",
        "2.  **Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ø¨Ø±Ø¬Ø³ØªÙ‡:** Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ù†Ù‚Ø§Ø·ØŒ Ø¢Ù…Ø§Ø±/Ø§Ø±Ù‚Ø§Ù… Ù…Ù‡Ù…ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§/Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ (Ø­Ø¯Ø§Ù‚Ù„ Ûµ Ù…ÙˆØ±Ø¯).\n",
        "3.  **Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…:** Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒØŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§/Ù…ÙˆØ§Ø±Ø¯ Ø®Ø§ØµØŒ Ù†Ù‚Ù„ Ù‚ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… (Ø­Ø¯Ø§Ú©Ø«Ø± Û²-Û³).\n",
        "4.  **ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†):** Ø§Ø±ØªØ¨Ø§Ø· Ù…ÙØ§Ù‡ÛŒÙ…ØŒ Ù†Ù‚Ø§Ø· Ù‚ÙˆØª/Ø¶Ø¹ÙØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª/Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§.\n",
        "5.  **Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆØ¶ÙˆØ¹ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ):** Ù…ÙˆØ¶ÙˆØ¹Ø§Øª ÙØ±Ø¹ÛŒ Ùˆ Ø§Ø±ØªØ¨Ø§Ø·Ø´Ø§Ù† Ø¨Ø§ Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ.\n",
        "\n",
        "**Ø®Ø±ÙˆØ¬ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:**\n",
        "*   Ø®Ù„Ø§ØµÙ‡ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ù„ÛŒØ³ Ùˆ Ø±ÙˆØ§Ù†.\n",
        "*   Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ø§ ØªÛŒØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ ÙØ§Ø±Ø³ÛŒ (Ù…Ø§Ù†Ù†Ø¯ \"Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ\", \"Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ø¨Ø±Ø¬Ø³ØªÙ‡\").\n",
        "*   Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ (Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§).\n",
        "*   Ø·ÙˆÙ„ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ.\n",
        "*   ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒØŒ Ø¨Ø¯ÙˆÙ† Ø¹Ø¨Ø§Ø±Øª Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ ÛŒØ§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ.\n",
        "\"\"\"\n",
        "            response = await asyncio.to_thread(\n",
        "                model.generate_content,\n",
        "                [summary_prompt.format(transcription_context=transcription_context), audio_file_ref]\n",
        "            )\n",
        "            summary = response.text.strip()\n",
        "\n",
        "            if not summary:\n",
        "                logger.warning(\"Summarization response was empty.\")\n",
        "                raise ValueError(\"Summarization failed: No text returned.\")\n",
        "            logger.info(\"Summarization successful.\")\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during summarization: {e}\", exc_info=True)\n",
        "            raise\n",
        "        finally:\n",
        "            # --- Switch back to MAIN API key ---\n",
        "            if not current_global_key_is_main:  # If we switched to summary key\n",
        "                logger.info(f\"Switching genai config back to main GOOGLE_API_KEY (ends ...{GOOGLE_API_KEY[-4:]})\")\n",
        "                genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    else:  # Keys are the same, or no specific summary key, so use the already configured main key\n",
        "        try:\n",
        "            logger.info(\"Using main GOOGLE_API_KEY for summarization as keys are same or summary key not distinct.\")\n",
        "            model = get_gemini_model_instance(\"multimodal_model_name\", \"summarization_generation_config\")\n",
        "            summary_prompt = f\"\"\"\n",
        "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ùˆ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯.\n",
        "ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ Ø¢Ù† Ù†ÛŒØ² Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡ Ùˆ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ø²ÛŒØ± Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª.\n",
        "Ù„Ø·ÙØ§Ù‹ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ ÛŒÚ© Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:\n",
        "\n",
        "Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ:\n",
        "1.  **Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ (Û²-Û³ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù):** Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ Ùˆ Ù‡Ø¯ÙØŒ Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ø­Ø«ØŒ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§ØµÙ„ÛŒ.\n",
        "2.  **Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ø¨Ø±Ø¬Ø³ØªÙ‡:** Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ù†Ù‚Ø§Ø·ØŒ Ø¢Ù…Ø§Ø±/Ø§Ø±Ù‚Ø§Ù… Ù…Ù‡Ù…ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§/Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ (Ø­Ø¯Ø§Ù‚Ù„ Ûµ Ù…ÙˆØ±Ø¯).\n",
        "3.  **Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…:** Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒØŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§/Ù…ÙˆØ§Ø±Ø¯ Ø®Ø§ØµØŒ Ù†Ù‚Ù„ Ù‚ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… (Ø­Ø¯Ø§Ú©Ø«Ø± Û²-Û³).\n",
        "4.  **ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†):** Ø§Ø±ØªØ¨Ø§Ø· Ù…ÙØ§Ù‡ÛŒÙ…ØŒ Ù†Ù‚Ø§Ø· Ù‚ÙˆØª/Ø¶Ø¹ÙØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª/Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§.\n",
        "5.  **Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆØ¶ÙˆØ¹ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ):** Ù…ÙˆØ¶ÙˆØ¹Ø§Øª ÙØ±Ø¹ÛŒ Ùˆ Ø§Ø±ØªØ¨Ø§Ø·Ø´Ø§Ù† Ø¨Ø§ Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ.\n",
        "\n",
        "**Ø®Ø±ÙˆØ¬ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:**\n",
        "*   Ø®Ù„Ø§ØµÙ‡ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ù„ÛŒØ³ Ùˆ Ø±ÙˆØ§Ù†.\n",
        "*   Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ø§ ØªÛŒØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ ÙØ§Ø±Ø³ÛŒ (Ù…Ø§Ù†Ù†Ø¯ \"Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ\", \"Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ø¨Ø±Ø¬Ø³ØªÙ‡\").\n",
        "*   Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ (Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§).\n",
        "*   Ø·ÙˆÙ„ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ.\n",
        "*   ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒØŒ Ø¨Ø¯ÙˆÙ† Ø¹Ø¨Ø§Ø±Øª Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ ÛŒØ§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ.\n",
        "\"\"\"\n",
        "            response = await asyncio.to_thread(\n",
        "                model.generate_content,\n",
        "                [summary_prompt.format(transcription_context=transcription_context), audio_file_ref]\n",
        "            )\n",
        "            summary = response.text.strip()\n",
        "            if not summary:\n",
        "                logger.warning(\"Summarization response was empty.\")\n",
        "                raise ValueError(\"Summarization failed: No text returned.\")\n",
        "            logger.info(\"Summarization successful.\")\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during summarization with main key: {e}\", exc_info=True)\n",
        "            raise\n",
        "\n",
        "async def translate_to_persian_google(text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    if not text or not text.strip(): return \"\"\n",
        "    logger.info(\"Translating text to Persian...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        prompt = f'Translate the following text to Persian:\\n\\n\"{text}\"\\n\\nReturn ONLY the Persian translation.'\n",
        "        response = await asyncio.to_thread(model.generate_content, prompt)\n",
        "        translation = response.text.strip()\n",
        "        if not translation:\n",
        "            logger.warning(\"Translation response was empty.\")\n",
        "            raise ValueError(\"Translation failed: No text returned.\")\n",
        "        logger.info(\"Translation successful.\")\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during translation: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def segment_persian_text_google(persian_text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    logger.info(\"Segmenting Persian text for SRT...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        segmentation_prompt = f\"\"\"Take the following Persian text and break it into suitable subtitle segments. Each segment should be on a new line. Aim for natural breaks and readable lengths for subtitles.\n",
        "Return ONLY the segmented text, with each segment on a new line.\n",
        "Persian text:\n",
        "---\n",
        "{persian_text}\n",
        "---\"\"\"\n",
        "        response = await asyncio.to_thread(model.generate_content, segmentation_prompt)\n",
        "        segmented_text = response.text.strip()\n",
        "\n",
        "        if not segmented_text:  # Fallback\n",
        "            logger.warning(\"LLM Segmentation response was empty. Using regex fallback.\")\n",
        "            segments = re.split(r'[à¥¤\\.ØŸ!\\n]+', persian_text)\n",
        "            segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "            if not segmented_text: raise ValueError(\"Segmentation failed: No text from LLM or fallback.\")\n",
        "        logger.info(\"Segmentation successful.\")\n",
        "        return segmented_text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during LLM segmentation: {e}. Using regex fallback.\", exc_info=True)\n",
        "        segments = re.split(r'[à¥¤\\.ØŸ!\\n]+', persian_text)  # Fallback on any error\n",
        "        segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "        if not segmented_text: raise ValueError(f\"Segmentation failed: Error '{e}' and fallback also yielded no text.\")\n",
        "        return segmented_text\n",
        "\n",
        "async def generate_persian_srt_google(transcription):\n",
        "    logger.info(\"Generating Persian SRT...\")\n",
        "    try:\n",
        "        persian_translation = await translate_to_persian_google(transcription)\n",
        "        if not persian_translation: raise ValueError(\"Translation step failed for SRT.\")\n",
        "        segmented_persian_text = await segment_persian_text_google(persian_translation)\n",
        "        if not segmented_persian_text: raise ValueError(\"Segmentation step failed for SRT.\")\n",
        "        srt_content = generate_srt_with_timecodes(segmented_persian_text)\n",
        "        logger.info(\"SRT generation successful.\")\n",
        "        return srt_content\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating SRT: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def get_bot_response_google(message_text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    logger.info(f\"Getting bot response for: {message_text[:50]}...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        prompt = f\"\"\"You are LinguaScribe_Bot, a helpful Telegram assistant. The user's language is Persian.\n",
        "User says: \"{message_text}\"\n",
        "Provide a concise and helpful response in Persian. If the user sends audio, you will have received the transcription as 'messageText'.\n",
        "If they ask about services, mention audio transcription to text (Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØµÙˆØª), Persian translation (ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ), SRT generation (ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT), and audio summarization (Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ ØµÙˆØª).\n",
        "Keep responses brief. If the input is non-sensical or just a greeting, respond politely and briefly in Persian.\n",
        "Return ONLY the bot's reply.\"\"\"\n",
        "        response = await asyncio.to_thread(model.generate_content, prompt)\n",
        "        reply = response.text.strip()\n",
        "        if not reply:\n",
        "            logger.warning(\"Bot response generation was empty.\")\n",
        "            return \"Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‚Ø§Ø¯Ø± Ø¨Ù‡ Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ù†ÛŒØ³ØªÙ….\"\n",
        "        logger.info(\"Bot response generated.\")\n",
        "        return reply\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting bot response: {e}\", exc_info=True)\n",
        "        return \"Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯.\"\n",
        "\n",
        "# --- New Function for Processing Long Audio ---\n",
        "async def process_long_audio(event, download_path, original_name_base, chat_id, processing_msg):\n",
        "    \"\"\"Process a long audio file by splitting it into chunks and processing each chunk\"\"\"\n",
        "    try:\n",
        "        # Check audio duration\n",
        "        audio_duration_ms = await get_audio_duration(download_path)\n",
        "\n",
        "        if audio_duration_ms <= MAX_DURATION_MS:\n",
        "            # Audio is shorter than threshold, process normally\n",
        "            logger.info(f\"Audio duration ({audio_duration_ms/60000:.2f} min) is under threshold, processing normally\")\n",
        "            return await process_single_audio(str(download_path), original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # Audio is longer than threshold, need to split\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"âš ï¸ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø´Ù…Ø§ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø³Øª ({audio_duration_ms/60000:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡). Ø¯Ø± Ø­Ø§Ù„ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª {MAX_DURATION_MINUTES} Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´...\"\n",
        "        )\n",
        "\n",
        "        # Split the audio file\n",
        "        chunk_paths = await split_audio_file(download_path, original_name_base)\n",
        "\n",
        "        # Process each chunk and collect transcriptions\n",
        "        all_transcriptions = []\n",
        "        all_uploaded_refs = []  # Track all uploaded file references for cleanup\n",
        "\n",
        "        for i, chunk_path in enumerate(chunk_paths):\n",
        "            await client.edit_message(\n",
        "                processing_msg,\n",
        "                processing_msg.text + f\"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ù‚Ø·Ø¹Ù‡ {i+1} Ø§Ø² {len(chunk_paths)}...\"\n",
        "            )\n",
        "\n",
        "            chunk_transcription, chunk_ref = await transcribe_audio_google(chunk_path)\n",
        "            all_uploaded_refs.append(chunk_ref)\n",
        "            all_transcriptions.append(chunk_transcription)\n",
        "\n",
        "            await client.edit_message(\n",
        "                processing_msg,\n",
        "                processing_msg.text + f\"\\nâœ… Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‚Ø·Ø¹Ù‡ {i+1} Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\"\n",
        "            )\n",
        "\n",
        "        # Combine all transcriptions\n",
        "        full_transcription = \"\\n\\n\".join(all_transcriptions)\n",
        "\n",
        "        # Save combined transcription\n",
        "        transcription_filename = f\"{original_name_base}_full_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(full_transcription)\n",
        "\n",
        "        # Send the combined transcription\n",
        "        await client.send_file(\n",
        "            chat_id,\n",
        "            str(transcription_path),\n",
        "            caption=\"ğŸ¤ Ù…ØªÙ† Ú©Ø§Ù…Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:\"\n",
        "        )\n",
        "\n",
        "        # Generate SRT from combined transcription\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT) Ú©Ø§Ù…Ù„...\")\n",
        "        srt_content = await generate_persian_srt_google(full_transcription)\n",
        "        srt_filename = f\"{original_name_base}_full_subtitles.srt\"\n",
        "        srt_path = TEMP_DIR / srt_filename\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_content)\n",
        "        await client.send_file(chat_id, str(srt_path), caption=\"ğŸ¬ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ú©Ø§Ù…Ù„ (SRT):\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT) Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        # Generate summary using the first chunk's audio reference and the full transcription\n",
        "        # (since we can't combine audio files for the API, we'll use one chunk but provide full transcription)\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙ‡ÛŒÙ‡ Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ...\")\n",
        "        summary = await summarize_audio_google(all_uploaded_refs[0], full_transcription)\n",
        "        await client.send_message(\n",
        "            chat_id,\n",
        "            f\"ğŸ“ *Ø®Ù„Ø§ØµÙ‡ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„:*\\n\\n{summary}\",\n",
        "            parse_mode='md'\n",
        "        )\n",
        "\n",
        "        # Final status message\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ {audio_duration_ms/60000:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ Ø´Ù…Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯.\"\n",
        "        )\n",
        "\n",
        "        # Return all files for cleanup\n",
        "        return all_uploaded_refs, [download_path, transcription_path, srt_path] + chunk_paths\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_long_audio: {e}\")\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ù„Ù†Ø¯: {str(e)}\"\n",
        "        )\n",
        "        return [], [download_path]\n",
        "\n",
        "# --- Function to Process a Single Audio File (for reuse) ---\n",
        "async def process_single_audio(file_path, original_name_base, chat_id, processing_msg):\n",
        "    \"\"\"Process a single audio file and return the uploaded ref and files for cleanup\"\"\"\n",
        "    try:\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†...\")\n",
        "        transcription, google_audio_file_uploaded_ref = await transcribe_audio_google(file_path)\n",
        "\n",
        "        transcription_filename = f\"{original_name_base}_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcription)\n",
        "\n",
        "        await client.send_file(chat_id, str(transcription_path), caption=\"ğŸ¤ Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙ‡ÛŒÙ‡ Ø®Ù„Ø§ØµÙ‡...\")\n",
        "        summary = await summarize_audio_google(google_audio_file_uploaded_ref, transcription)\n",
        "        await client.send_message(chat_id, f\"ğŸ“ *Ø®Ù„Ø§ØµÙ‡ Ù…Ø­ØªÙˆØ§:*\\n\\n{summary}\", parse_mode='md')\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… Ø®Ù„Ø§ØµÙ‡ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT)...\")\n",
        "        srt_content = await generate_persian_srt_google(transcription)\n",
        "        srt_filename = f\"{original_name_base}_subtitles.srt\"\n",
        "        srt_path = TEMP_DIR / srt_filename\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_content)\n",
        "        await client.send_file(chat_id, str(srt_path), caption=\"ğŸ¬ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT):\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT) Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "        await client.edit_message(processing_msg, \"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\")\n",
        "\n",
        "        # Return references and paths for cleanup\n",
        "        return [google_audio_file_uploaded_ref], [file_path, transcription_path, srt_path]\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_single_audio: {e}\")\n",
        "        await client.edit_message(processing_msg, f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ: {str(e)}\")\n",
        "        return [], [file_path]  # Return empty refs and only the original file for cleanup\n",
        "\n",
        "# --- Main Bot Event Handlers ---\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/start'))\n",
        "async def start(event):\n",
        "    sender = await event.get_sender()\n",
        "    chat_id = event.chat_id\n",
        "    logger.info(f\"New /start command from User {sender.id} in Chat {chat_id}\")\n",
        "\n",
        "    await event.reply(\n",
        "        \"ğŸ‘‹ Ø³Ù„Ø§Ù…! Ø¨Ù‡ Ø±Ø¨Ø§Øª *LinguaScribe* Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯.\\n\\n\"\n",
        "        \"Ø§ÛŒÙ† Ø±Ø¨Ø§Øª Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯:\\n\"\n",
        "        \"ğŸ¤ **Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†**: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø±Ø§ Ø¨Ù‡ Ù…ØªÙ† ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ø¯\\n\"\n",
        "        \"ğŸ“ **Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ**: Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ Ø±Ø§ Ø®Ù„Ø§ØµÙ‡ Ú©Ù†Ø¯\\n\"\n",
        "        \"ğŸ¬ **Ø²ÛŒØ±Ù†ÙˆÛŒØ³**: ÙØ§ÛŒÙ„ SRT ÙØ§Ø±Ø³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ø¯\\n\\n\"\n",
        "        \"Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù† Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/help'))\n",
        "async def help_command(event):\n",
        "    await event.reply(\n",
        "        \"ğŸ” **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² LinguaScribe Bot**\\n\\n\"\n",
        "        \"Ú©Ø§Ø±Ø¨Ø±Ø¯:\\n\"\n",
        "        \"1ï¸âƒ£ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ (voice message, audio file) Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\\n\"\n",
        "        \"2ï¸âƒ£ Ø±Ø¨Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø±:\\n\"\n",
        "        \"   - Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\\n\"\n",
        "        \"   - Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ø­ØªÙˆØ§ ØªÙ‡ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\\n\"\n",
        "        \"   - ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\\n\\n\"\n",
        "        \"ğŸ“‹ **Ù†Ú©Ø§Øª Ù…Ù‡Ù…**:\\n\"\n",
        "        \"â€¢ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ ØªØ§ Û³Û° Ø¯Ù‚ÛŒÙ‚Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯\\n\"\n",
        "        \"â€¢ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ±ØŒ Ø±Ø¨Ø§Øª Ø¢Ù†Ù‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ± ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯\\n\"\n",
        "        \"â€¢ Ø²Ø¨Ø§Ù† Ø§ØµÙ„ÛŒ Ù…ÙˆØ±Ø¯ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª\\n\\n\"\n",
        "        \"ğŸ“Œ **Ø¯Ø³ØªÙˆØ±Ø§Øª:**\\n\"\n",
        "        \"/start - Ø´Ø±ÙˆØ¹ Ú©Ø§Ø± Ø¨Ø§ Ø±Ø¨Ø§Øª\\n\"\n",
        "        \"/help - Ù†Ù…Ø§ÛŒØ´ Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.text and not e.text.startswith('/')))\n",
        "async def handle_text_message(event):\n",
        "    chat_id = event.chat_id\n",
        "    message_text = event.text\n",
        "    logger.info(f\"Received text message in chat {chat_id}: {message_text[:50]}...\")\n",
        "\n",
        "    # Let the user know we're processing\n",
        "    processing_msg = await event.reply(\"â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ø´Ù…Ø§...\")\n",
        "\n",
        "    try:\n",
        "        bot_response = await get_bot_response_google(message_text)\n",
        "        await client.edit_message(processing_msg, bot_response)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling text message: {e}\", exc_info=True)\n",
        "        await client.edit_message(processing_msg, \"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ø´Ù…Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯.\")\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.audio or e.voice or e.document))\n",
        "async def handle_audio_message(event):\n",
        "    try:\n",
        "        chat_id = event.chat_id\n",
        "        sender = await event.get_sender()\n",
        "        logger.info(f\"Received audio from User {sender.id} in Chat {chat_id}\")\n",
        "\n",
        "        # Check if the message contains audio, voice, or a document\n",
        "        if event.audio:\n",
        "            media = event.audio\n",
        "            file_type = \"audio\"\n",
        "        elif event.voice:\n",
        "            media = event.voice\n",
        "            file_type = \"voice\"\n",
        "        elif event.document and hasattr(event.document, 'mime_type') and event.document.mime_type.startswith('audio/'):\n",
        "            media = event.document\n",
        "            file_type = \"document\"\n",
        "        else:\n",
        "            await event.reply(\"âŒ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "            return\n",
        "\n",
        "        # Initial processing message\n",
        "        processing_msg = await event.reply(\"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ...\")\n",
        "\n",
        "        # Generate a unique filename based on timestamp and user\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        original_name = getattr(media, 'attributes', [{}])[0].file_name if hasattr(getattr(media, 'attributes', [{}])[0], 'file_name') else f\"{file_type}_{timestamp}\"\n",
        "        original_name_base = Path(original_name).stem\n",
        "        download_path = TEMP_DIR / f\"{original_name_base}_{timestamp}.ogg\"\n",
        "\n",
        "        # Download the file\n",
        "        try:\n",
        "            await client.download_media(message=event.message, file=str(download_path))\n",
        "            logger.info(f\"File downloaded to {download_path}\")\n",
        "            await client.edit_message(processing_msg, \"âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...\")\n",
        "        except Exception as download_error:\n",
        "            logger.error(f\"Error downloading file: {download_error}\", exc_info=True)\n",
        "            await client.edit_message(processing_msg, \"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ.\")\n",
        "            return\n",
        "\n",
        "        # Process the audio (handles both short and long audio files)\n",
        "        uploaded_refs, files_to_cleanup = await process_long_audio(\n",
        "            event, download_path, original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # Clean up all temporary files and references\n",
        "        await cleanup_files(*files_to_cleanup)\n",
        "        for ref in uploaded_refs:\n",
        "            try:\n",
        "                # Only attempt to clean up Google API uploaded file references if they exist\n",
        "                if ref and hasattr(ref, 'name'):\n",
        "                    logger.info(f\"Cleaning up Google API file reference: {ref.name}\")\n",
        "                    # No cleanup needed for now as these are handled by Google's API\n",
        "            except Exception as ref_cleanup_error:\n",
        "                logger.error(f\"Error cleaning up reference: {ref_cleanup_error}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Unhandled error in handle_audio_message: {e}\")\n",
        "        try:\n",
        "            await event.reply(\"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø´Ù…Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# --- Main Entry Point ---\n",
        "\n",
        "async def main():\n",
        "    logger.info(\"Starting the bot...\")\n",
        "\n",
        "    # Clear temp directory at startup\n",
        "    for file_path in TEMP_DIR.glob(\"*\"):\n",
        "        try:\n",
        "            file_path.unlink()\n",
        "            logger.info(f\"Cleaned up old file: {file_path}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error cleaning up file {file_path}: {e}\")\n",
        "\n",
        "    # Start the client\n",
        "    await client.start(bot_token=BOT_TOKEN)\n",
        "    logger.info(\"Bot started successfully\")\n",
        "\n",
        "    # Get the bot info\n",
        "    me = await client.get_me()\n",
        "    logger.info(f\"Bot Username: @{me.username}\")\n",
        "\n",
        "    # Keep the bot running\n",
        "    try:\n",
        "        logger.info(\"Bot is now running. Press Ctrl+C to stop.\")\n",
        "        await client.run_until_disconnected()\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"Bot stopped by user\")\n",
        "    finally:\n",
        "        await client.disconnect()\n",
        "        logger.info(\"Bot disconnected\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the bot\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
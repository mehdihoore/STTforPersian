{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdihoore/STTforPersian/blob/main/sttbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx0Ee8w5Gk4Z"
      },
      "outputs": [],
      "source": [
        "!pip install telethon google-generativeai python-dotenv nest_asyncio Pillow pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import re\n",
        "import math\n",
        "import zipfile\n",
        "import shutil # For robust directory cleanup\n",
        "from io import BytesIO\n",
        "\n",
        "from telethon import TelegramClient, events, Button\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold, GenerationConfig\n",
        "from google.api_core import exceptions as google_exceptions # For specific error handling\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# --- Configuration ---\n",
        "# Apply nest_asyncio early\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    API_ID = int(userdata.get('TELEGRAM_API_ID'))\n",
        "    API_HASH = userdata.get('TELEGRAM_API_HASH')\n",
        "    BOT_TOKEN = userdata.get('TELEGRAM_BOT_TTS')\n",
        "\n",
        "    # Load multiple Google API Keys\n",
        "    # Name your secrets like GOOGLE_API_KEY_1, GOOGLE_API_KEY_2, etc. in Colab\n",
        "    GOOGLE_API_KEYS_LIST = []\n",
        "    for i in range(1, 6): # Try to load up to 5 keys, adjust as needed\n",
        "        key = userdata.get(f'GOOGLE_API_KEY_{i}')\n",
        "        if key:\n",
        "            GOOGLE_API_KEYS_LIST.append(key)\n",
        "\n",
        "    if not all([API_ID, API_HASH, BOT_TOKEN]):\n",
        "        raise ValueError(\"Telegram API_ID, API_HASH, or BOT_TOKEN is missing.\")\n",
        "    if not GOOGLE_API_KEYS_LIST:\n",
        "        raise ValueError(\"At least one GOOGLE_API_KEY_n must be configured in Colab secrets.\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.critical(f\"Error loading secrets: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Model and API Configuration ---\n",
        "MODEL_PREFERENCES = {\n",
        "    \"transcription\": [\"gemini-1.5-flash-latest\", \"gemini-1.5-flash-latest\"], # Pro for potentially better accuracy\n",
        "    \"summarization_detailed\": [\"gemini-2.5-flash-preview-04-17-thinking\", \"gemini-2.5-flash-preview-04-17\"], # Pro essential for detailed summaries\n",
        "    \"translation_segmentation\": [\"gemini-1.5-flash-latest\"],\n",
        "    \"bot_response\": [\"gemini-1.5-flash-latest\"],\n",
        "}\n",
        "\n",
        "GENERATION_CONFIGS = {\n",
        "    \"default\": GenerationConfig(temperature=0.5),\n",
        "    \"summarization_detailed\": GenerationConfig(temperature=0.4, top_p=0.95), # Lower temp for factual detail\n",
        "    \"translation_segmentation\": GenerationConfig(temperature=0.2), # More deterministic\n",
        "    \"bot_response\": GenerationConfig(temperature=0.7),\n",
        "}\n",
        "\n",
        "SAFETY_SETTINGS = [\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_HARASSMENT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_HATE_SPEECH, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "]\n",
        "\n",
        "# --- Global State for API Key Management ---\n",
        "_current_key_index = 0\n",
        "_active_google_api_key = None\n",
        "\n",
        "def configure_gemini_client(api_key_to_set):\n",
        "    global _active_google_api_key\n",
        "    if api_key_to_set != _active_google_api_key:\n",
        "        logger.info(f\"Configuring Google AI SDK with API key ending with ...{api_key_to_set[-4:]}\")\n",
        "        try:\n",
        "            genai.configure(api_key=api_key_to_set)\n",
        "            _active_google_api_key = api_key_to_set\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to configure Google AI SDK with key ...{api_key_to_set[-4:]}: {e}\")\n",
        "            _active_google_api_key = None\n",
        "            return False\n",
        "    return True # Already configured with this key\n",
        "\n",
        "# Initialize with the first key\n",
        "if not configure_gemini_client(GOOGLE_API_KEYS_LIST[0]):\n",
        "    logger.critical(\"Failed to configure Gemini with the initial API key. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Telethon Client Initialization\n",
        "session_name = f\"bot_session_{BOT_TOKEN.split(':')[0]}\"\n",
        "client = TelegramClient(session_name, API_ID, API_HASH)\n",
        "TEMP_DIR = Path(\"./temp_files_linguascribe_bot\")\n",
        "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TEMP_EXTRACTION_DIR = TEMP_DIR / \"extracted_files\"\n",
        "TEMP_EXTRACTION_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# --- Audio/Video Processing Constants ---\n",
        "MAX_DURATION_MINUTES = 25  # Max duration for single audio processing before splitting (Gemini Flash can handle up to 1h, Pro even more, but smaller chunks are safer for retries)\n",
        "MAX_DURATION_MS = MAX_DURATION_MINUTES * 60 * 1000\n",
        "VIDEO_MIME_TYPES = ['video/mp4', 'video/mpeg', 'video/quicktime', 'video/x-msvideo', 'video/x-flv', 'video/webm', 'video/x-matroska', 'video/avi']\n",
        "AUDIO_OUTPUT_FORMAT = \"ogg\" # opus in ogg\n",
        "AUDIO_OUTPUT_CODEC = \"libopus\"\n",
        "AUDIO_OUTPUT_BITRATE = \"48k\" # Reduced bitrate for smaller size\n",
        "AUDIO_SAMPLE_RATE = 16000 # Good for speech\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "async def cleanup_files_and_dirs(*paths):\n",
        "    for path_obj in paths:\n",
        "        path = Path(path_obj)\n",
        "        if not path.exists():\n",
        "            continue\n",
        "        try:\n",
        "            if path.is_file():\n",
        "                path.unlink()\n",
        "                logger.info(f\"Deleted temporary file: {path}\")\n",
        "            elif path.is_dir():\n",
        "                shutil.rmtree(path)\n",
        "                logger.info(f\"Deleted temporary directory: {path}\")\n",
        "        except OSError as e:\n",
        "            logger.error(f\"Error deleting {path}: {e}\")\n",
        "\n",
        "def generate_srt_with_timecodes(segmented_text):\n",
        "    lines = [line for line in segmented_text.split(\"\\n\") if line.strip()]\n",
        "    if not lines:\n",
        "        return \"1\\n00:00:00,000 --> 00:00:05,000\\n(محتوایی برای زمان‌بندی وجود ندارد)\\n\"\n",
        "    srt_content = []\n",
        "    current_time_total_seconds = 0\n",
        "    segment_duration_seconds = 5 # Average duration per subtitle line\n",
        "    for i, line in enumerate(lines):\n",
        "        start_seconds = current_time_total_seconds\n",
        "        end_seconds = current_time_total_seconds + segment_duration_seconds\n",
        "        def format_time(s):\n",
        "            return f\"{int(s // 3600):02}:{int(s % 3600 // 60):02}:{int(s % 60):02},{int((s % 1) * 1000):03}\"\n",
        "        srt_content.append(str(i + 1))\n",
        "        srt_content.append(f\"{format_time(start_seconds)} --> {format_time(end_seconds)}\")\n",
        "        srt_content.append(line)\n",
        "        srt_content.append(\"\")\n",
        "        current_time_total_seconds = end_seconds + 0.5 # Add a small gap\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "async def get_audio_duration(file_path):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        duration_ms = len(audio)\n",
        "        logger.info(f\"Audio duration for {file_path}: {duration_ms/1000:.2f}s ({duration_ms/60000:.2f}min)\")\n",
        "        return duration_ms\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting audio duration for {file_path}: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def split_audio_file(file_path, base_name, max_duration_ms=MAX_DURATION_MS):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        total_duration_ms = len(audio)\n",
        "\n",
        "        if total_duration_ms <= max_duration_ms:\n",
        "            logger.info(f\"Audio {base_name} is short enough, no split needed.\")\n",
        "            return [str(file_path)]\n",
        "\n",
        "        num_chunks = math.ceil(total_duration_ms / max_duration_ms)\n",
        "        logger.info(f\"Splitting audio {base_name} into {num_chunks} chunks.\")\n",
        "        chunk_paths = []\n",
        "        for i in range(num_chunks):\n",
        "            start_ms = i * max_duration_ms\n",
        "            end_ms = min((i + 1) * max_duration_ms, total_duration_ms)\n",
        "            chunk = audio[start_ms:end_ms]\n",
        "            # Ensure correct extension based on AUDIO_OUTPUT_FORMAT\n",
        "            chunk_filename = f\"{base_name}_part{i+1}.{AUDIO_OUTPUT_FORMAT}\"\n",
        "            chunk_path = TEMP_DIR / chunk_filename\n",
        "            logger.info(f\"Exporting chunk {i+1}/{num_chunks} to {chunk_path}\")\n",
        "            chunk.export(str(chunk_path), format=AUDIO_OUTPUT_FORMAT, codec=AUDIO_OUTPUT_CODEC if AUDIO_OUTPUT_FORMAT == \"ogg\" else None, bitrate=AUDIO_OUTPUT_BITRATE)\n",
        "            chunk_paths.append(str(chunk_path))\n",
        "        return chunk_paths\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error splitting audio file {base_name}: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "# --- Core Gemini API Request Function with Retry ---\n",
        "async def gemini_request_with_retry(\n",
        "    task_name: str,\n",
        "    model_preference_key: str,\n",
        "    prompt_parts: list,\n",
        "    generation_config_key: str,\n",
        "    file_path_to_upload: str = None\n",
        "):\n",
        "    global _current_key_index\n",
        "    uploaded_file_ref = None\n",
        "    max_key_cycles = len(GOOGLE_API_KEYS_LIST)\n",
        "\n",
        "    for key_cycle in range(max_key_cycles):\n",
        "        current_api_key = GOOGLE_API_KEYS_LIST[_current_key_index]\n",
        "        logger.info(f\"[Task: {task_name}] Attempting with API key ending ...{current_api_key[-4:]} (Cycle {key_cycle+1}/{max_key_cycles})\")\n",
        "\n",
        "        if not configure_gemini_client(current_api_key):\n",
        "            _current_key_index = (_current_key_index + 1) % len(GOOGLE_API_KEYS_LIST)\n",
        "            continue # Try next key if this one fails to configure\n",
        "\n",
        "        models_to_try = MODEL_PREFERENCES.get(model_preference_key, [MODEL_PREFERENCES[\"bot_response\"][0]])\n",
        "        gen_config = GENERATION_CONFIGS.get(generation_config_key, GENERATION_CONFIGS[\"default\"])\n",
        "\n",
        "        # File Upload (if needed, once per key attempt)\n",
        "        if file_path_to_upload and not uploaded_file_ref: # Only upload once per successful key config\n",
        "            try:\n",
        "                logger.info(f\"[Task: {task_name}] Uploading file: {file_path_to_upload} with key ...{current_api_key[-4:]}\")\n",
        "                # genai.upload_file is synchronous\n",
        "                uploaded_file_ref = await asyncio.to_thread(\n",
        "                    genai.upload_file, path=file_path_to_upload,\n",
        "                    # mime_type can be specified if Path(file_path_to_upload).suffix is not reliable\n",
        "                )\n",
        "                logger.info(f\"[Task: {task_name}] File uploaded successfully: {uploaded_file_ref.name}\")\n",
        "                # Prepend file to prompt_parts if upload successful\n",
        "                current_prompt_parts = [uploaded_file_ref] + prompt_parts\n",
        "            except Exception as e:\n",
        "                logger.error(f\"[Task: {task_name}] File upload failed with key ...{current_api_key[-4:]}: {e}\")\n",
        "                # If upload fails, this key might be problematic for uploads or file is bad.\n",
        "                # Cycle to next key by incrementing index and continuing outer loop.\n",
        "                _current_key_index = (_current_key_index + 1) % len(GOOGLE_API_KEYS_LIST)\n",
        "                uploaded_file_ref = None # Reset for next key\n",
        "                continue\n",
        "        elif file_path_to_upload and uploaded_file_ref: # File already uploaded with this key\n",
        "             current_prompt_parts = [uploaded_file_ref] + prompt_parts\n",
        "        else: # No file to upload\n",
        "            current_prompt_parts = prompt_parts\n",
        "\n",
        "\n",
        "        for model_name in models_to_try:\n",
        "            logger.info(f\"[Task: {task_name}] Trying model: {model_name} with key ...{current_api_key[-4:]}\")\n",
        "            try:\n",
        "                model = genai.GenerativeModel(\n",
        "                    model_name=model_name,\n",
        "                    generation_config=gen_config,\n",
        "                    safety_settings=SAFETY_SETTINGS\n",
        "                )\n",
        "                # model.generate_content is synchronous\n",
        "                response = await asyncio.to_thread(\n",
        "                    model.generate_content, contents=current_prompt_parts\n",
        "                )\n",
        "                # Check for empty or problematic response\n",
        "                if not response.candidates or not response.text:\n",
        "                    if response.prompt_feedback and response.prompt_feedback.block_reason:\n",
        "                        logger.warning(f\"[Task: {task_name}] Request blocked for model {model_name}. Reason: {response.prompt_feedback.block_reason_message or response.prompt_feedback.block_reason}\")\n",
        "                        # This is often not retriable with same input. Break from model loop.\n",
        "                        break\n",
        "                    else:\n",
        "                        logger.warning(f\"[Task: {task_name}] Empty response from model {model_name}. Candidates: {response.candidates}\")\n",
        "                        # Treat as a failure for this model, try next model or key\n",
        "                        continue # Try next model\n",
        "\n",
        "                logger.info(f\"[Task: {task_name}] Successful response from model {model_name} with key ...{current_api_key[-4:]}\")\n",
        "                return response.text.strip(), uploaded_file_ref # Return text and file_ref\n",
        "\n",
        "            except (google_exceptions.ResourceExhausted,\n",
        "                    google_exceptions.InternalServerError,\n",
        "                    google_exceptions.DeadlineExceeded,\n",
        "                    google_exceptions.ServiceUnavailable,\n",
        "                    google_exceptions.Aborted) as e:\n",
        "                logger.warning(f\"[Task: {task_name}] Retryable API error with model {model_name} / key ...{current_api_key[-4:]}: {type(e).__name__} - {e}. Retrying with next model/key.\")\n",
        "                await asyncio.sleep(1) # Simple backoff\n",
        "                continue # Try next model or, if end of models, will go to next key\n",
        "            except (google_exceptions.InvalidArgument, google_exceptions.PermissionDenied) as e:\n",
        "                logger.error(f\"[Task: {task_name}] Non-retryable (for this model/key) API error with model {model_name} / key ...{current_api_key[-4:]}: {type(e).__name__} - {e}. Skipping model/key.\")\n",
        "                break # Break from model loop, try next key\n",
        "            except genai.types.BlockedPromptException as e:\n",
        "                logger.error(f\"[Task: {task_name}] BlockedPromptException with model {model_name}: {e}. This input is problematic.\")\n",
        "                raise # Re-raise, as this is usually an input issue not fixable by retry\n",
        "            except Exception as e:\n",
        "                logger.error(f\"[Task: {task_name}] Unexpected error with model {model_name} / key ...{current_api_key[-4:]}: {type(e).__name__} - {e}\", exc_info=True)\n",
        "                # For unexpected errors, break from model loop and try next key\n",
        "                break\n",
        "\n",
        "        # If all models for the current key failed or were skipped\n",
        "        _current_key_index = (_current_key_index + 1) % len(GOOGLE_API_KEYS_LIST)\n",
        "        uploaded_file_ref = None # Reset uploaded file ref if we are changing key\n",
        "\n",
        "    # If all keys and models failed\n",
        "    logger.error(f\"[Task: {task_name}] All API keys and models failed after {max_key_cycles} cycles.\")\n",
        "    raise Exception(f\"Failed to get response for {task_name} after multiple retries with all available keys/models.\")\n",
        "\n",
        "\n",
        "# --- Specific Google AI API Call Functions (using the retry wrapper) ---\n",
        "\n",
        "async def transcribe_audio_google(file_path):\n",
        "    logger.info(f\"Transcribing audio file: {file_path}\")\n",
        "    prompt = \"Please transcribe the audio provided accurately. Return ONLY the plain text transcription.\"\n",
        "    transcription, uploaded_file_ref = await gemini_request_with_retry(\n",
        "        task_name=\"AudioTranscription\",\n",
        "        model_preference_key=\"transcription\",\n",
        "        prompt_parts=[prompt],\n",
        "        generation_config_key=\"default\",\n",
        "        file_path_to_upload=file_path\n",
        "    )\n",
        "    if not transcription:\n",
        "        raise ValueError(\"Transcription failed: No text returned after retries.\")\n",
        "    return transcription, uploaded_file_ref\n",
        "\n",
        "DETAILED_SUMMARY_PROMPT_FOR_COLLEGE_PREP_FA = \"\"\"\n",
        "شما یک دستیار آموزشی خبره هستید که وظیفه تهیه مطالب مطالعه برای آمادگی آزمون‌های ورودی دانشگاه (کنکور) را بر عهده دارید.\n",
        "فایل صوتی (که محتوای آن در متن پیاده‌سازی شده آمده) و متن پیاده‌سازی شده اولیه آن ارائه شده است.\n",
        "لطفاً این محتوا را با دقت بسیار بالا تحلیل کرده و یک خلاصه بسیار جامع، دقیق و با جزئیات فراوان به زبان فارسی روان تهیه کنید که برای دانشجویی که نیاز به یادآوری و درک کامل این اطلاعات برای یک آزمون مهم دارد، مناسب باشد.\n",
        "\n",
        "متن پیاده‌سازی شده اولیه (برای کمک به زمینه و کلمات کلیدی):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "دستورالعمل‌های خلاصه‌سازی جامع برای آمادگی آزمون:\n",
        "\n",
        "1.  **مقدمه و هدف کلی (۱-۲ پاراگراف):**\n",
        "    *   موضوع اصلی و هدف کلی از ارائه این محتوا چیست؟\n",
        "    *   زمینه و بستر اصلی بحث چیست؟\n",
        "\n",
        "2.  **مفاهیم و تعاریف کلیدی (لیست شماره‌گذاری شده):**\n",
        "    *   تمامی اصطلاحات، مفاهیم و واژگان تخصصی مهم مطرح شده را شناسایی کنید.\n",
        "    *   هر کدام را به طور واضح و دقیق در چارچوب بحث تعریف کنید.\n",
        "\n",
        "3.  **نکات اصلی و استدلال‌ها (ساختار درختی یا با عنوان‌بندی مناسب با استفاده از Markdown):**\n",
        "    *   تمامی نکات، ایده‌ها و استدلال‌های اصلی مطرح شده را به تفصیل بیان کنید.\n",
        "    *   برای هر نکته یا استدلال، شواهد، مثال‌ها، آمار، ارقام، تاریخ‌ها و اسامی مهم ذکر شده را به طور کامل بیاورید.\n",
        "    *   اگر زنجیره منطقی یا مراحل خاصی در استدلال‌ها وجود دارد، آن‌ها را گام به گام توضیح دهید.\n",
        "\n",
        "4.  **جزئیات تکمیلی و مثال‌های مهم (حداقل ۵-۷ مورد یا بیشتر در صورت لزوم):**\n",
        "    *   مثال‌های کلیدی، موارد خاص، مطالعات موردی یا نمونه‌هایی که برای روشن شدن مفاهیم ارائه شده‌اند را با جزئیات شرح دهید.\n",
        "    *   نقل قول‌های مهم و تاثیرگذار را (در صورت وجود) با ذکر دقیق آورده و اهمیت آن‌ها را توضیح دهید.\n",
        "\n",
        "5.  **تحلیل عمیق محتوا (در صورت امکان و مرتبط بودن):**\n",
        "    *   ارتباط بین مفاهیم مختلف چگونه است؟\n",
        "    *   نقاط قوت و ضعف استدلال‌های ارائه شده (در صورت تحلیل در خود محتوا) چیست؟\n",
        "    *   پیشنهادات، راهکارها یا نتایج عملی که از بحث حاصل می‌شود، کدامند؟\n",
        "    *   هرگونه پیش‌فرض، فرضیه زمینه‌ای یا پیامدهای پنهان را شناسایی کنید.\n",
        "\n",
        "6.  **نتیجه‌گیری اصلی و پیام نهایی (۱-۲ پاراگراف):**\n",
        "    *   جمع‌بندی نهایی بحث و مهمترین نتایجی که می‌توان گرفت چیست؟\n",
        "    *   پیام اصلی یا درسی که مخاطب باید از این محتوا بگیرد چیست؟\n",
        "\n",
        "7.  **ساختار و زبان:**\n",
        "    *   خلاصه باید کاملاً به زبان فارسی رسمی، علمی و روان باشد.\n",
        "    *   از ساختار منطقی با عنوان‌بندی و شماره‌گذاری مناسب (مانند لیست‌ها، تیترهای فرعی با استفاده از Markdown مانند #, ##, ###, *, -) برای سازماندهی اطلاعات استفاده کنید تا خوانایی و قابلیت مرور آن برای مطالعه افزایش یابد.\n",
        "    *   در ارائه جزئیات کوتاهی نکنید؛ هدف، پوشش کامل و عمیق مطالب برای آمادگی آزمون است.\n",
        "    *   فقط و فقط خلاصه نهایی مطابق ساختار درخواستی، بدون عبارت مقدماتی یا توضیحات اضافی درباره فرآیند خلاصه‌سازی ارائه شود.\n",
        "\"\"\"\n",
        "\n",
        "async def summarize_audio_google(audio_file_ref_for_context, transcription_context):\n",
        "    logger.info(\"Generating detailed summary for college prep...\")\n",
        "    # audio_file_ref_for_context is used by the model to get richer context than just text\n",
        "    summary_prompt_formatted = DETAILED_SUMMARY_PROMPT_FOR_COLLEGE_PREP_FA.format(transcription_context=transcription_context)\n",
        "\n",
        "    # Note: We are passing audio_file_ref_for_context. The retry wrapper expects a file *path*.\n",
        "    # For summarization, we pass the *transcription* as primary text content,\n",
        "    # and the audio_file_ref is a reference to an *already uploaded* file.\n",
        "    # The current `gemini_request_with_retry` uploads a file if path is given.\n",
        "    # We need to adjust how `summarize_audio_google` calls it if it relies on an existing ref.\n",
        "\n",
        "    # Option 1: If audio_file_ref is essential and already exists, prompt needs to be [text_prompt, audio_file_ref]\n",
        "    # The retry wrapper needs to support passing pre-uploaded file objects.\n",
        "    # For now, let's assume the model can work very well with detailed text prompt and transcription.\n",
        "    # If the audio file itself *must* be re-sent for summarization, we'd need the path.\n",
        "    # Let's assume the transcription is rich enough for the text-based summarization models (Pro)\n",
        "    # and if we need multimodal summary, we'd pass the audio file path again.\n",
        "\n",
        "    # Current summarization prompt is text-based but uses transcription for context.\n",
        "    # If we want the model to *listen* again, we pass the audio_file_ref.\n",
        "    # The prompt implies both audio and text are provided.\n",
        "\n",
        "    # Simplification: For now, the `summarize_audio_google` will use the transcription text.\n",
        "    # If the `audio_file_ref` is to be used, `gemini_request_with_retry` needs modification\n",
        "    # to accept `genai.File` objects directly in `prompt_parts` without re-uploading.\n",
        "    # Let's assume for detailed summary, a powerful model can work from transcription.\n",
        "    # If we must use the audio file reference:\n",
        "    # prompt_parts = [summary_prompt_formatted, audio_file_ref_for_context]\n",
        "    # And `gemini_request_with_retry` would need to handle this case.\n",
        "\n",
        "    # For now, using text-only summarization with transcription as primary input:\n",
        "      summary_text, _ = await gemini_request_with_retry(\n",
        "        task_name=\"DetailedSummarization\",\n",
        "        model_preference_key=\"summarization_detailed\",\n",
        "        prompt_parts=[summary_prompt_formatted],\n",
        "        generation_config_key=\"summarization_detailed\",\n",
        "        file_path_to_upload=None # Or pass audio_file_ref_for_context if retry wrapper is adapted\n",
        "    )\n",
        "\n",
        "\n",
        "    # To use the audio_file_ref with the current retry wrapper, we'd effectively need to \"re-upload\" it logically\n",
        "    # or the wrapper needs to accept genai.File objects.\n",
        "    # Let's adapt the prompt_parts for summarize_audio_google specifically.\n",
        "    # The `gemini_request_with_retry` will have to be smart.\n",
        "    # If `file_path_to_upload` is a `genai.File` object, use it directly.\n",
        "\n",
        "    # --- REVISED APPROACH for summarize_audio_google to use existing file ref ---\n",
        "    # This requires `gemini_request_with_retry` to handle `file_path_to_upload` being a `genai.File` object.\n",
        "    # Let's assume `gemini_request_with_retry` is NOT changed for now, and we pass audio file path if needed.\n",
        "    # The original logic was: model.generate_content([summary_prompt, audio_file_ref])\n",
        "    # The simplest for now is to use the transcription for the detailed summary,\n",
        "    # relying on a strong Pro model.\n",
        "\n",
        "    if not summary:\n",
        "        raise ValueError(\"Summarization failed: No text returned after retries.\")\n",
        "    return \"\\u200F\" + summary_text\n",
        "\n",
        "\n",
        "async def translate_to_persian_google(text):\n",
        "    if not text or not text.strip(): return \"\"\n",
        "    logger.info(\"Translating text to Persian...\")\n",
        "    prompt = f'Translate the following text to Persian:\\n\\n\"{text}\"\\n\\nReturn ONLY the Persian translation, with no introductory phrases.'\n",
        "    translation, _ = await gemini_request_with_retry(\n",
        "        task_name=\"TranslationToPersian\",\n",
        "        model_preference_key=\"translation_segmentation\",\n",
        "        prompt_parts=[prompt],\n",
        "        generation_config_key=\"translation_segmentation\"\n",
        "    )\n",
        "    if not translation:\n",
        "        raise ValueError(\"Translation failed: No text returned.\")\n",
        "    return translation\n",
        "\n",
        "async def segment_persian_text_google(persian_text):\n",
        "    logger.info(\"Segmenting Persian text for SRT...\")\n",
        "    segmentation_prompt = f\"\"\"Take the following Persian text and break it into suitable subtitle segments. Each segment should be on a new line. Aim for natural breaks and readable lengths for subtitles (typically 1-2 short sentences or phrases).\n",
        "Return ONLY the segmented text, with each segment on a new line. Do not add numbering.\n",
        "Persian text:\n",
        "---\n",
        "{persian_text}\n",
        "---\"\"\"\n",
        "    segmented_text, _ = await gemini_request_with_retry(\n",
        "        task_name=\"TextSegmentation\",\n",
        "        model_preference_key=\"translation_segmentation\",\n",
        "        prompt_parts=[segmentation_prompt],\n",
        "        generation_config_key=\"translation_segmentation\"\n",
        "    )\n",
        "    if not segmented_text:\n",
        "        logger.warning(\"LLM Segmentation response was empty. Using regex fallback.\")\n",
        "        segments = re.split(r'[।\\.؟!\\n]+', persian_text)\n",
        "        segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "        if not segmented_text: raise ValueError(\"Segmentation failed: No text from LLM or fallback.\")\n",
        "    return segmented_text\n",
        "\n",
        "async def generate_persian_srt_google(transcription):\n",
        "    logger.info(\"Generating Persian SRT...\")\n",
        "    try:\n",
        "        # For SRT, a direct, less \"creative\" translation might be better than a highly contextual one.\n",
        "        # However, for now, using the same translation function.\n",
        "        persian_translation = await translate_to_persian_google(transcription)\n",
        "        if not persian_translation: raise ValueError(\"Translation step failed for SRT.\")\n",
        "\n",
        "        segmented_persian_text = await segment_persian_text_google(persian_translation)\n",
        "        if not segmented_persian_text: raise ValueError(\"Segmentation step failed for SRT.\")\n",
        "\n",
        "        srt_content = generate_srt_with_timecodes(segmented_persian_text)\n",
        "        logger.info(\"SRT generation successful.\")\n",
        "        return srt_content\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating SRT: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def get_bot_response_google(message_text):\n",
        "    logger.info(f\"Getting bot response for: {message_text[:50]}...\")\n",
        "    prompt = f\"\"\"You are LinguaScribe_Bot, a helpful Telegram assistant. The user's language is Persian.\n",
        "User says: \"{message_text}\"\n",
        "Provide a concise and helpful response in Persian.\n",
        "If they ask about your capabilities, mention:\n",
        "- پیاده‌سازی صوت به متن (Audio transcription)\n",
        "- خلاصه‌سازی جامع و تخصصی محتوای صوتی (Detailed audio summarization for study/prep)\n",
        "- تولید فایل زیرنویس SRT به فارسی (Persian SRT subtitle generation)\n",
        "- پردازش فایل‌های ZIP حاوی صوت یا متن (Processing ZIP files with audio/text)\n",
        "- تبدیل ویدیو به صوت برای پردازش (Video to audio conversion for processing)\n",
        "\n",
        "Keep responses brief. If the input is non-sensical or just a greeting, respond politely and briefly in Persian.\n",
        "Return ONLY the bot's reply in Persian.\n",
        "\"\"\"\n",
        "    reply, _ = await gemini_request_with_retry(\n",
        "        task_name=\"BotResponse\",\n",
        "        model_preference_key=\"bot_response\",\n",
        "        prompt_parts=[prompt],\n",
        "        generation_config_key=\"bot_response\"\n",
        "    )\n",
        "    if not reply:\n",
        "        return \"متاسفانه در حال حاضر قادر به پاسخگویی نیستم.\"\n",
        "    return reply\n",
        "\n",
        "# --- Core Media Processing Logic ---\n",
        "\n",
        "async def process_single_audio_file_operations(\n",
        "    audio_file_path: str,\n",
        "    original_name_base: str,\n",
        "    chat_id: int,\n",
        "    processing_msg_event,\n",
        "    is_part_of_long_audio=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Processes a single audio file (or a chunk of a longer one).\n",
        "    Returns transcription, path to transcription file, path to SRT file, and the Google uploaded file reference.\n",
        "    \"\"\"\n",
        "    files_to_cleanup_later = []\n",
        "    google_audio_file_ref = None\n",
        "    transcription = \"\"\n",
        "    transcription_path_str = None\n",
        "    srt_path_str = None\n",
        "\n",
        "    try:\n",
        "        # 1. Transcription\n",
        "        await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\n⏳ در حال پیاده‌سازی متن...\")\n",
        "        transcription, google_audio_file_ref = await transcribe_audio_google(audio_file_path)\n",
        "        files_to_cleanup_later.append(audio_file_path) # Original/converted audio chunk\n",
        "\n",
        "        transcription_filename = f\"{original_name_base}_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcription)\n",
        "        transcription_path_str = str(transcription_path)\n",
        "        files_to_cleanup_later.append(transcription_path_str)\n",
        "\n",
        "        await client.send_file(chat_id, transcription_path_str, caption=\"🎤 متن پیاده‌سازی شده:\")\n",
        "        await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n✅ متن پیاده‌سازی و ارسال شد.\")\n",
        "\n",
        "        # 2. SRT Generation (only if not part of a larger audio being processed, or do it per chunk too?)\n",
        "        # For long audio, SRT is generated for the full combined text later.\n",
        "        if not is_part_of_long_audio:\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\n⏳ در حال تولید زیرنویس (SRT)...\")\n",
        "            srt_content = await generate_persian_srt_google(transcription)\n",
        "            srt_filename = f\"{original_name_base}_subtitles.srt\"\n",
        "            srt_path = TEMP_DIR / srt_filename\n",
        "            with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(srt_content)\n",
        "            srt_path_str = str(srt_path)\n",
        "            files_to_cleanup_later.append(srt_path_str)\n",
        "            await client.send_file(chat_id, srt_path_str, caption=\"🎬 فایل زیرنویس (SRT):\")\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n✅ فایل زیرنویس (SRT) ارسال شد.\")\n",
        "\n",
        "        # Summary is done after all chunks are processed for long audio.\n",
        "        # For single short audio, summary is done here.\n",
        "        if not is_part_of_long_audio:\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\n⏳ در حال تهیه خلاصه جامع...\")\n",
        "            # For summary, we need the audio_file_ref if the model uses multimodal input.\n",
        "            # The `summarize_audio_google` currently uses text-based approach with transcription.\n",
        "            # If it were to use the audio file, we'd pass `google_audio_file_ref`.\n",
        "            summary = await summarize_audio_google(google_audio_file_ref, transcription)\n",
        "            summary_filename = f\"{original_name_base}_summary.md\" # Save as markdown\n",
        "            summary_path = TEMP_DIR / summary_filename\n",
        "            with open(summary_path, \"w\", encoding=\"utf-8\") as f: f.write(summary)\n",
        "            files_to_cleanup_later.append(str(summary_path))\n",
        "\n",
        "            await client.send_file(chat_id, str(summary_path), caption=\"📝 *خلاصه جامع محتوا:*\", parse_mode='md')\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n✅ خلاصه جامع ارسال شد.\")\n",
        "            await client.edit_message(processing_msg_event, \"✅ پردازش فایل صوتی با موفقیت تکمیل شد!\")\n",
        "\n",
        "        return transcription, transcription_path_str, srt_path_str, google_audio_file_ref, files_to_cleanup_later\n",
        "\n",
        "    except genai.types.BlockedPromptException as bpe:\n",
        "        logger.error(f\"Processing stopped due to blocked prompt: {bpe}\", exc_info=True)\n",
        "        await client.edit_message(processing_msg_event, f\"❌ پردازش متوقف شد. محتوای ارسالی با سیاست‌های ایمنی سازگار نیست.\")\n",
        "        # Do not delete uploaded_file_ref here, it's managed by Google\n",
        "        return None, None, None, google_audio_file_ref, files_to_cleanup_later # google_audio_file_ref might be None if upload failed\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_single_audio_file_operations for {original_name_base}: {e}\")\n",
        "        await client.edit_message(processing_msg_event, f\"❌ خطا در پردازش فایل صوتی ({original_name_base}): {str(e)[:100]}\")\n",
        "        return None, None, None, google_audio_file_ref, files_to_cleanup_later\n",
        "\n",
        "\n",
        "async def process_audio_file(event, audio_file_path: str, original_name_base: str, chat_id: int, processing_msg_event):\n",
        "    \"\"\"Handles splitting if necessary, then processes audio, generates summary and SRT for the whole.\"\"\"\n",
        "    all_local_files_to_cleanup = [audio_file_path] # Start with the input audio path\n",
        "    # google_uploaded_file_refs are not cleaned by us, Google manages them.\n",
        "\n",
        "    try:\n",
        "        audio_duration_ms = await get_audio_duration(audio_file_path)\n",
        "        needs_splitting = audio_duration_ms > MAX_DURATION_MS\n",
        "\n",
        "        chunk_paths = []\n",
        "        if needs_splitting:\n",
        "            await client.edit_message(\n",
        "                processing_msg_event,\n",
        "                f\"⚠️ فایل صوتی شما طولانی است ({audio_duration_ms/60000:.1f} دقیقه). در حال تقسیم به قطعات ~{MAX_DURATION_MINUTES} دقیقه‌ای و پردازش...\"\n",
        "            )\n",
        "            chunk_paths = await split_audio_file(audio_file_path, original_name_base, MAX_DURATION_MS)\n",
        "            all_local_files_to_cleanup.extend(chunk_paths)\n",
        "            if audio_file_path in chunk_paths: # If not split, original path is the only \"chunk\"\n",
        "                 pass # original audio_file_path is already in all_local_files_to_cleanup\n",
        "            elif audio_file_path not in chunk_paths and chunk_paths: # Original was split\n",
        "                # The original large file (audio_file_path) is implicitly cleaned if split_audio_file creates new files from it.\n",
        "                # If split_audio_file returns the original path (no split), it's handled.\n",
        "                pass\n",
        "\n",
        "\n",
        "        else:\n",
        "            logger.info(f\"Audio duration ({audio_duration_ms/60000:.2f} min) is under threshold, processing as single unit.\")\n",
        "            chunk_paths = [audio_file_path] # Process the original file as a single chunk\n",
        "\n",
        "        full_transcription_parts = []\n",
        "        # We need one audio_file_ref for the final summary if it's multimodal.\n",
        "        # Let's use the ref from the first chunk.\n",
        "        first_chunk_google_ref = None\n",
        "\n",
        "        for i, chunk_path in enumerate(chunk_paths):\n",
        "            chunk_name_base = f\"{original_name_base}_part{i+1}\" if needs_splitting else original_name_base\n",
        "            await client.edit_message(\n",
        "                processing_msg_event,\n",
        "                processing_msg_event.text + f\"\\n\\nProcessing chunk {i+1}/{len(chunk_paths)}: {Path(chunk_path).name}\"\n",
        "            )\n",
        "\n",
        "            transcription, _, _, google_ref, chunk_cleanup_files = await process_single_audio_file_operations(\n",
        "                audio_file_path=chunk_path,\n",
        "                original_name_base=chunk_name_base,\n",
        "                chat_id=chat_id,\n",
        "                processing_msg_event=processing_msg_event,\n",
        "                is_part_of_long_audio=needs_splitting # True if there are multiple chunks\n",
        "            )\n",
        "            all_local_files_to_cleanup.extend(chunk_cleanup_files)\n",
        "\n",
        "            if transcription:\n",
        "                full_transcription_parts.append(transcription)\n",
        "                if i == 0 and google_ref: # Save ref from first chunk\n",
        "                    first_chunk_google_ref = google_ref\n",
        "            else:\n",
        "                # If a chunk fails, we might stop or continue. For now, continue.\n",
        "                logger.warning(f\"Chunk {i+1} ({Path(chunk_path).name}) failed transcription. Skipping for combined output.\")\n",
        "                await client.edit_message(processing_msg_event, processing_msg_event.text + f\"\\n⚠️ خطایی در پردازش قطعه {i+1} رخ داد.\")\n",
        "\n",
        "\n",
        "        if not full_transcription_parts:\n",
        "            await client.edit_message(processing_msg_event, \"❌ پردازش هیچ بخشی از فایل صوتی موفقیت آمیز نبود.\")\n",
        "            return # Early exit\n",
        "\n",
        "        full_transcription = \"\\n\\n\".join(full_transcription_parts)\n",
        "        full_transcription_filename = f\"{original_name_base}_FULL_transcription.txt\"\n",
        "        full_transcription_path = TEMP_DIR / full_transcription_filename\n",
        "        with open(full_transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(full_transcription)\n",
        "        all_local_files_to_cleanup.append(str(full_transcription_path))\n",
        "\n",
        "        if needs_splitting: # If it was split, send the full transcription\n",
        "            await client.send_file(chat_id, str(full_transcription_path), caption=\"🎤 متن کامل پیاده‌سازی شده (از تمامی قطعات):\")\n",
        "\n",
        "        # Generate combined SRT and Summary if multiple chunks were processed OR if it was single file not processed by `is_part_of_long_audio=False` path\n",
        "        if needs_splitting: # For long audio, generate combined SRT and summary now\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\n⏳ در حال تولید زیرنویس (SRT) کامل...\")\n",
        "            combined_srt_content = await generate_persian_srt_google(full_transcription)\n",
        "            combined_srt_filename = f\"{original_name_base}_FULL_subtitles.srt\"\n",
        "            combined_srt_path = TEMP_DIR / combined_srt_filename\n",
        "            with open(combined_srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(combined_srt_content)\n",
        "            all_local_files_to_cleanup.append(str(combined_srt_path))\n",
        "            await client.send_file(chat_id, str(combined_srt_path), caption=\"🎬 فایل زیرنویس کامل (SRT):\")\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n✅ فایل زیرنویس کامل (SRT) ارسال شد.\")\n",
        "\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n\\n⏳ در حال تهیه خلاصه جامع کامل...\")\n",
        "            # Use transcription of all parts. If multimodal summary is desired, use first_chunk_google_ref\n",
        "            combined_summary = await summarize_audio_google(first_chunk_google_ref, full_transcription) # Pass ref if summarize_audio_google is adapted\n",
        "\n",
        "            summary_filename = f\"{original_name_base}_FULL_summary.md\"\n",
        "            summary_path = TEMP_DIR / summary_filename\n",
        "            with open(summary_path, \"w\", encoding=\"utf-8\") as f: f.write(combined_summary)\n",
        "            all_local_files_to_cleanup.append(str(summary_path))\n",
        "\n",
        "            await client.send_file(chat_id, str(summary_path), caption=\"📝 *خلاصه جامع محتوای کامل:*\", parse_mode='md')\n",
        "            await client.edit_message(processing_msg_event, processing_msg_event.text + \"\\n✅ خلاصه جامع کامل ارسال شد.\")\n",
        "\n",
        "        final_message = \"✅ پردازش فایل\"\n",
        "        if needs_splitting: final_message += f\" صوتی طولانی ({audio_duration_ms/60000:.1f} دقیقه)\"\n",
        "        final_message += \" با موفقیت تکمیل شد!\"\n",
        "        await client.edit_message(processing_msg_event, final_message)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Critical error in process_audio_file for {original_name_base}: {e}\")\n",
        "        await client.edit_message(processing_msg_event, f\"❌ خطای جدی در پردازش فایل صوتی: {str(e)[:100]}\")\n",
        "    finally:\n",
        "        # Cleanup all local temporary files accumulated\n",
        "        unique_cleanup_paths = list(set(all_local_files_to_cleanup)) # Remove duplicates\n",
        "        await cleanup_files_and_dirs(*unique_cleanup_paths)\n",
        "\n",
        "\n",
        "# --- Main Bot Event Handlers ---\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/start'))\n",
        "async def start(event):\n",
        "    sender = await event.get_sender()\n",
        "    logger.info(f\"/start from User {sender.id} in Chat {event.chat_id}\")\n",
        "    await event.reply(\n",
        "        \"👋 سلام! به ربات *LinguaScribe* خوش آمدید.\\n\\n\"\n",
        "        \"این ربات می‌تواند فایل‌های صوتی، ویدیویی یا ZIP را پردازش کند:\\n\"\n",
        "        \"🎤 **پیاده‌سازی متن دقیق**\\n\"\n",
        "        \"📝 **خلاصه‌سازی جامع و تخصصی** (مناسب آمادگی آزمون)\\n\"\n",
        "        \"🎬 **تولید زیرنویس SRT فارسی**\\n\"\n",
        "        \"📹 **تبدیل ویدیو به صوت** برای تحلیل\\n\"\n",
        "        \"🗜️ **پردازش فایل‌های ZIP** حاوی صوت یا متن\\n\\n\"\n",
        "        \"یک فایل صوتی (voice, audio), ویدیویی, یا فایل ZIP برای من ارسال کنید.\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/help'))\n",
        "async def help_command(event):\n",
        "    await event.reply(\n",
        "        \"🔍 **راهنمای LinguaScribe Bot**\\n\\n\"\n",
        "        \"1️⃣ یک فایل صوتی، ویدیویی، یا ZIP ارسال کنید.\\n\"\n",
        "        \"2️⃣ ربات به صورت خودکار آن را پردازش می‌کند.\\n\"\n",
        "        \"   - ویدیو به صوت تبدیل می‌شود.\\n\"\n",
        "        \"   - فایل‌های ZIP استخراج و محتوای پشتیبانی شده (صوت/متن) پردازش می‌شود.\\n\"\n",
        "        \"   - برای صوت: متن پیاده‌سازی، خلاصه جامع، و زیرنویس SRT ارائه می‌شود.\\n\"\n",
        "        \"   - برای متن (از ZIP): محتوا ترکیب و ارسال می‌شود.\\n\\n\"\n",
        "        \"📋 **نکات**:\\n\"\n",
        "        f\"• فایل‌های صوتی تا {MAX_DURATION_MINUTES} دقیقه به صورت یکجا، طولانی‌تر به صورت بخش‌بندی شده پردازش می‌شوند.\\n\"\n",
        "        \"• زبان اصلی فارسی است.\\n\\n\"\n",
        "        \"📌 **دستورات:** /start, /help\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.text and not e.text.startswith('/')))\n",
        "async def handle_text_message(event):\n",
        "    chat_id = event.chat_id\n",
        "    message_text = event.text\n",
        "    logger.info(f\"Text message in chat {chat_id}: {message_text[:50]}...\")\n",
        "    processing_msg = await event.reply(\"⏳ در حال پردازش پیام شما...\")\n",
        "    try:\n",
        "        bot_response = await get_bot_response_google(message_text)\n",
        "        await client.edit_message(processing_msg, bot_response)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling text message: {e}\", exc_info=True)\n",
        "        await client.edit_message(processing_msg, \"❌ متأسفانه در پردازش پیام شما مشکلی پیش آمد.\")\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.audio or e.voice or e.document))\n",
        "async def handle_media_message(event):\n",
        "    chat_id = event.chat_id\n",
        "    sender = await event.get_sender()\n",
        "    message_id = event.message.id\n",
        "    logger.info(f\"Media from User {sender.id} (msg_id:{message_id}) in Chat {chat_id}\")\n",
        "\n",
        "    media_item = None\n",
        "    file_name_attr = None\n",
        "    mime_type_attr = None\n",
        "    media_type_for_log = \"unknown\"\n",
        "\n",
        "    if event.audio:\n",
        "        media_item = event.audio\n",
        "        media_type_for_log = \"audio\"\n",
        "        mime_type_attr = getattr(media_item, 'mime_type', 'audio/ogg') # Default if not present\n",
        "        file_name_attr = getattr(media_item, 'attributes', [{}])[0].file_name if media_item.attributes and hasattr(media_item.attributes[0], 'file_name') else f\"audio_{message_id}.{mime_type_attr.split('/')[-1]}\"\n",
        "    elif event.voice:\n",
        "        media_item = event.voice\n",
        "        media_type_for_log = \"voice\"\n",
        "        mime_type_attr = getattr(media_item, 'mime_type', 'audio/ogg')\n",
        "        file_name_attr = f\"voice_{message_id}.ogg\"\n",
        "    elif event.document:\n",
        "        media_item = event.document\n",
        "        mime_type_attr = getattr(media_item, 'mime_type', '')\n",
        "        file_name_attr = getattr(media_item, 'attributes', [{}])[0].file_name if media_item.attributes and hasattr(media_item.attributes[0], 'file_name') else f\"document_{message_id}\"\n",
        "\n",
        "        if mime_type_attr.startswith('audio/'):\n",
        "            media_type_for_log = \"document_audio\"\n",
        "        elif mime_type_attr.startswith('video/'):\n",
        "            media_type_for_log = \"document_video\"\n",
        "        elif mime_type_attr in ['application/zip', 'application/x-zip-compressed'] or file_name_attr.lower().endswith('.zip'):\n",
        "            media_type_for_log = \"document_zip\"\n",
        "        else:\n",
        "            await event.reply(\"⚠️ این نوع فایل توسط ربات پشتیبانی نمی‌شود. لطفاً فایل صوتی، ویدیویی یا ZIP ارسال کنید.\")\n",
        "            return\n",
        "    else: # Should not happen given the func filter, but as a safeguard\n",
        "        return\n",
        "\n",
        "    processing_msg = await event.reply(\"⏳ در حال دریافت و بررسی فایل...\")\n",
        "\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    original_name_base = Path(file_name_attr).stem\n",
        "    # Use a generic download name, actual format determined later\n",
        "    download_path_initial = TEMP_DIR / f\"{original_name_base}_{timestamp}{Path(file_name_attr).suffix or '.dat'}\"\n",
        "\n",
        "    local_files_to_cleanup_main_handler = [str(download_path_initial)]\n",
        "\n",
        "    try:\n",
        "        await client.download_media(message=event.message, file=str(download_path_initial))\n",
        "        logger.info(f\"File {file_name_attr} ({media_type_for_log}) downloaded to {download_path_initial}\")\n",
        "        await client.edit_message(processing_msg, \"✅ فایل دریافت شد. در حال پردازش اولیه...\")\n",
        "\n",
        "        # --- ZIP File Handling ---\n",
        "        if media_type_for_log == \"document_zip\":\n",
        "            await client.edit_message(processing_msg, processing_msg.text + \"\\n🗜️ فایل ZIP شناسایی شد، در حال استخراج...\")\n",
        "            extraction_path = TEMP_EXTRACTION_DIR / f\"{original_name_base}_{timestamp}_extracted\"\n",
        "            extraction_path.mkdir(parents=True, exist_ok=True)\n",
        "            local_files_to_cleanup_main_handler.append(str(extraction_path)) # ensure extracted dir is cleaned\n",
        "\n",
        "            extracted_files_info = []\n",
        "            try:\n",
        "                with zipfile.ZipFile(download_path_initial, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(extraction_path)\n",
        "                logger.info(f\"ZIP extracted to {extraction_path}\")\n",
        "\n",
        "                # Process extracted files\n",
        "                combined_text_content = []\n",
        "                audio_files_in_zip = []\n",
        "\n",
        "                for item in extraction_path.rglob('*'): # Recurse through subdirectories\n",
        "                    if item.is_file():\n",
        "                        item_name_base = item.stem\n",
        "                        item_suffix_lower = item.suffix.lower()\n",
        "\n",
        "                        # Check for audio types\n",
        "                        if item_suffix_lower in ['.mp3', '.wav', '.ogg', '.m4a', '.opus', '.flac', '.aac']:\n",
        "                            audio_files_in_zip.append(item)\n",
        "                        # Check for text types\n",
        "                        elif item_suffix_lower in ['.txt', '.md', '.rtf']: # Add more text types if needed\n",
        "                            try:\n",
        "                                combined_text_content.append(item.read_text(encoding='utf-8'))\n",
        "                                logger.info(f\"Read text from {item.name}\")\n",
        "                            except Exception as e:\n",
        "                                logger.warning(f\"Could not read text file {item.name}: {e}\")\n",
        "\n",
        "                if audio_files_in_zip:\n",
        "                    await client.edit_message(processing_msg, processing_msg.text + f\"\\n🔊 {len(audio_files_in_zip)} فایل صوتی در ZIP یافت شد. پردازش آن‌ها...\")\n",
        "                    for i, audio_item_path in enumerate(audio_files_in_zip):\n",
        "                        zip_audio_name_base = f\"{original_name_base}_zip_audio{i+1}_{audio_item_path.stem}\"\n",
        "                        # Create a new processing message for each audio file to avoid super long message\n",
        "                        audio_proc_msg = await event.reply(f\"⏳ پردازش فایل صوتی {i+1}/{len(audio_files_in_zip)} از ZIP: {audio_item_path.name}\")\n",
        "                        await process_audio_file(event, str(audio_item_path), zip_audio_name_base, chat_id, audio_proc_msg)\n",
        "                        # Don't add audio_item_path to local_files_to_cleanup_main_handler, process_audio_file handles its copies/chunks.\n",
        "                        # The extraction_path itself will be cleaned, removing all original extracted files.\n",
        "\n",
        "                if combined_text_content:\n",
        "                    full_extracted_text = \"\\n\\n---\\n\\n\".join(combined_text_content)\n",
        "                    text_output_filename = f\"{original_name_base}_extracted_texts.txt\"\n",
        "                    text_output_path = TEMP_DIR / text_output_filename\n",
        "                    with open(text_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(full_extracted_text)\n",
        "                    local_files_to_cleanup_main_handler.append(str(text_output_path))\n",
        "                    await client.send_file(chat_id, str(text_output_path), caption=\"📜 متن‌های استخراج شده از فایل ZIP:\")\n",
        "                    await client.edit_message(processing_msg, processing_msg.text + \"\\n📜 محتوای متنی از ZIP ارسال شد.\")\n",
        "\n",
        "                if not audio_files_in_zip and not combined_text_content:\n",
        "                     await client.edit_message(processing_msg, processing_msg.text + \"\\n⚠️ هیچ فایل صوتی یا متنی قابل پردازشی در ZIP یافت نشد.\")\n",
        "                else:\n",
        "                     await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ پردازش محتوای ZIP تکمیل شد.\")\n",
        "\n",
        "            except zipfile.BadZipFile:\n",
        "                logger.error(f\"Bad ZIP file: {download_path_initial}\")\n",
        "                await client.edit_message(processing_msg, \"❌ فایل ZIP نامعتبر است.\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing ZIP file: {e}\", exc_info=True)\n",
        "                await client.edit_message(processing_msg, f\"❌ خطا در پردازش فایل ZIP: {e}\")\n",
        "            return # End of ZIP processing\n",
        "\n",
        "        # --- Video to Audio Conversion ---\n",
        "        actual_audio_file_to_process = download_path_initial\n",
        "        if media_type_for_log.startswith(\"document_video\") or mime_type_attr.startswith(\"video/\"):\n",
        "            await client.edit_message(processing_msg, processing_msg.text + \"\\n📹 فایل ویدیویی شناسایی شد، در حال تبدیل به صوت فشرده...\")\n",
        "            converted_audio_path = TEMP_DIR / f\"{original_name_base}_{timestamp}_converted.{AUDIO_OUTPUT_FORMAT}\"\n",
        "            try:\n",
        "                video_segment = AudioSegment.from_file(str(download_path_initial))\n",
        "                audio_only = video_segment.set_channels(1).set_frame_rate(AUDIO_SAMPLE_RATE)\n",
        "                audio_only.export(\n",
        "                    str(converted_audio_path),\n",
        "                    format=AUDIO_OUTPUT_FORMAT,\n",
        "                    codec=AUDIO_OUTPUT_CODEC if AUDIO_OUTPUT_FORMAT == \"ogg\" else None,\n",
        "                    bitrate=AUDIO_OUTPUT_BITRATE\n",
        "                )\n",
        "                actual_audio_file_to_process = converted_audio_path\n",
        "                local_files_to_cleanup_main_handler.append(str(converted_audio_path)) # Add converted file for cleanup\n",
        "                logger.info(f\"Video converted to audio: {converted_audio_path}\")\n",
        "                await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ ویدیو به صوت تبدیل شد.\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error converting video to audio: {e}\", exc_info=True)\n",
        "                await client.edit_message(processing_msg, f\"❌ خطا در تبدیل ویدیو به صوت: {e}. تلاش برای پردازش فایل اصلی (اگر صوت باشد)...\")\n",
        "                # Fallback to actual_audio_file_to_process = download_path_initial if conversion fails\n",
        "                # but it might not be an audio file. For now, we assume it fails cleanly if not convertible.\n",
        "                if not mime_type_attr.startswith('audio/'): # If original was not audio, then fail\n",
        "                     await client.edit_message(processing_msg, processing_msg.text + \"\\n❌ فایل اصلی ویدیو قابل پردازش مستقیم به عنوان صوت نیست.\")\n",
        "                     return\n",
        "\n",
        "        # --- Audio Processing (Original Audio, Document Audio, or Converted Video) ---\n",
        "        if media_type_for_log.startswith(\"audio\") or media_type_for_log.startswith(\"voice\") or \\\n",
        "           media_type_for_log.startswith(\"document_audio\") or actual_audio_file_to_process != download_path_initial: # i.e. video was converted\n",
        "\n",
        "            # Ensure the file is in a format pydub can handle well for duration check and potential re-encoding/splitting\n",
        "            # Re-encoding to a standard format (like ogg opus) can help.\n",
        "            standardized_audio_path = TEMP_DIR / f\"{Path(actual_audio_file_to_process).stem}_standardized.{AUDIO_OUTPUT_FORMAT}\"\n",
        "            try:\n",
        "                audio_seg = AudioSegment.from_file(str(actual_audio_file_to_process))\n",
        "                # Standardize: mono, 16kHz, ogg opus\n",
        "                audio_seg = audio_seg.set_channels(1).set_frame_rate(AUDIO_SAMPLE_RATE)\n",
        "                audio_seg.export(\n",
        "                    str(standardized_audio_path),\n",
        "                    format=AUDIO_OUTPUT_FORMAT,\n",
        "                    codec=AUDIO_OUTPUT_CODEC if AUDIO_OUTPUT_FORMAT == \"ogg\" else None,\n",
        "                    bitrate=AUDIO_OUTPUT_BITRATE\n",
        "                )\n",
        "                logger.info(f\"Audio standardized to: {standardized_audio_path}\")\n",
        "                if str(actual_audio_file_to_process) != str(download_path_initial): # if it was converted video\n",
        "                    local_files_to_cleanup_main_handler.append(str(actual_audio_file_to_process)) # The intermediate converted video audio\n",
        "                actual_audio_file_to_process = standardized_audio_path\n",
        "                local_files_to_cleanup_main_handler.append(str(standardized_audio_path))\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Could not standardize audio {actual_audio_file_to_process}: {e}. Proceeding with original/converted.\")\n",
        "                # actual_audio_file_to_process remains as it was\n",
        "\n",
        "            await process_audio_file(event, str(actual_audio_file_to_process), original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # If it was just a document that wasn't audio, video, or zip, it would have been filtered earlier.\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Unhandled error in handle_media_message for {file_name_attr}: {e}\")\n",
        "        try:\n",
        "            await client.edit_message(processing_msg, \"❌ متأسفانه یک خطای ناشناخته در پردازش فایل شما رخ داد.\")\n",
        "        except: # If editing message fails (e.g., message deleted)\n",
        "            pass\n",
        "    finally:\n",
        "        # General cleanup for files created directly in this handler (like initial download)\n",
        "        # Files created by sub-processors (process_audio_file) are cleaned by them.\n",
        "        unique_cleanup_paths_main = list(set(local_files_to_cleanup_main_handler))\n",
        "        await cleanup_files_and_dirs(*unique_cleanup_paths_main)\n",
        "        # Clean the entire extraction base dir if it was used\n",
        "        if TEMP_EXTRACTION_DIR.exists():\n",
        "            await cleanup_files_and_dirs(TEMP_EXTRACTION_DIR)\n",
        "            TEMP_EXTRACTION_DIR.mkdir(parents=True, exist_ok=True) # Recreate for next use\n",
        "\n",
        "\n",
        "# --- Main Entry Point ---\n",
        "async def main():\n",
        "    logger.info(\"Starting LinguaScribe Bot...\")\n",
        "\n",
        "    # Clear temp directory at startup (robustly)\n",
        "    if TEMP_DIR.exists():\n",
        "        try:\n",
        "            shutil.rmtree(TEMP_DIR)\n",
        "            logger.info(f\"Cleaned up old temp directory: {TEMP_DIR}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error cleaning up temp directory {TEMP_DIR} at startup: {e}\")\n",
        "    TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    TEMP_EXTRACTION_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "    await client.start(bot_token=BOT_TOKEN)\n",
        "    me = await client.get_me()\n",
        "    logger.info(f\"Bot @{me.username} started successfully!\")\n",
        "    logger.info(f\"Using {len(GOOGLE_API_KEYS_LIST)} Google API Key(s).\")\n",
        "    logger.info(f\"Initial Google API Key: ...{_active_google_api_key[-4:] if _active_google_api_key else 'N/A'}\")\n",
        "\n",
        "    try:\n",
        "        await client.run_until_disconnected()\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"Bot stopped by user (Ctrl+C)\")\n",
        "    finally:\n",
        "        await client.disconnect()\n",
        "        logger.info(\"Bot disconnected.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ],
      "metadata": {
        "id": "Bnmj3r78OGC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The old code for one job only:\n",
        "## it do transcribe and get text srt and summary"
      ],
      "metadata": {
        "id": "I8_WmnPRSWoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS1cE8WIGs_O",
        "outputId": "0bc9e696-78cd-46ff-b0de-dff48d1c7188"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Error during translation: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 306, in translate_to_persian_google\n",
            "    translation = response.text.strip()\n",
            "                  ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 463, in text\n",
            "    parts = self.parts\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 446, in parts\n",
            "    raise ValueError(msg)\n",
            "ValueError: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "ERROR:__main__:Error generating SRT: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 347, in generate_persian_srt_google\n",
            "    persian_translation = await translate_to_persian_google(transcription)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 306, in translate_to_persian_google\n",
            "    translation = response.text.strip()\n",
            "                  ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 463, in text\n",
            "    parts = self.parts\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 446, in parts\n",
            "    raise ValueError(msg)\n",
            "ValueError: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "ERROR:__main__:Error in process_long_audio: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 438, in process_long_audio\n",
            "    srt_content = await generate_persian_srt_google(full_transcription)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 347, in generate_persian_srt_google\n",
            "    persian_translation = await translate_to_persian_google(transcription)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-ec2a3394cdbd>\", line 306, in translate_to_persian_google\n",
            "    translation = response.text.strip()\n",
            "                  ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 463, in text\n",
            "    parts = self.parts\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\", line 446, in parts\n",
            "    raise ValueError(msg)\n",
            "ValueError: Invalid operation: The `response.parts` quick accessor requires a single candidate, but but `response.candidates` is empty.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import re\n",
        "import math\n",
        "from telethon import TelegramClient, events, Button\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from pydub import AudioSegment  # New import for audio processing\n",
        "\n",
        "# --- Configuration ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    API_ID = int(userdata.get('TELEGRAM_API_ID'))\n",
        "    API_HASH = userdata.get('TELEGRAM_API_HASH')\n",
        "    BOT_TOKEN = userdata.get('TELEGRAM_BOT_TTS')\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY1')  # Main key\n",
        "    GOOGLE_SUMMARY_API_KEY = userdata.get('GOOGLE_SUMMARY_API_KEY')  # Specific key for summaries\n",
        "\n",
        "    if not all([API_ID, API_HASH, BOT_TOKEN, GOOGLE_API_KEY, GOOGLE_SUMMARY_API_KEY]):\n",
        "        raise ValueError(\"One or more secrets are missing.\")\n",
        "    if GOOGLE_API_KEY == GOOGLE_SUMMARY_API_KEY:\n",
        "        print(\"Main Google API Key and Summary API Key are the same. No key switching needed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading secrets: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Apply nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Initial Google AI SDK Configuration (with the MAIN key) ---\n",
        "try:\n",
        "    logger.info(f\"Configuring Google AI SDK with MAIN API key ending with ...{GOOGLE_API_KEY[-4:]}\")\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error configuring Google AI SDK with main key: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_CONFIG = {\n",
        "    \"text_model_name\": \"gemini-2.5-flash-preview-04-17-thinking\",\n",
        "    \"multimodal_model_name\": \"gemini-1.5-flash-latest\",\n",
        "    \"generation_config\": {\"temperature\": 0.5},\n",
        "    \"summarization_generation_config\": {\"temperature\": 0.6},\n",
        "    SAFETY_SETTINGS = [\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_HARASSMENT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_HATE_SPEECH, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "    {\"category\": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, \"threshold\": HarmBlockThreshold.BLOCK_ONLY_HIGH},\n",
        "]\n",
        "}\n",
        "\n",
        "# Telethon Client Initialization\n",
        "session_name = f\"bot_session_{BOT_TOKEN.split(':')[0]}\"  # Ensure unique session name\n",
        "client = TelegramClient(session_name, API_ID, API_HASH)\n",
        "TEMP_DIR = Path(\"./temp_audio_telethon_bot\")\n",
        "TEMP_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Audio Processing Constants ---\n",
        "MAX_DURATION_MINUTES = 30  # Maximum duration in minutes before splitting\n",
        "MAX_DURATION_MS = MAX_DURATION_MINUTES * 60 * 1000  # Convert to milliseconds\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def get_gemini_model_instance(model_name_key, custom_generation_config_key=None):\n",
        "    \"\"\"\n",
        "    Creates and returns a Gemini model instance.\n",
        "    ASSUMES genai IS ALREADY CONFIGURED with the correct API key FOR THIS CALL.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model_name_actual = MODEL_CONFIG[model_name_key]\n",
        "        generation_config_actual = MODEL_CONFIG[custom_generation_config_key] if custom_generation_config_key else MODEL_CONFIG[\"generation_config\"]\n",
        "\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=model_name_actual,\n",
        "            generation_config=generation_config_actual,\n",
        "            safety_settings=MODEL_CONFIG[\"safety_settings\"]\n",
        "        )\n",
        "        logger.info(f\"Created model instance for {model_name_actual} (current global API key is in use)\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating Gemini model {model_name_actual}: {e}\")\n",
        "        raise\n",
        "\n",
        "async def cleanup_files(*files):\n",
        "    for file_path in files:\n",
        "        if file_path and Path(file_path).exists():\n",
        "            try:\n",
        "                Path(file_path).unlink()\n",
        "                logger.info(f\"Deleted temporary file: {file_path}\")\n",
        "            except OSError as e:\n",
        "                logger.error(f\"Error deleting file {file_path}: {e}\")\n",
        "\n",
        "def generate_srt_with_timecodes(segmented_text):\n",
        "    lines = [line for line in segmented_text.split(\"\\n\") if line.strip()]\n",
        "    if not lines:\n",
        "        return \"1\\n00:00:00,000 --> 00:00:05,000\\n(محتوایی برای زمان‌بندی وجود ندارد)\\n\"\n",
        "    srt_content = []\n",
        "    current_time_total_seconds = 0\n",
        "    segment_duration_seconds = 5\n",
        "    for i, line in enumerate(lines):\n",
        "        start_seconds = current_time_total_seconds\n",
        "        end_seconds = current_time_total_seconds + segment_duration_seconds\n",
        "        def format_time(s):\n",
        "            return f\"{int(s // 3600):02}:{int(s % 3600 // 60):02}:{int(s % 60):02},{int((s % 1) * 1000):03}\"\n",
        "        srt_content.append(str(i + 1))\n",
        "        srt_content.append(f\"{format_time(start_seconds)} --> {format_time(end_seconds)}\")\n",
        "        srt_content.append(line)\n",
        "        srt_content.append(\"\")\n",
        "        current_time_total_seconds = end_seconds\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "# --- New Audio Splitting Functions ---\n",
        "\n",
        "async def get_audio_duration(file_path):\n",
        "    \"\"\"Get the duration of an audio file in milliseconds.\"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        duration_ms = len(audio)\n",
        "        logger.info(f\"Audio duration: {duration_ms/1000:.2f} seconds ({duration_ms/60000:.2f} minutes)\")\n",
        "        return duration_ms\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting audio duration: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def split_audio_file(file_path, base_name, max_duration_ms=MAX_DURATION_MS):\n",
        "    \"\"\"\n",
        "    Split an audio file into chunks of max_duration_ms.\n",
        "    Returns a list of paths to the split audio files.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        total_duration_ms = len(audio)\n",
        "\n",
        "        if total_duration_ms <= max_duration_ms:\n",
        "            logger.info(f\"Audio is shorter than {MAX_DURATION_MINUTES} minutes, no need to split\")\n",
        "            return [file_path]\n",
        "\n",
        "        # Calculate number of chunks needed\n",
        "        num_chunks = math.ceil(total_duration_ms / max_duration_ms)\n",
        "        logger.info(f\"Splitting audio into {num_chunks} chunks of {MAX_DURATION_MINUTES} minutes each\")\n",
        "\n",
        "        chunk_paths = []\n",
        "        for i in range(num_chunks):\n",
        "            start_ms = i * max_duration_ms\n",
        "            end_ms = min((i + 1) * max_duration_ms, total_duration_ms)\n",
        "\n",
        "            chunk = audio[start_ms:end_ms]\n",
        "            chunk_filename = f\"{base_name}_part{i+1}.ogg\"\n",
        "            chunk_path = TEMP_DIR / chunk_filename\n",
        "\n",
        "            logger.info(f\"Exporting chunk {i+1}/{num_chunks} to {chunk_path}\")\n",
        "            chunk.export(str(chunk_path), format=\"ogg\")\n",
        "            chunk_paths.append(str(chunk_path))\n",
        "\n",
        "        logger.info(f\"Successfully split audio into {len(chunk_paths)} chunks\")\n",
        "        return chunk_paths\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error splitting audio file: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "# --- Google AI API Call Functions ---\n",
        "\n",
        "async def transcribe_audio_google(file_path):\n",
        "    logger.info(f\"Transcribing audio file: {file_path}\")\n",
        "    google_audio_file_obj = None\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"multimodal_model_name\")  # Assumes main key is active\n",
        "        logger.info(\"Uploading audio file for transcription...\")\n",
        "        # upload_file is synchronous, so run in a thread\n",
        "        google_audio_file_obj = await asyncio.to_thread(genai.upload_file, path=file_path)\n",
        "        logger.info(f\"Audio file uploaded: {google_audio_file_obj.name}\")\n",
        "\n",
        "        prompt = \"Please transcribe the audio provided accurately. Return ONLY the plain text transcription.\"\n",
        "\n",
        "        # Run the synchronous generate_content in a thread\n",
        "        response = await asyncio.to_thread(\n",
        "            model.generate_content,\n",
        "            [prompt, google_audio_file_obj]  # Pass contents directly\n",
        "        )\n",
        "\n",
        "        transcription = response.text.strip()\n",
        "\n",
        "        if not transcription:\n",
        "             logger.warning(\"Transcription response was empty.\")\n",
        "             raise ValueError(\"Transcription failed: No text returned.\")\n",
        "        logger.info(\"Transcription successful.\")\n",
        "        return transcription, google_audio_file_obj\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during transcription: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def summarize_audio_google(audio_file_ref, transcription_context):\n",
        "    logger.info(\"Summarizing audio content...\")\n",
        "    # --- API Key Switching Logic ---\n",
        "    current_global_key_is_main = True  # Assume it's the main key initially\n",
        "\n",
        "    if GOOGLE_API_KEY != GOOGLE_SUMMARY_API_KEY and GOOGLE_SUMMARY_API_KEY:\n",
        "        try:\n",
        "            logger.info(f\"Temporarily configuring genai for GOOGLE_SUMMARY_API_KEY (ends ...{GOOGLE_SUMMARY_API_KEY[-4:]}) for summarization\")\n",
        "            genai.configure(api_key=GOOGLE_SUMMARY_API_KEY)\n",
        "            current_global_key_is_main = False  # Now it's the summary key\n",
        "\n",
        "            model = get_gemini_model_instance(\"multimodal_model_name\", \"summarization_generation_config\")\n",
        "\n",
        "            summary_prompt = \"\"\"\n",
        "شما یک دستیار متخصص در تحلیل و خلاصه‌سازی محتوای صوتی به زبان فارسی هستید.\n",
        "فایل صوتی ارائه شده است. متن پیاده‌سازی شده اولیه آن نیز برای کمک به زمینه و کلمات کلیدی در زیر آمده است.\n",
        "لطفاً این فایل صوتی را با دقت تحلیل کرده و یک خلاصه جامع و دقیق به زبان فارسی روان تهیه کنید که شامل موارد زیر باشد:\n",
        "\n",
        "متن پیاده‌سازی شده اولیه (برای کمک به زمینه):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "دستورالعمل‌های خلاصه‌سازی:\n",
        "1.  **خلاصه کلی (۲-۳ پاراگراف):** موضوع اصلی و هدف، زمینه بحث، نتیجه‌گیری اصلی.\n",
        "2.  **نکات کلیدی و برجسته:** مهم‌ترین نقاط، آمار/ارقام مهم، تاریخ‌ها/رویدادهای کلیدی (حداقل ۵ مورد).\n",
        "3.  **جزئیات و استدلال‌های مهم:** استدلال‌های اصلی، مثال‌ها/موارد خاص، نقل قول‌های مهم (حداکثر ۲-۳).\n",
        "4.  **تحلیل محتوا (در صورت امکان):** ارتباط مفاهیم، نقاط قوت/ضعف، پیشنهادات/راهکارها.\n",
        "5.  **دسته‌بندی موضوعی (اختیاری):** موضوعات فرعی و ارتباطشان با موضوع اصلی.\n",
        "\n",
        "**خروجی مورد انتظار:**\n",
        "*   خلاصه کاملاً به زبان فارسی سلیس و روان.\n",
        "*   ساختاریافته با تیترهای مشخص فارسی (مانند \"خلاصه کلی\", \"نکات کلیدی و برجسته\").\n",
        "*   استفاده از نشانه‌گذاری مناسب (لیست‌ها).\n",
        "*   طول متناسب با محتوای صوتی.\n",
        "*   فقط و فقط خلاصه نهایی مطابق ساختار درخواستی، بدون عبارت مقدماتی یا توضیحات اضافی.\n",
        "\"\"\"\n",
        "            response = await asyncio.to_thread(\n",
        "                model.generate_content,\n",
        "                [summary_prompt.format(transcription_context=transcription_context), audio_file_ref]\n",
        "            )\n",
        "            summary = response.text.strip()\n",
        "\n",
        "            if not summary:\n",
        "                logger.warning(\"Summarization response was empty.\")\n",
        "                raise ValueError(\"Summarization failed: No text returned.\")\n",
        "            logger.info(\"Summarization successful.\")\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during summarization: {e}\", exc_info=True)\n",
        "            raise\n",
        "        finally:\n",
        "            # --- Switch back to MAIN API key ---\n",
        "            if not current_global_key_is_main:  # If we switched to summary key\n",
        "                logger.info(f\"Switching genai config back to main GOOGLE_API_KEY (ends ...{GOOGLE_API_KEY[-4:]})\")\n",
        "                genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    else:  # Keys are the same, or no specific summary key, so use the already configured main key\n",
        "        try:\n",
        "            logger.info(\"Using main GOOGLE_API_KEY for summarization as keys are same or summary key not distinct.\")\n",
        "            model = get_gemini_model_instance(\"multimodal_model_name\", \"summarization_generation_config\")\n",
        "            summary_prompt = f\"\"\"\n",
        "شما یک دستیار متخصص در تحلیل و خلاصه‌سازی محتوای صوتی به زبان فارسی هستید.\n",
        "فایل صوتی ارائه شده است. متن پیاده‌سازی شده اولیه آن نیز برای کمک به زمینه و کلمات کلیدی در زیر آمده است.\n",
        "لطفاً این فایل صوتی را با دقت تحلیل کرده و یک خلاصه جامع و دقیق به زبان فارسی روان تهیه کنید که شامل موارد زیر باشد:\n",
        "\n",
        "متن پیاده‌سازی شده اولیه (برای کمک به زمینه):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "دستورالعمل‌های خلاصه‌سازی:\n",
        "1.  **خلاصه کلی (۲-۳ پاراگراف):** موضوع اصلی و هدف، زمینه بحث، نتیجه‌گیری اصلی.\n",
        "2.  **نکات کلیدی و برجسته:** مهم‌ترین نقاط، آمار/ارقام مهم، تاریخ‌ها/رویدادهای کلیدی (حداقل ۵ مورد).\n",
        "3.  **جزئیات و استدلال‌های مهم:** استدلال‌های اصلی، مثال‌ها/موارد خاص، نقل قول‌های مهم (حداکثر ۲-۳).\n",
        "4.  **تحلیل محتوا (در صورت امکان):** ارتباط مفاهیم، نقاط قوت/ضعف، پیشنهادات/راهکارها.\n",
        "5.  **دسته‌بندی موضوعی (اختیاری):** موضوعات فرعی و ارتباطشان با موضوع اصلی.\n",
        "\n",
        "**خروجی مورد انتظار:**\n",
        "*   خلاصه کاملاً به زبان فارسی سلیس و روان.\n",
        "*   ساختاریافته با تیترهای مشخص فارسی (مانند \"خلاصه کلی\", \"نکات کلیدی و برجسته\").\n",
        "*   استفاده از نشانه‌گذاری مناسب (لیست‌ها).\n",
        "*   طول متناسب با محتوای صوتی.\n",
        "*   فقط و فقط خلاصه نهایی مطابق ساختار درخواستی، بدون عبارت مقدماتی یا توضیحات اضافی.\n",
        "\"\"\"\n",
        "            response = await asyncio.to_thread(\n",
        "                model.generate_content,\n",
        "                [summary_prompt.format(transcription_context=transcription_context), audio_file_ref]\n",
        "            )\n",
        "            summary = response.text.strip()\n",
        "            if not summary:\n",
        "                logger.warning(\"Summarization response was empty.\")\n",
        "                raise ValueError(\"Summarization failed: No text returned.\")\n",
        "            logger.info(\"Summarization successful.\")\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during summarization with main key: {e}\", exc_info=True)\n",
        "            raise\n",
        "\n",
        "async def translate_to_persian_google(text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    if not text or not text.strip(): return \"\"\n",
        "    logger.info(\"Translating text to Persian...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        prompt = f'Translate the following text to Persian:\\n\\n\"{text}\"\\n\\nReturn ONLY the Persian translation.'\n",
        "        response = await asyncio.to_thread(model.generate_content, prompt)\n",
        "        translation = response.text.strip()\n",
        "        if not translation:\n",
        "            logger.warning(\"Translation response was empty.\")\n",
        "            raise ValueError(\"Translation failed: No text returned.\")\n",
        "        logger.info(\"Translation successful.\")\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during translation: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def segment_persian_text_google(persian_text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    logger.info(\"Segmenting Persian text for SRT...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        segmentation_prompt = f\"\"\"Take the following Persian text and break it into suitable subtitle segments. Each segment should be on a new line. Aim for natural breaks and readable lengths for subtitles.\n",
        "Return ONLY the segmented text, with each segment on a new line.\n",
        "Persian text:\n",
        "---\n",
        "{persian_text}\n",
        "---\"\"\"\n",
        "        response = await asyncio.to_thread(model.generate_content, segmentation_prompt)\n",
        "        segmented_text = response.text.strip()\n",
        "\n",
        "        if not segmented_text:  # Fallback\n",
        "            logger.warning(\"LLM Segmentation response was empty. Using regex fallback.\")\n",
        "            segments = re.split(r'[।\\.؟!\\n]+', persian_text)\n",
        "            segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "            if not segmented_text: raise ValueError(\"Segmentation failed: No text from LLM or fallback.\")\n",
        "        logger.info(\"Segmentation successful.\")\n",
        "        return segmented_text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during LLM segmentation: {e}. Using regex fallback.\", exc_info=True)\n",
        "        segments = re.split(r'[।\\.؟!\\n]+', persian_text)  # Fallback on any error\n",
        "        segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "        if not segmented_text: raise ValueError(f\"Segmentation failed: Error '{e}' and fallback also yielded no text.\")\n",
        "        return segmented_text\n",
        "\n",
        "async def generate_persian_srt_google(transcription):\n",
        "    logger.info(\"Generating Persian SRT...\")\n",
        "    try:\n",
        "        persian_translation = await translate_to_persian_google(transcription)\n",
        "        if not persian_translation: raise ValueError(\"Translation step failed for SRT.\")\n",
        "        segmented_persian_text = await segment_persian_text_google(persian_translation)\n",
        "        if not segmented_persian_text: raise ValueError(\"Segmentation step failed for SRT.\")\n",
        "        srt_content = generate_srt_with_timecodes(segmented_persian_text)\n",
        "        logger.info(\"SRT generation successful.\")\n",
        "        return srt_content\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating SRT: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def get_bot_response_google(message_text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    logger.info(f\"Getting bot response for: {message_text[:50]}...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        prompt = f\"\"\"You are LinguaScribe_Bot, a helpful Telegram assistant. The user's language is Persian.\n",
        "User says: \"{message_text}\"\n",
        "Provide a concise and helpful response in Persian. If the user sends audio, you will have received the transcription as 'messageText'.\n",
        "If they ask about services, mention audio transcription to text (پیاده‌سازی صوت), Persian translation (ترجمه به فارسی), SRT generation (تولید فایل زیرنویس SRT), and audio summarization (خلاصه‌سازی صوت).\n",
        "Keep responses brief. If the input is non-sensical or just a greeting, respond politely and briefly in Persian.\n",
        "Return ONLY the bot's reply.\"\"\"\n",
        "        response = await asyncio.to_thread(model.generate_content, prompt)\n",
        "        reply = response.text.strip()\n",
        "        if not reply:\n",
        "            logger.warning(\"Bot response generation was empty.\")\n",
        "            return \"متاسفانه در حال حاضر قادر به پاسخگویی نیستم.\"\n",
        "        logger.info(\"Bot response generated.\")\n",
        "        return reply\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting bot response: {e}\", exc_info=True)\n",
        "        return \"متاسفانه در پردازش درخواست شما مشکلی پیش آمد.\"\n",
        "\n",
        "# --- New Function for Processing Long Audio ---\n",
        "async def process_long_audio(event, download_path, original_name_base, chat_id, processing_msg):\n",
        "    \"\"\"Process a long audio file by splitting it into chunks and processing each chunk\"\"\"\n",
        "    try:\n",
        "        # Check audio duration\n",
        "        audio_duration_ms = await get_audio_duration(download_path)\n",
        "\n",
        "        if audio_duration_ms <= MAX_DURATION_MS:\n",
        "            # Audio is shorter than threshold, process normally\n",
        "            logger.info(f\"Audio duration ({audio_duration_ms/60000:.2f} min) is under threshold, processing normally\")\n",
        "            return await process_single_audio(str(download_path), original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # Audio is longer than threshold, need to split\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"⚠️ فایل صوتی شما طولانی است ({audio_duration_ms/60000:.1f} دقیقه). در حال تقسیم به قطعات {MAX_DURATION_MINUTES} دقیقه‌ای و پردازش...\"\n",
        "        )\n",
        "\n",
        "        # Split the audio file\n",
        "        chunk_paths = await split_audio_file(download_path, original_name_base)\n",
        "\n",
        "        # Process each chunk and collect transcriptions\n",
        "        all_transcriptions = []\n",
        "        all_uploaded_refs = []  # Track all uploaded file references for cleanup\n",
        "\n",
        "        for i, chunk_path in enumerate(chunk_paths):\n",
        "            await client.edit_message(\n",
        "                processing_msg,\n",
        "                processing_msg.text + f\"\\n\\n⏳ در حال پیاده‌سازی متن قطعه {i+1} از {len(chunk_paths)}...\"\n",
        "            )\n",
        "\n",
        "            chunk_transcription, chunk_ref = await transcribe_audio_google(chunk_path)\n",
        "            all_uploaded_refs.append(chunk_ref)\n",
        "            all_transcriptions.append(chunk_transcription)\n",
        "\n",
        "            await client.edit_message(\n",
        "                processing_msg,\n",
        "                processing_msg.text + f\"\\n✅ پیاده‌سازی قطعه {i+1} انجام شد.\"\n",
        "            )\n",
        "\n",
        "        # Combine all transcriptions\n",
        "        full_transcription = \"\\n\\n\".join(all_transcriptions)\n",
        "\n",
        "        # Save combined transcription\n",
        "        transcription_filename = f\"{original_name_base}_full_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(full_transcription)\n",
        "\n",
        "        # Send the combined transcription\n",
        "        await client.send_file(\n",
        "            chat_id,\n",
        "            str(transcription_path),\n",
        "            caption=\"🎤 متن کامل پیاده‌سازی شده:\"\n",
        "        )\n",
        "\n",
        "        # Generate SRT from combined transcription\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال تولید زیرنویس (SRT) کامل...\")\n",
        "        srt_content = await generate_persian_srt_google(full_transcription)\n",
        "        srt_filename = f\"{original_name_base}_full_subtitles.srt\"\n",
        "        srt_path = TEMP_DIR / srt_filename\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_content)\n",
        "        await client.send_file(chat_id, str(srt_path), caption=\"🎬 فایل زیرنویس کامل (SRT):\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ فایل زیرنویس (SRT) ارسال شد.\")\n",
        "\n",
        "        # Generate summary using the first chunk's audio reference and the full transcription\n",
        "        # (since we can't combine audio files for the API, we'll use one chunk but provide full transcription)\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال تهیه خلاصه کلی...\")\n",
        "        summary = await summarize_audio_google(all_uploaded_refs[0], full_transcription)\n",
        "        await client.send_message(\n",
        "            chat_id,\n",
        "            f\"📝 *خلاصه محتوای کامل:*\\n\\n{summary}\",\n",
        "            parse_mode='md'\n",
        "        )\n",
        "\n",
        "        # Final status message\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"✅ پردازش فایل صوتی {audio_duration_ms/60000:.1f} دقیقه‌ای شما با موفقیت تکمیل شد.\"\n",
        "        )\n",
        "\n",
        "        # Return all files for cleanup\n",
        "        return all_uploaded_refs, [download_path, transcription_path, srt_path] + chunk_paths\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_long_audio: {e}\")\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"❌ خطا در پردازش فایل صوتی بلند: {str(e)}\"\n",
        "        )\n",
        "        return [], [download_path]\n",
        "\n",
        "# --- Function to Process a Single Audio File (for reuse) ---\n",
        "async def process_single_audio(file_path, original_name_base, chat_id, processing_msg):\n",
        "    \"\"\"Process a single audio file and return the uploaded ref and files for cleanup\"\"\"\n",
        "    try:\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال پیاده‌سازی متن...\")\n",
        "        transcription, google_audio_file_uploaded_ref = await transcribe_audio_google(file_path)\n",
        "\n",
        "        transcription_filename = f\"{original_name_base}_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcription)\n",
        "\n",
        "        await client.send_file(chat_id, str(transcription_path), caption=\"🎤 متن پیاده‌سازی شده:\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ متن پیاده‌سازی و ارسال شد.\")\n",
        "\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال تهیه خلاصه...\")\n",
        "        summary = await summarize_audio_google(google_audio_file_uploaded_ref, transcription)\n",
        "        await client.send_message(chat_id, f\"📝 *خلاصه محتوا:*\\n\\n{summary}\", parse_mode='md')\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ خلاصه ارسال شد.\")\n",
        "\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال تولید زیرنویس (SRT)...\")\n",
        "        srt_content = await generate_persian_srt_google(transcription)\n",
        "        srt_filename = f\"{original_name_base}_subtitles.srt\"\n",
        "        srt_path = TEMP_DIR / srt_filename\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_content)\n",
        "        await client.send_file(chat_id, str(srt_path), caption=\"🎬 فایل زیرنویس (SRT):\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ فایل زیرنویس (SRT) ارسال شد.\")\n",
        "        await client.edit_message(processing_msg, \"✅ پردازش فایل صوتی با موفقیت تکمیل شد!\")\n",
        "\n",
        "        # Return references and paths for cleanup\n",
        "        return [google_audio_file_uploaded_ref], [file_path, transcription_path, srt_path]\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_single_audio: {e}\")\n",
        "        await client.edit_message(processing_msg, f\"❌ خطا در پردازش فایل صوتی: {str(e)}\")\n",
        "        return [], [file_path]  # Return empty refs and only the original file for cleanup\n",
        "\n",
        "# --- Main Bot Event Handlers ---\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/start'))\n",
        "async def start(event):\n",
        "    sender = await event.get_sender()\n",
        "    chat_id = event.chat_id\n",
        "    logger.info(f\"New /start command from User {sender.id} in Chat {chat_id}\")\n",
        "\n",
        "    await event.reply(\n",
        "        \"👋 سلام! به ربات *LinguaScribe* خوش آمدید.\\n\\n\"\n",
        "        \"این ربات می‌تواند:\\n\"\n",
        "        \"🎤 **پیاده‌سازی متن**: فایل‌های صوتی را به متن تبدیل کند\\n\"\n",
        "        \"📝 **خلاصه‌سازی**: محتوای صوتی را خلاصه کند\\n\"\n",
        "        \"🎬 **زیرنویس**: فایل SRT فارسی تولید کند\\n\\n\"\n",
        "        \"برای شروع، یک فایل صوتی برای من ارسال کنید.\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/help'))\n",
        "async def help_command(event):\n",
        "    await event.reply(\n",
        "        \"🔍 **راهنمای استفاده از LinguaScribe Bot**\\n\\n\"\n",
        "        \"کاربرد:\\n\"\n",
        "        \"1️⃣ یک فایل صوتی (voice message, audio file) ارسال کنید\\n\"\n",
        "        \"2️⃣ ربات به صورت خودکار:\\n\"\n",
        "        \"   - متن پیاده‌سازی شده را ارسال می‌کند\\n\"\n",
        "        \"   - خلاصه‌ای از محتوا تهیه می‌کند\\n\"\n",
        "        \"   - فایل زیرنویس SRT تولید می‌کند\\n\\n\"\n",
        "        \"📋 **نکات مهم**:\\n\"\n",
        "        \"• فایل‌های صوتی تا ۳۰ دقیقه پشتیبانی می‌شوند\\n\"\n",
        "        \"• برای فایل‌های طولانی‌تر، ربات آنها را به بخش‌های کوچکتر تقسیم می‌کند\\n\"\n",
        "        \"• زبان اصلی مورد پشتیبانی فارسی است\\n\\n\"\n",
        "        \"📌 **دستورات:**\\n\"\n",
        "        \"/start - شروع کار با ربات\\n\"\n",
        "        \"/help - نمایش این راهنما\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.text and not e.text.startswith('/')))\n",
        "async def handle_text_message(event):\n",
        "    chat_id = event.chat_id\n",
        "    message_text = event.text\n",
        "    logger.info(f\"Received text message in chat {chat_id}: {message_text[:50]}...\")\n",
        "\n",
        "    # Let the user know we're processing\n",
        "    processing_msg = await event.reply(\"⏳ در حال پردازش پیام شما...\")\n",
        "\n",
        "    try:\n",
        "        bot_response = await get_bot_response_google(message_text)\n",
        "        await client.edit_message(processing_msg, bot_response)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling text message: {e}\", exc_info=True)\n",
        "        await client.edit_message(processing_msg, \"❌ متأسفانه در پردازش پیام شما مشکلی پیش آمد.\")\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.audio or e.voice or e.document))\n",
        "async def handle_audio_message(event):\n",
        "    try:\n",
        "        chat_id = event.chat_id\n",
        "        sender = await event.get_sender()\n",
        "        logger.info(f\"Received audio from User {sender.id} in Chat {chat_id}\")\n",
        "\n",
        "        # Check if the message contains audio, voice, or a document\n",
        "        if event.audio:\n",
        "            media = event.audio\n",
        "            file_type = \"audio\"\n",
        "        elif event.voice:\n",
        "            media = event.voice\n",
        "            file_type = \"voice\"\n",
        "        elif event.document and hasattr(event.document, 'mime_type') and event.document.mime_type.startswith('audio/'):\n",
        "            media = event.document\n",
        "            file_type = \"document\"\n",
        "        else:\n",
        "            await event.reply(\"❌ لطفاً یک فایل صوتی معتبر ارسال کنید.\")\n",
        "            return\n",
        "\n",
        "        # Initial processing message\n",
        "        processing_msg = await event.reply(\"⏳ در حال دریافت فایل صوتی...\")\n",
        "\n",
        "        # Generate a unique filename based on timestamp and user\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        original_name = getattr(media, 'attributes', [{}])[0].file_name if hasattr(getattr(media, 'attributes', [{}])[0], 'file_name') else f\"{file_type}_{timestamp}\"\n",
        "        original_name_base = Path(original_name).stem\n",
        "        download_path = TEMP_DIR / f\"{original_name_base}_{timestamp}.ogg\"\n",
        "\n",
        "        # Download the file\n",
        "        try:\n",
        "            await client.download_media(message=event.message, file=str(download_path))\n",
        "            logger.info(f\"File downloaded to {download_path}\")\n",
        "            await client.edit_message(processing_msg, \"✅ فایل صوتی دریافت شد. در حال پردازش...\")\n",
        "        except Exception as download_error:\n",
        "            logger.error(f\"Error downloading file: {download_error}\", exc_info=True)\n",
        "            await client.edit_message(processing_msg, \"❌ خطا در دریافت فایل صوتی.\")\n",
        "            return\n",
        "\n",
        "        # Process the audio (handles both short and long audio files)\n",
        "        uploaded_refs, files_to_cleanup = await process_long_audio(\n",
        "            event, download_path, original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # Clean up all temporary files and references\n",
        "        await cleanup_files(*files_to_cleanup)\n",
        "        for ref in uploaded_refs:\n",
        "            try:\n",
        "                # Only attempt to clean up Google API uploaded file references if they exist\n",
        "                if ref and hasattr(ref, 'name'):\n",
        "                    logger.info(f\"Cleaning up Google API file reference: {ref.name}\")\n",
        "                    # No cleanup needed for now as these are handled by Google's API\n",
        "            except Exception as ref_cleanup_error:\n",
        "                logger.error(f\"Error cleaning up reference: {ref_cleanup_error}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Unhandled error in handle_audio_message: {e}\")\n",
        "        try:\n",
        "            await event.reply(\"❌ متأسفانه در پردازش فایل صوتی شما مشکلی پیش آمد. لطفاً دوباره تلاش کنید.\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# --- Main Entry Point ---\n",
        "\n",
        "async def main():\n",
        "    logger.info(\"Starting the bot...\")\n",
        "\n",
        "    # Clear temp directory at startup\n",
        "    for file_path in TEMP_DIR.glob(\"*\"):\n",
        "        try:\n",
        "            file_path.unlink()\n",
        "            logger.info(f\"Cleaned up old file: {file_path}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error cleaning up file {file_path}: {e}\")\n",
        "\n",
        "    # Start the client\n",
        "    await client.start(bot_token=BOT_TOKEN)\n",
        "    logger.info(\"Bot started successfully\")\n",
        "\n",
        "    # Get the bot info\n",
        "    me = await client.get_me()\n",
        "    logger.info(f\"Bot Username: @{me.username}\")\n",
        "\n",
        "    # Keep the bot running\n",
        "    try:\n",
        "        logger.info(\"Bot is now running. Press Ctrl+C to stop.\")\n",
        "        await client.run_until_disconnected()\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"Bot stopped by user\")\n",
        "    finally:\n",
        "        await client.disconnect()\n",
        "        logger.info(\"Bot disconnected\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the bot\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
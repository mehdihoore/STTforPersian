{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa7YPHZ2a00XstEHbamThw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdihoore/STTforPersian/blob/main/sttbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx0Ee8w5Gk4Z"
      },
      "outputs": [],
      "source": [
        "!pip install telethon google-generativeai python-dotenv nest_asyncio Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "G33RviUMGo7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import re\n",
        "import math\n",
        "from telethon import TelegramClient, events, Button\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from pydub import AudioSegment  # New import for audio processing\n",
        "\n",
        "# --- Configuration ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    API_ID = int(userdata.get('TELEGRAM_API_ID'))\n",
        "    API_HASH = userdata.get('TELEGRAM_API_HASH')\n",
        "    BOT_TOKEN = userdata.get('TELEGRAM_BOT_TTS')\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')  # Main key\n",
        "    GOOGLE_SUMMARY_API_KEY = userdata.get('GOOGLE_SUMMARY_API_KEY')  # Specific key for summaries\n",
        "\n",
        "    if not all([API_ID, API_HASH, BOT_TOKEN, GOOGLE_API_KEY, GOOGLE_SUMMARY_API_KEY]):\n",
        "        raise ValueError(\"One or more secrets are missing.\")\n",
        "    if GOOGLE_API_KEY == GOOGLE_SUMMARY_API_KEY:\n",
        "        print(\"Main Google API Key and Summary API Key are the same. No key switching needed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading secrets: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Apply nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Initial Google AI SDK Configuration (with the MAIN key) ---\n",
        "try:\n",
        "    logger.info(f\"Configuring Google AI SDK with MAIN API key ending with ...{GOOGLE_API_KEY[-4:]}\")\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error configuring Google AI SDK with main key: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_CONFIG = {\n",
        "    \"text_model_name\": \"gemini-1.5-flash-latest\",\n",
        "    \"multimodal_model_name\": \"gemini-1.5-flash-latest\",\n",
        "    \"generation_config\": {\"temperature\": 0.5},\n",
        "    \"summarization_generation_config\": {\"temperature\": 0.6},\n",
        "    \"safety_settings\": [\n",
        "        {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Telethon Client Initialization\n",
        "session_name = f\"bot_session_{BOT_TOKEN.split(':')[0]}\"  # Ensure unique session name\n",
        "client = TelegramClient(session_name, API_ID, API_HASH)\n",
        "TEMP_DIR = Path(\"./temp_audio_telethon_bot\")\n",
        "TEMP_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Audio Processing Constants ---\n",
        "MAX_DURATION_MINUTES = 30  # Maximum duration in minutes before splitting\n",
        "MAX_DURATION_MS = MAX_DURATION_MINUTES * 60 * 1000  # Convert to milliseconds\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def get_gemini_model_instance(model_name_key, custom_generation_config_key=None):\n",
        "    \"\"\"\n",
        "    Creates and returns a Gemini model instance.\n",
        "    ASSUMES genai IS ALREADY CONFIGURED with the correct API key FOR THIS CALL.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model_name_actual = MODEL_CONFIG[model_name_key]\n",
        "        generation_config_actual = MODEL_CONFIG[custom_generation_config_key] if custom_generation_config_key else MODEL_CONFIG[\"generation_config\"]\n",
        "\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=model_name_actual,\n",
        "            generation_config=generation_config_actual,\n",
        "            safety_settings=MODEL_CONFIG[\"safety_settings\"]\n",
        "        )\n",
        "        logger.info(f\"Created model instance for {model_name_actual} (current global API key is in use)\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating Gemini model {model_name_actual}: {e}\")\n",
        "        raise\n",
        "\n",
        "async def cleanup_files(*files):\n",
        "    for file_path in files:\n",
        "        if file_path and Path(file_path).exists():\n",
        "            try:\n",
        "                Path(file_path).unlink()\n",
        "                logger.info(f\"Deleted temporary file: {file_path}\")\n",
        "            except OSError as e:\n",
        "                logger.error(f\"Error deleting file {file_path}: {e}\")\n",
        "\n",
        "def generate_srt_with_timecodes(segmented_text):\n",
        "    lines = [line for line in segmented_text.split(\"\\n\") if line.strip()]\n",
        "    if not lines:\n",
        "        return \"1\\n00:00:00,000 --> 00:00:05,000\\n(محتوایی برای زمان‌بندی وجود ندارد)\\n\"\n",
        "    srt_content = []\n",
        "    current_time_total_seconds = 0\n",
        "    segment_duration_seconds = 5\n",
        "    for i, line in enumerate(lines):\n",
        "        start_seconds = current_time_total_seconds\n",
        "        end_seconds = current_time_total_seconds + segment_duration_seconds\n",
        "        def format_time(s):\n",
        "            return f\"{int(s // 3600):02}:{int(s % 3600 // 60):02}:{int(s % 60):02},{int((s % 1) * 1000):03}\"\n",
        "        srt_content.append(str(i + 1))\n",
        "        srt_content.append(f\"{format_time(start_seconds)} --> {format_time(end_seconds)}\")\n",
        "        srt_content.append(line)\n",
        "        srt_content.append(\"\")\n",
        "        current_time_total_seconds = end_seconds\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "# --- New Audio Splitting Functions ---\n",
        "\n",
        "async def get_audio_duration(file_path):\n",
        "    \"\"\"Get the duration of an audio file in milliseconds.\"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        duration_ms = len(audio)\n",
        "        logger.info(f\"Audio duration: {duration_ms/1000:.2f} seconds ({duration_ms/60000:.2f} minutes)\")\n",
        "        return duration_ms\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting audio duration: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def split_audio_file(file_path, base_name, max_duration_ms=MAX_DURATION_MS):\n",
        "    \"\"\"\n",
        "    Split an audio file into chunks of max_duration_ms.\n",
        "    Returns a list of paths to the split audio files.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        total_duration_ms = len(audio)\n",
        "\n",
        "        if total_duration_ms <= max_duration_ms:\n",
        "            logger.info(f\"Audio is shorter than {MAX_DURATION_MINUTES} minutes, no need to split\")\n",
        "            return [file_path]\n",
        "\n",
        "        # Calculate number of chunks needed\n",
        "        num_chunks = math.ceil(total_duration_ms / max_duration_ms)\n",
        "        logger.info(f\"Splitting audio into {num_chunks} chunks of {MAX_DURATION_MINUTES} minutes each\")\n",
        "\n",
        "        chunk_paths = []\n",
        "        for i in range(num_chunks):\n",
        "            start_ms = i * max_duration_ms\n",
        "            end_ms = min((i + 1) * max_duration_ms, total_duration_ms)\n",
        "\n",
        "            chunk = audio[start_ms:end_ms]\n",
        "            chunk_filename = f\"{base_name}_part{i+1}.ogg\"\n",
        "            chunk_path = TEMP_DIR / chunk_filename\n",
        "\n",
        "            logger.info(f\"Exporting chunk {i+1}/{num_chunks} to {chunk_path}\")\n",
        "            chunk.export(str(chunk_path), format=\"ogg\")\n",
        "            chunk_paths.append(str(chunk_path))\n",
        "\n",
        "        logger.info(f\"Successfully split audio into {len(chunk_paths)} chunks\")\n",
        "        return chunk_paths\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error splitting audio file: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "# --- Google AI API Call Functions ---\n",
        "\n",
        "async def transcribe_audio_google(file_path):\n",
        "    logger.info(f\"Transcribing audio file: {file_path}\")\n",
        "    google_audio_file_obj = None\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"multimodal_model_name\")  # Assumes main key is active\n",
        "        logger.info(\"Uploading audio file for transcription...\")\n",
        "        # upload_file is synchronous, so run in a thread\n",
        "        google_audio_file_obj = await asyncio.to_thread(genai.upload_file, path=file_path)\n",
        "        logger.info(f\"Audio file uploaded: {google_audio_file_obj.name}\")\n",
        "\n",
        "        prompt = \"Please transcribe the audio provided accurately. Return ONLY the plain text transcription.\"\n",
        "\n",
        "        # Run the synchronous generate_content in a thread\n",
        "        response = await asyncio.to_thread(\n",
        "            model.generate_content,\n",
        "            [prompt, google_audio_file_obj]  # Pass contents directly\n",
        "        )\n",
        "\n",
        "        transcription = response.text.strip()\n",
        "\n",
        "        if not transcription:\n",
        "             logger.warning(\"Transcription response was empty.\")\n",
        "             raise ValueError(\"Transcription failed: No text returned.\")\n",
        "        logger.info(\"Transcription successful.\")\n",
        "        return transcription, google_audio_file_obj\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during transcription: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def summarize_audio_google(audio_file_ref, transcription_context):\n",
        "    logger.info(\"Summarizing audio content...\")\n",
        "    # --- API Key Switching Logic ---\n",
        "    current_global_key_is_main = True  # Assume it's the main key initially\n",
        "\n",
        "    if GOOGLE_API_KEY != GOOGLE_SUMMARY_API_KEY and GOOGLE_SUMMARY_API_KEY:\n",
        "        try:\n",
        "            logger.info(f\"Temporarily configuring genai for GOOGLE_SUMMARY_API_KEY (ends ...{GOOGLE_SUMMARY_API_KEY[-4:]}) for summarization\")\n",
        "            genai.configure(api_key=GOOGLE_SUMMARY_API_KEY)\n",
        "            current_global_key_is_main = False  # Now it's the summary key\n",
        "\n",
        "            model = get_gemini_model_instance(\"multimodal_model_name\", \"summarization_generation_config\")\n",
        "            summary_prompt = \"\"\"\n",
        "شما یک دستیار متخصص در تحلیل و خلاصه‌سازی محتوای صوتی به زبان فارسی هستید.\n",
        "فایل صوتی ارائه شده است. متن پیاده‌سازی شده اولیه آن نیز برای کمک به زمینه و کلمات کلیدی در زیر آمده است.\n",
        "لطفاً این فایل صوتی را با دقت تحلیل کرده و یک خلاصه جامع و دقیق به زبان فارسی روان تهیه کنید که شامل موارد زیر باشد:\n",
        "\n",
        "متن پیاده‌سازی شده اولیه (برای کمک به زمینه):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "دستورالعمل‌های خلاصه‌سازی:\n",
        "1.  **خلاصه کلی (۲-۳ پاراگراف):** موضوع اصلی و هدف، زمینه بحث، نتیجه‌گیری اصلی.\n",
        "2.  **نکات کلیدی و برجسته:** مهم‌ترین نقاط، آمار/ارقام مهم، تاریخ‌ها/رویدادهای کلیدی (حداقل ۵ مورد).\n",
        "3.  **جزئیات و استدلال‌های مهم:** استدلال‌های اصلی، مثال‌ها/موارد خاص، نقل قول‌های مهم (حداکثر ۲-۳).\n",
        "4.  **تحلیل محتوا (در صورت امکان):** ارتباط مفاهیم، نقاط قوت/ضعف، پیشنهادات/راهکارها.\n",
        "5.  **دسته‌بندی موضوعی (اختیاری):** موضوعات فرعی و ارتباطشان با موضوع اصلی.\n",
        "\n",
        "**خروجی مورد انتظار:**\n",
        "*   خلاصه کاملاً به زبان فارسی سلیس و روان.\n",
        "*   ساختاریافته با تیترهای مشخص فارسی (مانند \"خلاصه کلی\", \"نکات کلیدی و برجسته\").\n",
        "*   استفاده از نشانه‌گذاری مناسب (لیست‌ها).\n",
        "*   طول متناسب با محتوای صوتی.\n",
        "*   فقط و فقط خلاصه نهایی مطابق ساختار درخواستی، بدون عبارت مقدماتی یا توضیحات اضافی.\n",
        "\"\"\"\n",
        "            response = await asyncio.to_thread(\n",
        "                model.generate_content,\n",
        "                [summary_prompt.format(transcription_context=transcription_context), audio_file_ref]\n",
        "            )\n",
        "            summary = response.text.strip()\n",
        "\n",
        "            if not summary:\n",
        "                logger.warning(\"Summarization response was empty.\")\n",
        "                raise ValueError(\"Summarization failed: No text returned.\")\n",
        "            logger.info(\"Summarization successful.\")\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during summarization: {e}\", exc_info=True)\n",
        "            raise\n",
        "        finally:\n",
        "            # --- Switch back to MAIN API key ---\n",
        "            if not current_global_key_is_main:  # If we switched to summary key\n",
        "                logger.info(f\"Switching genai config back to main GOOGLE_API_KEY (ends ...{GOOGLE_API_KEY[-4:]})\")\n",
        "                genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    else:  # Keys are the same, or no specific summary key, so use the already configured main key\n",
        "        try:\n",
        "            logger.info(\"Using main GOOGLE_API_KEY for summarization as keys are same or summary key not distinct.\")\n",
        "            model = get_gemini_model_instance(\"multimodal_model_name\", \"summarization_generation_config\")\n",
        "            summary_prompt = f\"\"\"\n",
        "شما یک دستیار متخصص در تحلیل و خلاصه‌سازی محتوای صوتی به زبان فارسی هستید.\n",
        "فایل صوتی ارائه شده است. متن پیاده‌سازی شده اولیه آن نیز برای کمک به زمینه و کلمات کلیدی در زیر آمده است.\n",
        "لطفاً این فایل صوتی را با دقت تحلیل کرده و یک خلاصه جامع و دقیق به زبان فارسی روان تهیه کنید که شامل موارد زیر باشد:\n",
        "\n",
        "متن پیاده‌سازی شده اولیه (برای کمک به زمینه):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "دستورالعمل‌های خلاصه‌سازی:\n",
        "1.  **خلاصه کلی (۲-۳ پاراگراف):** موضوع اصلی و هدف، زمینه بحث، نتیجه‌گیری اصلی.\n",
        "2.  **نکات کلیدی و برجسته:** مهم‌ترین نقاط، آمار/ارقام مهم، تاریخ‌ها/رویدادهای کلیدی (حداقل ۵ مورد).\n",
        "3.  **جزئیات و استدلال‌های مهم:** استدلال‌های اصلی، مثال‌ها/موارد خاص، نقل قول‌های مهم (حداکثر ۲-۳).\n",
        "4.  **تحلیل محتوا (در صورت امکان):** ارتباط مفاهیم، نقاط قوت/ضعف، پیشنهادات/راهکارها.\n",
        "5.  **دسته‌بندی موضوعی (اختیاری):** موضوعات فرعی و ارتباطشان با موضوع اصلی.\n",
        "\n",
        "**خروجی مورد انتظار:**\n",
        "*   خلاصه کاملاً به زبان فارسی سلیس و روان.\n",
        "*   ساختاریافته با تیترهای مشخص فارسی (مانند \"خلاصه کلی\", \"نکات کلیدی و برجسته\").\n",
        "*   استفاده از نشانه‌گذاری مناسب (لیست‌ها).\n",
        "*   طول متناسب با محتوای صوتی.\n",
        "*   فقط و فقط خلاصه نهایی مطابق ساختار درخواستی، بدون عبارت مقدماتی یا توضیحات اضافی.\n",
        "\"\"\"\n",
        "            response = await asyncio.to_thread(\n",
        "                model.generate_content,\n",
        "                [summary_prompt.format(transcription_context=transcription_context), audio_file_ref]\n",
        "            )\n",
        "            summary = response.text.strip()\n",
        "            if not summary:\n",
        "                logger.warning(\"Summarization response was empty.\")\n",
        "                raise ValueError(\"Summarization failed: No text returned.\")\n",
        "            logger.info(\"Summarization successful.\")\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during summarization with main key: {e}\", exc_info=True)\n",
        "            raise\n",
        "\n",
        "async def translate_to_persian_google(text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    if not text or not text.strip(): return \"\"\n",
        "    logger.info(\"Translating text to Persian...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        prompt = f'Translate the following text to Persian:\\n\\n\"{text}\"\\n\\nReturn ONLY the Persian translation.'\n",
        "        response = await asyncio.to_thread(model.generate_content, prompt)\n",
        "        translation = response.text.strip()\n",
        "        if not translation:\n",
        "            logger.warning(\"Translation response was empty.\")\n",
        "            raise ValueError(\"Translation failed: No text returned.\")\n",
        "        logger.info(\"Translation successful.\")\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during translation: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def segment_persian_text_google(persian_text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    logger.info(\"Segmenting Persian text for SRT...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        segmentation_prompt = f\"\"\"Take the following Persian text and break it into suitable subtitle segments. Each segment should be on a new line. Aim for natural breaks and readable lengths for subtitles.\n",
        "Return ONLY the segmented text, with each segment on a new line.\n",
        "Persian text:\n",
        "---\n",
        "{persian_text}\n",
        "---\"\"\"\n",
        "        response = await asyncio.to_thread(model.generate_content, segmentation_prompt)\n",
        "        segmented_text = response.text.strip()\n",
        "\n",
        "        if not segmented_text:  # Fallback\n",
        "            logger.warning(\"LLM Segmentation response was empty. Using regex fallback.\")\n",
        "            segments = re.split(r'[।\\.؟!\\n]+', persian_text)\n",
        "            segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "            if not segmented_text: raise ValueError(\"Segmentation failed: No text from LLM or fallback.\")\n",
        "        logger.info(\"Segmentation successful.\")\n",
        "        return segmented_text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during LLM segmentation: {e}. Using regex fallback.\", exc_info=True)\n",
        "        segments = re.split(r'[।\\.؟!\\n]+', persian_text)  # Fallback on any error\n",
        "        segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "        if not segmented_text: raise ValueError(f\"Segmentation failed: Error '{e}' and fallback also yielded no text.\")\n",
        "        return segmented_text\n",
        "\n",
        "async def generate_persian_srt_google(transcription):\n",
        "    logger.info(\"Generating Persian SRT...\")\n",
        "    try:\n",
        "        persian_translation = await translate_to_persian_google(transcription)\n",
        "        if not persian_translation: raise ValueError(\"Translation step failed for SRT.\")\n",
        "        segmented_persian_text = await segment_persian_text_google(persian_translation)\n",
        "        if not segmented_persian_text: raise ValueError(\"Segmentation step failed for SRT.\")\n",
        "        srt_content = generate_srt_with_timecodes(segmented_persian_text)\n",
        "        logger.info(\"SRT generation successful.\")\n",
        "        return srt_content\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating SRT: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def get_bot_response_google(message_text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    logger.info(f\"Getting bot response for: {message_text[:50]}...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        prompt = f\"\"\"You are LinguaScribe_Bot, a helpful Telegram assistant. The user's language is Persian.\n",
        "User says: \"{message_text}\"\n",
        "Provide a concise and helpful response in Persian. If the user sends audio, you will have received the transcription as 'messageText'.\n",
        "If they ask about services, mention audio transcription to text (پیاده‌سازی صوت), Persian translation (ترجمه به فارسی), SRT generation (تولید فایل زیرنویس SRT), and audio summarization (خلاصه‌سازی صوت).\n",
        "Keep responses brief. If the input is non-sensical or just a greeting, respond politely and briefly in Persian.\n",
        "Return ONLY the bot's reply.\"\"\"\n",
        "        response = await asyncio.to_thread(model.generate_content, prompt)\n",
        "        reply = response.text.strip()\n",
        "        if not reply:\n",
        "            logger.warning(\"Bot response generation was empty.\")\n",
        "            return \"متاسفانه در حال حاضر قادر به پاسخگویی نیستم.\"\n",
        "        logger.info(\"Bot response generated.\")\n",
        "        return reply\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting bot response: {e}\", exc_info=True)\n",
        "        return \"متاسفانه در پردازش درخواست شما مشکلی پیش آمد.\"\n",
        "\n",
        "# --- New Function for Processing Long Audio ---\n",
        "async def process_long_audio(event, download_path, original_name_base, chat_id, processing_msg):\n",
        "    \"\"\"Process a long audio file by splitting it into chunks and processing each chunk\"\"\"\n",
        "    try:\n",
        "        # Check audio duration\n",
        "        audio_duration_ms = await get_audio_duration(download_path)\n",
        "\n",
        "        if audio_duration_ms <= MAX_DURATION_MS:\n",
        "            # Audio is shorter than threshold, process normally\n",
        "            logger.info(f\"Audio duration ({audio_duration_ms/60000:.2f} min) is under threshold, processing normally\")\n",
        "            return await process_single_audio(str(download_path), original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # Audio is longer than threshold, need to split\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"⚠️ فایل صوتی شما طولانی است ({audio_duration_ms/60000:.1f} دقیقه). در حال تقسیم به قطعات {MAX_DURATION_MINUTES} دقیقه‌ای و پردازش...\"\n",
        "        )\n",
        "\n",
        "        # Split the audio file\n",
        "        chunk_paths = await split_audio_file(download_path, original_name_base)\n",
        "\n",
        "        # Process each chunk and collect transcriptions\n",
        "        all_transcriptions = []\n",
        "        all_uploaded_refs = []  # Track all uploaded file references for cleanup\n",
        "\n",
        "        for i, chunk_path in enumerate(chunk_paths):\n",
        "            await client.edit_message(\n",
        "                processing_msg,\n",
        "                processing_msg.text + f\"\\n\\n⏳ در حال پیاده‌سازی متن قطعه {i+1} از {len(chunk_paths)}...\"\n",
        "            )\n",
        "\n",
        "            chunk_transcription, chunk_ref = await transcribe_audio_google(chunk_path)\n",
        "            all_uploaded_refs.append(chunk_ref)\n",
        "            all_transcriptions.append(chunk_transcription)\n",
        "\n",
        "            await client.edit_message(\n",
        "                processing_msg,\n",
        "                processing_msg.text + f\"\\n✅ پیاده‌سازی قطعه {i+1} انجام شد.\"\n",
        "            )\n",
        "\n",
        "        # Combine all transcriptions\n",
        "        full_transcription = \"\\n\\n\".join(all_transcriptions)\n",
        "\n",
        "        # Save combined transcription\n",
        "        transcription_filename = f\"{original_name_base}_full_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(full_transcription)\n",
        "\n",
        "        # Send the combined transcription\n",
        "        await client.send_file(\n",
        "            chat_id,\n",
        "            str(transcription_path),\n",
        "            caption=\"🎤 متن کامل پیاده‌سازی شده:\"\n",
        "        )\n",
        "\n",
        "        # Generate SRT from combined transcription\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال تولید زیرنویس (SRT) کامل...\")\n",
        "        srt_content = await generate_persian_srt_google(full_transcription)\n",
        "        srt_filename = f\"{original_name_base}_full_subtitles.srt\"\n",
        "        srt_path = TEMP_DIR / srt_filename\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_content)\n",
        "        await client.send_file(chat_id, str(srt_path), caption=\"🎬 فایل زیرنویس کامل (SRT):\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ فایل زیرنویس (SRT) ارسال شد.\")\n",
        "\n",
        "        # Generate summary using the first chunk's audio reference and the full transcription\n",
        "        # (since we can't combine audio files for the API, we'll use one chunk but provide full transcription)\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال تهیه خلاصه کلی...\")\n",
        "        summary = await summarize_audio_google(all_uploaded_refs[0], full_transcription)\n",
        "        await client.send_message(\n",
        "            chat_id,\n",
        "            f\"📝 *خلاصه محتوای کامل:*\\n\\n{summary}\",\n",
        "            parse_mode='md'\n",
        "        )\n",
        "\n",
        "        # Final status message\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"✅ پردازش فایل صوتی {audio_duration_ms/60000:.1f} دقیقه‌ای شما با موفقیت تکمیل شد.\"\n",
        "        )\n",
        "\n",
        "        # Return all files for cleanup\n",
        "        return all_uploaded_refs, [download_path, transcription_path, srt_path] + chunk_paths\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_long_audio: {e}\")\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"❌ خطا در پردازش فایل صوتی بلند: {str(e)}\"\n",
        "        )\n",
        "        return [], [download_path]\n",
        "\n",
        "# --- Function to Process a Single Audio File (for reuse) ---\n",
        "async def process_single_audio(file_path, original_name_base, chat_id, processing_msg):\n",
        "    \"\"\"Process a single audio file and return the uploaded ref and files for cleanup\"\"\"\n",
        "    try:\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال پیاده‌سازی متن...\")\n",
        "        transcription, google_audio_file_uploaded_ref = await transcribe_audio_google(file_path)\n",
        "\n",
        "        transcription_filename = f\"{original_name_base}_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcription)\n",
        "\n",
        "        await client.send_file(chat_id, str(transcription_path), caption=\"🎤 متن پیاده‌سازی شده:\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ متن پیاده‌سازی و ارسال شد.\")\n",
        "\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال تهیه خلاصه...\")\n",
        "        summary = await summarize_audio_google(google_audio_file_uploaded_ref, transcription)\n",
        "        await client.send_message(chat_id, f\"📝 *خلاصه محتوا:*\\n\\n{summary}\", parse_mode='md')\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ خلاصه ارسال شد.\")\n",
        "\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\n⏳ در حال تولید زیرنویس (SRT)...\")\n",
        "        srt_content = await generate_persian_srt_google(transcription)\n",
        "        srt_filename = f\"{original_name_base}_subtitles.srt\"\n",
        "        srt_path = TEMP_DIR / srt_filename\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_content)\n",
        "        await client.send_file(chat_id, str(srt_path), caption=\"🎬 فایل زیرنویس (SRT):\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n✅ فایل زیرنویس (SRT) ارسال شد.\")\n",
        "        await client.edit_message(processing_msg, \"✅ پردازش فایل صوتی با موفقیت تکمیل شد!\")\n",
        "\n",
        "        # Return references and paths for cleanup\n",
        "        return [google_audio_file_uploaded_ref], [file_path, transcription_path, srt_path]\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_single_audio: {e}\")\n",
        "        await client.edit_message(processing_msg, f\"❌ خطا در پردازش فایل صوتی: {str(e)}\")\n",
        "        return [], [file_path]  # Return empty refs and only the original file for cleanup\n",
        "\n",
        "# --- Main Bot Event Handlers ---\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/start'))\n",
        "async def start(event):\n",
        "    sender = await event.get_sender()\n",
        "    chat_id = event.chat_id\n",
        "    logger.info(f\"New /start command from User {sender.id} in Chat {chat_id}\")\n",
        "\n",
        "    await event.reply(\n",
        "        \"👋 سلام! به ربات *LinguaScribe* خوش آمدید.\\n\\n\"\n",
        "        \"این ربات می‌تواند:\\n\"\n",
        "        \"🎤 **پیاده‌سازی متن**: فایل‌های صوتی را به متن تبدیل کند\\n\"\n",
        "        \"📝 **خلاصه‌سازی**: محتوای صوتی را خلاصه کند\\n\"\n",
        "        \"🎬 **زیرنویس**: فایل SRT فارسی تولید کند\\n\\n\"\n",
        "        \"برای شروع، یک فایل صوتی برای من ارسال کنید.\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/help'))\n",
        "async def help_command(event):\n",
        "    await event.reply(\n",
        "        \"🔍 **راهنمای استفاده از LinguaScribe Bot**\\n\\n\"\n",
        "        \"کاربرد:\\n\"\n",
        "        \"1️⃣ یک فایل صوتی (voice message, audio file) ارسال کنید\\n\"\n",
        "        \"2️⃣ ربات به صورت خودکار:\\n\"\n",
        "        \"   - متن پیاده‌سازی شده را ارسال می‌کند\\n\"\n",
        "        \"   - خلاصه‌ای از محتوا تهیه می‌کند\\n\"\n",
        "        \"   - فایل زیرنویس SRT تولید می‌کند\\n\\n\"\n",
        "        \"📋 **نکات مهم**:\\n\"\n",
        "        \"• فایل‌های صوتی تا ۳۰ دقیقه پشتیبانی می‌شوند\\n\"\n",
        "        \"• برای فایل‌های طولانی‌تر، ربات آنها را به بخش‌های کوچکتر تقسیم می‌کند\\n\"\n",
        "        \"• زبان اصلی مورد پشتیبانی فارسی است\\n\\n\"\n",
        "        \"📌 **دستورات:**\\n\"\n",
        "        \"/start - شروع کار با ربات\\n\"\n",
        "        \"/help - نمایش این راهنما\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.text and not e.text.startswith('/')))\n",
        "async def handle_text_message(event):\n",
        "    chat_id = event.chat_id\n",
        "    message_text = event.text\n",
        "    logger.info(f\"Received text message in chat {chat_id}: {message_text[:50]}...\")\n",
        "\n",
        "    # Let the user know we're processing\n",
        "    processing_msg = await event.reply(\"⏳ در حال پردازش پیام شما...\")\n",
        "\n",
        "    try:\n",
        "        bot_response = await get_bot_response_google(message_text)\n",
        "        await client.edit_message(processing_msg, bot_response)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling text message: {e}\", exc_info=True)\n",
        "        await client.edit_message(processing_msg, \"❌ متأسفانه در پردازش پیام شما مشکلی پیش آمد.\")\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.audio or e.voice or e.document))\n",
        "async def handle_audio_message(event):\n",
        "    try:\n",
        "        chat_id = event.chat_id\n",
        "        sender = await event.get_sender()\n",
        "        logger.info(f\"Received audio from User {sender.id} in Chat {chat_id}\")\n",
        "\n",
        "        # Check if the message contains audio, voice, or a document\n",
        "        if event.audio:\n",
        "            media = event.audio\n",
        "            file_type = \"audio\"\n",
        "        elif event.voice:\n",
        "            media = event.voice\n",
        "            file_type = \"voice\"\n",
        "        elif event.document and hasattr(event.document, 'mime_type') and event.document.mime_type.startswith('audio/'):\n",
        "            media = event.document\n",
        "            file_type = \"document\"\n",
        "        else:\n",
        "            await event.reply(\"❌ لطفاً یک فایل صوتی معتبر ارسال کنید.\")\n",
        "            return\n",
        "\n",
        "        # Initial processing message\n",
        "        processing_msg = await event.reply(\"⏳ در حال دریافت فایل صوتی...\")\n",
        "\n",
        "        # Generate a unique filename based on timestamp and user\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        original_name = getattr(media, 'attributes', [{}])[0].file_name if hasattr(getattr(media, 'attributes', [{}])[0], 'file_name') else f\"{file_type}_{timestamp}\"\n",
        "        original_name_base = Path(original_name).stem\n",
        "        download_path = TEMP_DIR / f\"{original_name_base}_{timestamp}.ogg\"\n",
        "\n",
        "        # Download the file\n",
        "        try:\n",
        "            await client.download_media(message=event.message, file=str(download_path))\n",
        "            logger.info(f\"File downloaded to {download_path}\")\n",
        "            await client.edit_message(processing_msg, \"✅ فایل صوتی دریافت شد. در حال پردازش...\")\n",
        "        except Exception as download_error:\n",
        "            logger.error(f\"Error downloading file: {download_error}\", exc_info=True)\n",
        "            await client.edit_message(processing_msg, \"❌ خطا در دریافت فایل صوتی.\")\n",
        "            return\n",
        "\n",
        "        # Process the audio (handles both short and long audio files)\n",
        "        uploaded_refs, files_to_cleanup = await process_long_audio(\n",
        "            event, download_path, original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # Clean up all temporary files and references\n",
        "        await cleanup_files(*files_to_cleanup)\n",
        "        for ref in uploaded_refs:\n",
        "            try:\n",
        "                # Only attempt to clean up Google API uploaded file references if they exist\n",
        "                if ref and hasattr(ref, 'name'):\n",
        "                    logger.info(f\"Cleaning up Google API file reference: {ref.name}\")\n",
        "                    # No cleanup needed for now as these are handled by Google's API\n",
        "            except Exception as ref_cleanup_error:\n",
        "                logger.error(f\"Error cleaning up reference: {ref_cleanup_error}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Unhandled error in handle_audio_message: {e}\")\n",
        "        try:\n",
        "            await event.reply(\"❌ متأسفانه در پردازش فایل صوتی شما مشکلی پیش آمد. لطفاً دوباره تلاش کنید.\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# --- Main Entry Point ---\n",
        "\n",
        "async def main():\n",
        "    logger.info(\"Starting the bot...\")\n",
        "\n",
        "    # Clear temp directory at startup\n",
        "    for file_path in TEMP_DIR.glob(\"*\"):\n",
        "        try:\n",
        "            file_path.unlink()\n",
        "            logger.info(f\"Cleaned up old file: {file_path}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error cleaning up file {file_path}: {e}\")\n",
        "\n",
        "    # Start the client\n",
        "    await client.start(bot_token=BOT_TOKEN)\n",
        "    logger.info(\"Bot started successfully\")\n",
        "\n",
        "    # Get the bot info\n",
        "    me = await client.get_me()\n",
        "    logger.info(f\"Bot Username: @{me.username}\")\n",
        "\n",
        "    # Keep the bot running\n",
        "    try:\n",
        "        logger.info(\"Bot is now running. Press Ctrl+C to stop.\")\n",
        "        await client.run_until_disconnected()\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"Bot stopped by user\")\n",
        "    finally:\n",
        "        await client.disconnect()\n",
        "        logger.info(\"Bot disconnected\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the bot\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())\n"
      ],
      "metadata": {
        "id": "jS1cE8WIGs_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "df737444-6477-40bd-d3c3-0a2f205b2d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 35385.19ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 16001.20ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 13293.33ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 23082.18ms\n"
          ]
        }
      ]
    }
  ]
}
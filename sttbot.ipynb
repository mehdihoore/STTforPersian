{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa7YPHZ2a00XstEHbamThw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdihoore/STTforPersian/blob/main/sttbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx0Ee8w5Gk4Z"
      },
      "outputs": [],
      "source": [
        "!pip install telethon google-generativeai python-dotenv nest_asyncio Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "G33RviUMGo7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import re\n",
        "import math\n",
        "from telethon import TelegramClient, events, Button\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from pydub import AudioSegment  # New import for audio processing\n",
        "\n",
        "# --- Configuration ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    API_ID = int(userdata.get('TELEGRAM_API_ID'))\n",
        "    API_HASH = userdata.get('TELEGRAM_API_HASH')\n",
        "    BOT_TOKEN = userdata.get('TELEGRAM_BOT_TTS')\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')  # Main key\n",
        "    GOOGLE_SUMMARY_API_KEY = userdata.get('GOOGLE_SUMMARY_API_KEY')  # Specific key for summaries\n",
        "\n",
        "    if not all([API_ID, API_HASH, BOT_TOKEN, GOOGLE_API_KEY, GOOGLE_SUMMARY_API_KEY]):\n",
        "        raise ValueError(\"One or more secrets are missing.\")\n",
        "    if GOOGLE_API_KEY == GOOGLE_SUMMARY_API_KEY:\n",
        "        print(\"Main Google API Key and Summary API Key are the same. No key switching needed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading secrets: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Apply nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Initial Google AI SDK Configuration (with the MAIN key) ---\n",
        "try:\n",
        "    logger.info(f\"Configuring Google AI SDK with MAIN API key ending with ...{GOOGLE_API_KEY[-4:]}\")\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error configuring Google AI SDK with main key: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_CONFIG = {\n",
        "    \"text_model_name\": \"gemini-1.5-flash-latest\",\n",
        "    \"multimodal_model_name\": \"gemini-1.5-flash-latest\",\n",
        "    \"generation_config\": {\"temperature\": 0.5},\n",
        "    \"summarization_generation_config\": {\"temperature\": 0.6},\n",
        "    \"safety_settings\": [\n",
        "        {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Telethon Client Initialization\n",
        "session_name = f\"bot_session_{BOT_TOKEN.split(':')[0]}\"  # Ensure unique session name\n",
        "client = TelegramClient(session_name, API_ID, API_HASH)\n",
        "TEMP_DIR = Path(\"./temp_audio_telethon_bot\")\n",
        "TEMP_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Audio Processing Constants ---\n",
        "MAX_DURATION_MINUTES = 30  # Maximum duration in minutes before splitting\n",
        "MAX_DURATION_MS = MAX_DURATION_MINUTES * 60 * 1000  # Convert to milliseconds\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def get_gemini_model_instance(model_name_key, custom_generation_config_key=None):\n",
        "    \"\"\"\n",
        "    Creates and returns a Gemini model instance.\n",
        "    ASSUMES genai IS ALREADY CONFIGURED with the correct API key FOR THIS CALL.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model_name_actual = MODEL_CONFIG[model_name_key]\n",
        "        generation_config_actual = MODEL_CONFIG[custom_generation_config_key] if custom_generation_config_key else MODEL_CONFIG[\"generation_config\"]\n",
        "\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=model_name_actual,\n",
        "            generation_config=generation_config_actual,\n",
        "            safety_settings=MODEL_CONFIG[\"safety_settings\"]\n",
        "        )\n",
        "        logger.info(f\"Created model instance for {model_name_actual} (current global API key is in use)\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating Gemini model {model_name_actual}: {e}\")\n",
        "        raise\n",
        "\n",
        "async def cleanup_files(*files):\n",
        "    for file_path in files:\n",
        "        if file_path and Path(file_path).exists():\n",
        "            try:\n",
        "                Path(file_path).unlink()\n",
        "                logger.info(f\"Deleted temporary file: {file_path}\")\n",
        "            except OSError as e:\n",
        "                logger.error(f\"Error deleting file {file_path}: {e}\")\n",
        "\n",
        "def generate_srt_with_timecodes(segmented_text):\n",
        "    lines = [line for line in segmented_text.split(\"\\n\") if line.strip()]\n",
        "    if not lines:\n",
        "        return \"1\\n00:00:00,000 --> 00:00:05,000\\n(Ù…Ø­ØªÙˆØ§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯)\\n\"\n",
        "    srt_content = []\n",
        "    current_time_total_seconds = 0\n",
        "    segment_duration_seconds = 5\n",
        "    for i, line in enumerate(lines):\n",
        "        start_seconds = current_time_total_seconds\n",
        "        end_seconds = current_time_total_seconds + segment_duration_seconds\n",
        "        def format_time(s):\n",
        "            return f\"{int(s // 3600):02}:{int(s % 3600 // 60):02}:{int(s % 60):02},{int((s % 1) * 1000):03}\"\n",
        "        srt_content.append(str(i + 1))\n",
        "        srt_content.append(f\"{format_time(start_seconds)} --> {format_time(end_seconds)}\")\n",
        "        srt_content.append(line)\n",
        "        srt_content.append(\"\")\n",
        "        current_time_total_seconds = end_seconds\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "# --- New Audio Splitting Functions ---\n",
        "\n",
        "async def get_audio_duration(file_path):\n",
        "    \"\"\"Get the duration of an audio file in milliseconds.\"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        duration_ms = len(audio)\n",
        "        logger.info(f\"Audio duration: {duration_ms/1000:.2f} seconds ({duration_ms/60000:.2f} minutes)\")\n",
        "        return duration_ms\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting audio duration: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def split_audio_file(file_path, base_name, max_duration_ms=MAX_DURATION_MS):\n",
        "    \"\"\"\n",
        "    Split an audio file into chunks of max_duration_ms.\n",
        "    Returns a list of paths to the split audio files.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        total_duration_ms = len(audio)\n",
        "\n",
        "        if total_duration_ms <= max_duration_ms:\n",
        "            logger.info(f\"Audio is shorter than {MAX_DURATION_MINUTES} minutes, no need to split\")\n",
        "            return [file_path]\n",
        "\n",
        "        # Calculate number of chunks needed\n",
        "        num_chunks = math.ceil(total_duration_ms / max_duration_ms)\n",
        "        logger.info(f\"Splitting audio into {num_chunks} chunks of {MAX_DURATION_MINUTES} minutes each\")\n",
        "\n",
        "        chunk_paths = []\n",
        "        for i in range(num_chunks):\n",
        "            start_ms = i * max_duration_ms\n",
        "            end_ms = min((i + 1) * max_duration_ms, total_duration_ms)\n",
        "\n",
        "            chunk = audio[start_ms:end_ms]\n",
        "            chunk_filename = f\"{base_name}_part{i+1}.ogg\"\n",
        "            chunk_path = TEMP_DIR / chunk_filename\n",
        "\n",
        "            logger.info(f\"Exporting chunk {i+1}/{num_chunks} to {chunk_path}\")\n",
        "            chunk.export(str(chunk_path), format=\"ogg\")\n",
        "            chunk_paths.append(str(chunk_path))\n",
        "\n",
        "        logger.info(f\"Successfully split audio into {len(chunk_paths)} chunks\")\n",
        "        return chunk_paths\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error splitting audio file: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "# --- Google AI API Call Functions ---\n",
        "\n",
        "async def transcribe_audio_google(file_path):\n",
        "    logger.info(f\"Transcribing audio file: {file_path}\")\n",
        "    google_audio_file_obj = None\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"multimodal_model_name\")  # Assumes main key is active\n",
        "        logger.info(\"Uploading audio file for transcription...\")\n",
        "        # upload_file is synchronous, so run in a thread\n",
        "        google_audio_file_obj = await asyncio.to_thread(genai.upload_file, path=file_path)\n",
        "        logger.info(f\"Audio file uploaded: {google_audio_file_obj.name}\")\n",
        "\n",
        "        prompt = \"Please transcribe the audio provided accurately. Return ONLY the plain text transcription.\"\n",
        "\n",
        "        # Run the synchronous generate_content in a thread\n",
        "        response = await asyncio.to_thread(\n",
        "            model.generate_content,\n",
        "            [prompt, google_audio_file_obj]  # Pass contents directly\n",
        "        )\n",
        "\n",
        "        transcription = response.text.strip()\n",
        "\n",
        "        if not transcription:\n",
        "             logger.warning(\"Transcription response was empty.\")\n",
        "             raise ValueError(\"Transcription failed: No text returned.\")\n",
        "        logger.info(\"Transcription successful.\")\n",
        "        return transcription, google_audio_file_obj\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during transcription: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def summarize_audio_google(audio_file_ref, transcription_context):\n",
        "    logger.info(\"Summarizing audio content...\")\n",
        "    # --- API Key Switching Logic ---\n",
        "    current_global_key_is_main = True  # Assume it's the main key initially\n",
        "\n",
        "    if GOOGLE_API_KEY != GOOGLE_SUMMARY_API_KEY and GOOGLE_SUMMARY_API_KEY:\n",
        "        try:\n",
        "            logger.info(f\"Temporarily configuring genai for GOOGLE_SUMMARY_API_KEY (ends ...{GOOGLE_SUMMARY_API_KEY[-4:]}) for summarization\")\n",
        "            genai.configure(api_key=GOOGLE_SUMMARY_API_KEY)\n",
        "            current_global_key_is_main = False  # Now it's the summary key\n",
        "\n",
        "            model = get_gemini_model_instance(\"multimodal_model_name\", \"summarization_generation_config\")\n",
        "            summary_prompt = \"\"\"\n",
        "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ùˆ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯.\n",
        "ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ Ø¢Ù† Ù†ÛŒØ² Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡ Ùˆ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ø²ÛŒØ± Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª.\n",
        "Ù„Ø·ÙØ§Ù‹ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ ÛŒÚ© Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:\n",
        "\n",
        "Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ:\n",
        "1.  **Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ (Û²-Û³ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù):** Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ Ùˆ Ù‡Ø¯ÙØŒ Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ø­Ø«ØŒ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§ØµÙ„ÛŒ.\n",
        "2.  **Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ø¨Ø±Ø¬Ø³ØªÙ‡:** Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ù†Ù‚Ø§Ø·ØŒ Ø¢Ù…Ø§Ø±/Ø§Ø±Ù‚Ø§Ù… Ù…Ù‡Ù…ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§/Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ (Ø­Ø¯Ø§Ù‚Ù„ Ûµ Ù…ÙˆØ±Ø¯).\n",
        "3.  **Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…:** Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒØŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§/Ù…ÙˆØ§Ø±Ø¯ Ø®Ø§ØµØŒ Ù†Ù‚Ù„ Ù‚ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… (Ø­Ø¯Ø§Ú©Ø«Ø± Û²-Û³).\n",
        "4.  **ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†):** Ø§Ø±ØªØ¨Ø§Ø· Ù…ÙØ§Ù‡ÛŒÙ…ØŒ Ù†Ù‚Ø§Ø· Ù‚ÙˆØª/Ø¶Ø¹ÙØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª/Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§.\n",
        "5.  **Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆØ¶ÙˆØ¹ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ):** Ù…ÙˆØ¶ÙˆØ¹Ø§Øª ÙØ±Ø¹ÛŒ Ùˆ Ø§Ø±ØªØ¨Ø§Ø·Ø´Ø§Ù† Ø¨Ø§ Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ.\n",
        "\n",
        "**Ø®Ø±ÙˆØ¬ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:**\n",
        "*   Ø®Ù„Ø§ØµÙ‡ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ù„ÛŒØ³ Ùˆ Ø±ÙˆØ§Ù†.\n",
        "*   Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ø§ ØªÛŒØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ ÙØ§Ø±Ø³ÛŒ (Ù…Ø§Ù†Ù†Ø¯ \"Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ\", \"Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ø¨Ø±Ø¬Ø³ØªÙ‡\").\n",
        "*   Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ (Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§).\n",
        "*   Ø·ÙˆÙ„ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ.\n",
        "*   ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒØŒ Ø¨Ø¯ÙˆÙ† Ø¹Ø¨Ø§Ø±Øª Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ ÛŒØ§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ.\n",
        "\"\"\"\n",
        "            response = await asyncio.to_thread(\n",
        "                model.generate_content,\n",
        "                [summary_prompt.format(transcription_context=transcription_context), audio_file_ref]\n",
        "            )\n",
        "            summary = response.text.strip()\n",
        "\n",
        "            if not summary:\n",
        "                logger.warning(\"Summarization response was empty.\")\n",
        "                raise ValueError(\"Summarization failed: No text returned.\")\n",
        "            logger.info(\"Summarization successful.\")\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during summarization: {e}\", exc_info=True)\n",
        "            raise\n",
        "        finally:\n",
        "            # --- Switch back to MAIN API key ---\n",
        "            if not current_global_key_is_main:  # If we switched to summary key\n",
        "                logger.info(f\"Switching genai config back to main GOOGLE_API_KEY (ends ...{GOOGLE_API_KEY[-4:]})\")\n",
        "                genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    else:  # Keys are the same, or no specific summary key, so use the already configured main key\n",
        "        try:\n",
        "            logger.info(\"Using main GOOGLE_API_KEY for summarization as keys are same or summary key not distinct.\")\n",
        "            model = get_gemini_model_instance(\"multimodal_model_name\", \"summarization_generation_config\")\n",
        "            summary_prompt = f\"\"\"\n",
        "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ùˆ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯.\n",
        "ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ Ø¢Ù† Ù†ÛŒØ² Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡ Ùˆ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ø²ÛŒØ± Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª.\n",
        "Ù„Ø·ÙØ§Ù‹ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ ÛŒÚ© Ø®Ù„Ø§ØµÙ‡ Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:\n",
        "\n",
        "Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡):\n",
        "\\\"\\\"\\\"\n",
        "{transcription_context}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ:\n",
        "1.  **Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ (Û²-Û³ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù):** Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ Ùˆ Ù‡Ø¯ÙØŒ Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ø­Ø«ØŒ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§ØµÙ„ÛŒ.\n",
        "2.  **Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ø¨Ø±Ø¬Ø³ØªÙ‡:** Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ù†Ù‚Ø§Ø·ØŒ Ø¢Ù…Ø§Ø±/Ø§Ø±Ù‚Ø§Ù… Ù…Ù‡Ù…ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§/Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ (Ø­Ø¯Ø§Ù‚Ù„ Ûµ Ù…ÙˆØ±Ø¯).\n",
        "3.  **Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…:** Ø§Ø³ØªØ¯Ù„Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒØŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§/Ù…ÙˆØ§Ø±Ø¯ Ø®Ø§ØµØŒ Ù†Ù‚Ù„ Ù‚ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… (Ø­Ø¯Ø§Ú©Ø«Ø± Û²-Û³).\n",
        "4.  **ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†):** Ø§Ø±ØªØ¨Ø§Ø· Ù…ÙØ§Ù‡ÛŒÙ…ØŒ Ù†Ù‚Ø§Ø· Ù‚ÙˆØª/Ø¶Ø¹ÙØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª/Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§.\n",
        "5.  **Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆØ¶ÙˆØ¹ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ):** Ù…ÙˆØ¶ÙˆØ¹Ø§Øª ÙØ±Ø¹ÛŒ Ùˆ Ø§Ø±ØªØ¨Ø§Ø·Ø´Ø§Ù† Ø¨Ø§ Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ.\n",
        "\n",
        "**Ø®Ø±ÙˆØ¬ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:**\n",
        "*   Ø®Ù„Ø§ØµÙ‡ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ù„ÛŒØ³ Ùˆ Ø±ÙˆØ§Ù†.\n",
        "*   Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ø§ ØªÛŒØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ ÙØ§Ø±Ø³ÛŒ (Ù…Ø§Ù†Ù†Ø¯ \"Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ\", \"Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ø¨Ø±Ø¬Ø³ØªÙ‡\").\n",
        "*   Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ (Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§).\n",
        "*   Ø·ÙˆÙ„ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ.\n",
        "*   ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒØŒ Ø¨Ø¯ÙˆÙ† Ø¹Ø¨Ø§Ø±Øª Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ ÛŒØ§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ.\n",
        "\"\"\"\n",
        "            response = await asyncio.to_thread(\n",
        "                model.generate_content,\n",
        "                [summary_prompt.format(transcription_context=transcription_context), audio_file_ref]\n",
        "            )\n",
        "            summary = response.text.strip()\n",
        "            if not summary:\n",
        "                logger.warning(\"Summarization response was empty.\")\n",
        "                raise ValueError(\"Summarization failed: No text returned.\")\n",
        "            logger.info(\"Summarization successful.\")\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during summarization with main key: {e}\", exc_info=True)\n",
        "            raise\n",
        "\n",
        "async def translate_to_persian_google(text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    if not text or not text.strip(): return \"\"\n",
        "    logger.info(\"Translating text to Persian...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        prompt = f'Translate the following text to Persian:\\n\\n\"{text}\"\\n\\nReturn ONLY the Persian translation.'\n",
        "        response = await asyncio.to_thread(model.generate_content, prompt)\n",
        "        translation = response.text.strip()\n",
        "        if not translation:\n",
        "            logger.warning(\"Translation response was empty.\")\n",
        "            raise ValueError(\"Translation failed: No text returned.\")\n",
        "        logger.info(\"Translation successful.\")\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during translation: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def segment_persian_text_google(persian_text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    logger.info(\"Segmenting Persian text for SRT...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        segmentation_prompt = f\"\"\"Take the following Persian text and break it into suitable subtitle segments. Each segment should be on a new line. Aim for natural breaks and readable lengths for subtitles.\n",
        "Return ONLY the segmented text, with each segment on a new line.\n",
        "Persian text:\n",
        "---\n",
        "{persian_text}\n",
        "---\"\"\"\n",
        "        response = await asyncio.to_thread(model.generate_content, segmentation_prompt)\n",
        "        segmented_text = response.text.strip()\n",
        "\n",
        "        if not segmented_text:  # Fallback\n",
        "            logger.warning(\"LLM Segmentation response was empty. Using regex fallback.\")\n",
        "            segments = re.split(r'[à¥¤\\.ØŸ!\\n]+', persian_text)\n",
        "            segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "            if not segmented_text: raise ValueError(\"Segmentation failed: No text from LLM or fallback.\")\n",
        "        logger.info(\"Segmentation successful.\")\n",
        "        return segmented_text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during LLM segmentation: {e}. Using regex fallback.\", exc_info=True)\n",
        "        segments = re.split(r'[à¥¤\\.ØŸ!\\n]+', persian_text)  # Fallback on any error\n",
        "        segmented_text = \"\\n\".join(s.strip() for s in segments if s.strip())\n",
        "        if not segmented_text: raise ValueError(f\"Segmentation failed: Error '{e}' and fallback also yielded no text.\")\n",
        "        return segmented_text\n",
        "\n",
        "async def generate_persian_srt_google(transcription):\n",
        "    logger.info(\"Generating Persian SRT...\")\n",
        "    try:\n",
        "        persian_translation = await translate_to_persian_google(transcription)\n",
        "        if not persian_translation: raise ValueError(\"Translation step failed for SRT.\")\n",
        "        segmented_persian_text = await segment_persian_text_google(persian_translation)\n",
        "        if not segmented_persian_text: raise ValueError(\"Segmentation step failed for SRT.\")\n",
        "        srt_content = generate_srt_with_timecodes(segmented_persian_text)\n",
        "        logger.info(\"SRT generation successful.\")\n",
        "        return srt_content\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating SRT: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "async def get_bot_response_google(message_text):\n",
        "    # Assumes GOOGLE_API_KEY is globally configured\n",
        "    logger.info(f\"Getting bot response for: {message_text[:50]}...\")\n",
        "    try:\n",
        "        model = get_gemini_model_instance(\"text_model_name\")\n",
        "        prompt = f\"\"\"You are LinguaScribe_Bot, a helpful Telegram assistant. The user's language is Persian.\n",
        "User says: \"{message_text}\"\n",
        "Provide a concise and helpful response in Persian. If the user sends audio, you will have received the transcription as 'messageText'.\n",
        "If they ask about services, mention audio transcription to text (Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØµÙˆØª), Persian translation (ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ), SRT generation (ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT), and audio summarization (Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ ØµÙˆØª).\n",
        "Keep responses brief. If the input is non-sensical or just a greeting, respond politely and briefly in Persian.\n",
        "Return ONLY the bot's reply.\"\"\"\n",
        "        response = await asyncio.to_thread(model.generate_content, prompt)\n",
        "        reply = response.text.strip()\n",
        "        if not reply:\n",
        "            logger.warning(\"Bot response generation was empty.\")\n",
        "            return \"Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‚Ø§Ø¯Ø± Ø¨Ù‡ Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ù†ÛŒØ³ØªÙ….\"\n",
        "        logger.info(\"Bot response generated.\")\n",
        "        return reply\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting bot response: {e}\", exc_info=True)\n",
        "        return \"Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯.\"\n",
        "\n",
        "# --- New Function for Processing Long Audio ---\n",
        "async def process_long_audio(event, download_path, original_name_base, chat_id, processing_msg):\n",
        "    \"\"\"Process a long audio file by splitting it into chunks and processing each chunk\"\"\"\n",
        "    try:\n",
        "        # Check audio duration\n",
        "        audio_duration_ms = await get_audio_duration(download_path)\n",
        "\n",
        "        if audio_duration_ms <= MAX_DURATION_MS:\n",
        "            # Audio is shorter than threshold, process normally\n",
        "            logger.info(f\"Audio duration ({audio_duration_ms/60000:.2f} min) is under threshold, processing normally\")\n",
        "            return await process_single_audio(str(download_path), original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # Audio is longer than threshold, need to split\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"âš ï¸ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø´Ù…Ø§ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø³Øª ({audio_duration_ms/60000:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡). Ø¯Ø± Ø­Ø§Ù„ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª {MAX_DURATION_MINUTES} Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´...\"\n",
        "        )\n",
        "\n",
        "        # Split the audio file\n",
        "        chunk_paths = await split_audio_file(download_path, original_name_base)\n",
        "\n",
        "        # Process each chunk and collect transcriptions\n",
        "        all_transcriptions = []\n",
        "        all_uploaded_refs = []  # Track all uploaded file references for cleanup\n",
        "\n",
        "        for i, chunk_path in enumerate(chunk_paths):\n",
        "            await client.edit_message(\n",
        "                processing_msg,\n",
        "                processing_msg.text + f\"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ù‚Ø·Ø¹Ù‡ {i+1} Ø§Ø² {len(chunk_paths)}...\"\n",
        "            )\n",
        "\n",
        "            chunk_transcription, chunk_ref = await transcribe_audio_google(chunk_path)\n",
        "            all_uploaded_refs.append(chunk_ref)\n",
        "            all_transcriptions.append(chunk_transcription)\n",
        "\n",
        "            await client.edit_message(\n",
        "                processing_msg,\n",
        "                processing_msg.text + f\"\\nâœ… Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‚Ø·Ø¹Ù‡ {i+1} Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.\"\n",
        "            )\n",
        "\n",
        "        # Combine all transcriptions\n",
        "        full_transcription = \"\\n\\n\".join(all_transcriptions)\n",
        "\n",
        "        # Save combined transcription\n",
        "        transcription_filename = f\"{original_name_base}_full_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(full_transcription)\n",
        "\n",
        "        # Send the combined transcription\n",
        "        await client.send_file(\n",
        "            chat_id,\n",
        "            str(transcription_path),\n",
        "            caption=\"ðŸŽ¤ Ù…ØªÙ† Ú©Ø§Ù…Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:\"\n",
        "        )\n",
        "\n",
        "        # Generate SRT from combined transcription\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT) Ú©Ø§Ù…Ù„...\")\n",
        "        srt_content = await generate_persian_srt_google(full_transcription)\n",
        "        srt_filename = f\"{original_name_base}_full_subtitles.srt\"\n",
        "        srt_path = TEMP_DIR / srt_filename\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_content)\n",
        "        await client.send_file(chat_id, str(srt_path), caption=\"ðŸŽ¬ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ú©Ø§Ù…Ù„ (SRT):\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT) Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        # Generate summary using the first chunk's audio reference and the full transcription\n",
        "        # (since we can't combine audio files for the API, we'll use one chunk but provide full transcription)\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙ‡ÛŒÙ‡ Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ...\")\n",
        "        summary = await summarize_audio_google(all_uploaded_refs[0], full_transcription)\n",
        "        await client.send_message(\n",
        "            chat_id,\n",
        "            f\"ðŸ“ *Ø®Ù„Ø§ØµÙ‡ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„:*\\n\\n{summary}\",\n",
        "            parse_mode='md'\n",
        "        )\n",
        "\n",
        "        # Final status message\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ {audio_duration_ms/60000:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ Ø´Ù…Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯.\"\n",
        "        )\n",
        "\n",
        "        # Return all files for cleanup\n",
        "        return all_uploaded_refs, [download_path, transcription_path, srt_path] + chunk_paths\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_long_audio: {e}\")\n",
        "        await client.edit_message(\n",
        "            processing_msg,\n",
        "            f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ù„Ù†Ø¯: {str(e)}\"\n",
        "        )\n",
        "        return [], [download_path]\n",
        "\n",
        "# --- Function to Process a Single Audio File (for reuse) ---\n",
        "async def process_single_audio(file_path, original_name_base, chat_id, processing_msg):\n",
        "    \"\"\"Process a single audio file and return the uploaded ref and files for cleanup\"\"\"\n",
        "    try:\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†...\")\n",
        "        transcription, google_audio_file_uploaded_ref = await transcribe_audio_google(file_path)\n",
        "\n",
        "        transcription_filename = f\"{original_name_base}_transcription.txt\"\n",
        "        transcription_path = TEMP_DIR / transcription_filename\n",
        "        with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcription)\n",
        "\n",
        "        await client.send_file(chat_id, str(transcription_path), caption=\"ðŸŽ¤ Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙ‡ÛŒÙ‡ Ø®Ù„Ø§ØµÙ‡...\")\n",
        "        summary = await summarize_audio_google(google_audio_file_uploaded_ref, transcription)\n",
        "        await client.send_message(chat_id, f\"ðŸ“ *Ø®Ù„Ø§ØµÙ‡ Ù…Ø­ØªÙˆØ§:*\\n\\n{summary}\", parse_mode='md')\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… Ø®Ù„Ø§ØµÙ‡ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\n\\nâ³ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT)...\")\n",
        "        srt_content = await generate_persian_srt_google(transcription)\n",
        "        srt_filename = f\"{original_name_base}_subtitles.srt\"\n",
        "        srt_path = TEMP_DIR / srt_filename\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_content)\n",
        "        await client.send_file(chat_id, str(srt_path), caption=\"ðŸŽ¬ ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT):\")\n",
        "        await client.edit_message(processing_msg, processing_msg.text + \"\\nâœ… ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (SRT) Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.\")\n",
        "        await client.edit_message(processing_msg, \"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!\")\n",
        "\n",
        "        # Return references and paths for cleanup\n",
        "        return [google_audio_file_uploaded_ref], [file_path, transcription_path, srt_path]\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Error in process_single_audio: {e}\")\n",
        "        await client.edit_message(processing_msg, f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ: {str(e)}\")\n",
        "        return [], [file_path]  # Return empty refs and only the original file for cleanup\n",
        "\n",
        "# --- Main Bot Event Handlers ---\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/start'))\n",
        "async def start(event):\n",
        "    sender = await event.get_sender()\n",
        "    chat_id = event.chat_id\n",
        "    logger.info(f\"New /start command from User {sender.id} in Chat {chat_id}\")\n",
        "\n",
        "    await event.reply(\n",
        "        \"ðŸ‘‹ Ø³Ù„Ø§Ù…! Ø¨Ù‡ Ø±Ø¨Ø§Øª *LinguaScribe* Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯.\\n\\n\"\n",
        "        \"Ø§ÛŒÙ† Ø±Ø¨Ø§Øª Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯:\\n\"\n",
        "        \"ðŸŽ¤ **Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†**: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø±Ø§ Ø¨Ù‡ Ù…ØªÙ† ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ø¯\\n\"\n",
        "        \"ðŸ“ **Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ**: Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ Ø±Ø§ Ø®Ù„Ø§ØµÙ‡ Ú©Ù†Ø¯\\n\"\n",
        "        \"ðŸŽ¬ **Ø²ÛŒØ±Ù†ÙˆÛŒØ³**: ÙØ§ÛŒÙ„ SRT ÙØ§Ø±Ø³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ø¯\\n\\n\"\n",
        "        \"Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù† Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(pattern='/help'))\n",
        "async def help_command(event):\n",
        "    await event.reply(\n",
        "        \"ðŸ” **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² LinguaScribe Bot**\\n\\n\"\n",
        "        \"Ú©Ø§Ø±Ø¨Ø±Ø¯:\\n\"\n",
        "        \"1ï¸âƒ£ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ (voice message, audio file) Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯\\n\"\n",
        "        \"2ï¸âƒ£ Ø±Ø¨Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø±:\\n\"\n",
        "        \"   - Ù…ØªÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\\n\"\n",
        "        \"   - Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ø­ØªÙˆØ§ ØªÙ‡ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\\n\"\n",
        "        \"   - ÙØ§ÛŒÙ„ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\\n\\n\"\n",
        "        \"ðŸ“‹ **Ù†Ú©Ø§Øª Ù…Ù‡Ù…**:\\n\"\n",
        "        \"â€¢ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ ØªØ§ Û³Û° Ø¯Ù‚ÛŒÙ‚Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯\\n\"\n",
        "        \"â€¢ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ±ØŒ Ø±Ø¨Ø§Øª Ø¢Ù†Ù‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ± ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯\\n\"\n",
        "        \"â€¢ Ø²Ø¨Ø§Ù† Ø§ØµÙ„ÛŒ Ù…ÙˆØ±Ø¯ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª\\n\\n\"\n",
        "        \"ðŸ“Œ **Ø¯Ø³ØªÙˆØ±Ø§Øª:**\\n\"\n",
        "        \"/start - Ø´Ø±ÙˆØ¹ Ú©Ø§Ø± Ø¨Ø§ Ø±Ø¨Ø§Øª\\n\"\n",
        "        \"/help - Ù†Ù…Ø§ÛŒØ´ Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§\",\n",
        "        parse_mode='md'\n",
        "    )\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.text and not e.text.startswith('/')))\n",
        "async def handle_text_message(event):\n",
        "    chat_id = event.chat_id\n",
        "    message_text = event.text\n",
        "    logger.info(f\"Received text message in chat {chat_id}: {message_text[:50]}...\")\n",
        "\n",
        "    # Let the user know we're processing\n",
        "    processing_msg = await event.reply(\"â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ø´Ù…Ø§...\")\n",
        "\n",
        "    try:\n",
        "        bot_response = await get_bot_response_google(message_text)\n",
        "        await client.edit_message(processing_msg, bot_response)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling text message: {e}\", exc_info=True)\n",
        "        await client.edit_message(processing_msg, \"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ø´Ù…Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯.\")\n",
        "\n",
        "@client.on(events.NewMessage(func=lambda e: e.audio or e.voice or e.document))\n",
        "async def handle_audio_message(event):\n",
        "    try:\n",
        "        chat_id = event.chat_id\n",
        "        sender = await event.get_sender()\n",
        "        logger.info(f\"Received audio from User {sender.id} in Chat {chat_id}\")\n",
        "\n",
        "        # Check if the message contains audio, voice, or a document\n",
        "        if event.audio:\n",
        "            media = event.audio\n",
        "            file_type = \"audio\"\n",
        "        elif event.voice:\n",
        "            media = event.voice\n",
        "            file_type = \"voice\"\n",
        "        elif event.document and hasattr(event.document, 'mime_type') and event.document.mime_type.startswith('audio/'):\n",
        "            media = event.document\n",
        "            file_type = \"document\"\n",
        "        else:\n",
        "            await event.reply(\"âŒ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "            return\n",
        "\n",
        "        # Initial processing message\n",
        "        processing_msg = await event.reply(\"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ...\")\n",
        "\n",
        "        # Generate a unique filename based on timestamp and user\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        original_name = getattr(media, 'attributes', [{}])[0].file_name if hasattr(getattr(media, 'attributes', [{}])[0], 'file_name') else f\"{file_type}_{timestamp}\"\n",
        "        original_name_base = Path(original_name).stem\n",
        "        download_path = TEMP_DIR / f\"{original_name_base}_{timestamp}.ogg\"\n",
        "\n",
        "        # Download the file\n",
        "        try:\n",
        "            await client.download_media(message=event.message, file=str(download_path))\n",
        "            logger.info(f\"File downloaded to {download_path}\")\n",
        "            await client.edit_message(processing_msg, \"âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...\")\n",
        "        except Exception as download_error:\n",
        "            logger.error(f\"Error downloading file: {download_error}\", exc_info=True)\n",
        "            await client.edit_message(processing_msg, \"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ.\")\n",
        "            return\n",
        "\n",
        "        # Process the audio (handles both short and long audio files)\n",
        "        uploaded_refs, files_to_cleanup = await process_long_audio(\n",
        "            event, download_path, original_name_base, chat_id, processing_msg)\n",
        "\n",
        "        # Clean up all temporary files and references\n",
        "        await cleanup_files(*files_to_cleanup)\n",
        "        for ref in uploaded_refs:\n",
        "            try:\n",
        "                # Only attempt to clean up Google API uploaded file references if they exist\n",
        "                if ref and hasattr(ref, 'name'):\n",
        "                    logger.info(f\"Cleaning up Google API file reference: {ref.name}\")\n",
        "                    # No cleanup needed for now as these are handled by Google's API\n",
        "            except Exception as ref_cleanup_error:\n",
        "                logger.error(f\"Error cleaning up reference: {ref_cleanup_error}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(f\"Unhandled error in handle_audio_message: {e}\")\n",
        "        try:\n",
        "            await event.reply(\"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø´Ù…Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# --- Main Entry Point ---\n",
        "\n",
        "async def main():\n",
        "    logger.info(\"Starting the bot...\")\n",
        "\n",
        "    # Clear temp directory at startup\n",
        "    for file_path in TEMP_DIR.glob(\"*\"):\n",
        "        try:\n",
        "            file_path.unlink()\n",
        "            logger.info(f\"Cleaned up old file: {file_path}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error cleaning up file {file_path}: {e}\")\n",
        "\n",
        "    # Start the client\n",
        "    await client.start(bot_token=BOT_TOKEN)\n",
        "    logger.info(\"Bot started successfully\")\n",
        "\n",
        "    # Get the bot info\n",
        "    me = await client.get_me()\n",
        "    logger.info(f\"Bot Username: @{me.username}\")\n",
        "\n",
        "    # Keep the bot running\n",
        "    try:\n",
        "        logger.info(\"Bot is now running. Press Ctrl+C to stop.\")\n",
        "        await client.run_until_disconnected()\n",
        "    except KeyboardInterrupt:\n",
        "        logger.info(\"Bot stopped by user\")\n",
        "    finally:\n",
        "        await client.disconnect()\n",
        "        logger.info(\"Bot disconnected\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the bot\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())\n"
      ],
      "metadata": {
        "id": "jS1cE8WIGs_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "df737444-6477-40bd-d3c3-0a2f205b2d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 35385.19ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 16001.20ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 13293.33ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 23082.18ms\n"
          ]
        }
      ]
    }
  ]
}